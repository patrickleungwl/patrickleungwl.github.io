{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About ThinkNotes Every human being is the total sum of all his/her experiences. We learn from our mistakes. But sadly, we also tend to forget what we learned over time. So why not just jot down what we learned for the benefit of our own future selves and others? Ray Dalio's Principles said pain plus reflection equals progress . This idea makes sense. It is similar the retrospective phase in Scrum , a popular development practice. In order to improve, we must think and digest what we did wrong and remember . Jotting down these ideas help us remember what we learn. Sadly I have not written anything down consistently in the past decades. It is as if Marco Polo had never written down his adventures. Learn, Reflect, Record. Here I jot down what I've learned and reflect. This is the intent of ThinkNotes.","title":"About ThinkNotes"},{"location":"#about-thinknotes","text":"Every human being is the total sum of all his/her experiences. We learn from our mistakes. But sadly, we also tend to forget what we learned over time. So why not just jot down what we learned for the benefit of our own future selves and others? Ray Dalio's Principles said pain plus reflection equals progress . This idea makes sense. It is similar the retrospective phase in Scrum , a popular development practice. In order to improve, we must think and digest what we did wrong and remember . Jotting down these ideas help us remember what we learn. Sadly I have not written anything down consistently in the past decades. It is as if Marco Polo had never written down his adventures. Learn, Reflect, Record. Here I jot down what I've learned and reflect. This is the intent of ThinkNotes.","title":"About ThinkNotes"},{"location":"2022/predictions/","text":"Predictions For 2023, as compiled on 2022-12-29 GS outlook Recession at 30% probability, core inflation falls to 3%, +1% increase to unemployment rate. Peak short term interest rate at 5.25%, no cuts in 2023. Rate hikes +25bp each in Feb, Mar, and May 2023. Recession in Europe caused by increased energy costs. CS outlook No recession, GDP \u540c0.8%\uff0cinflation falls to 3.8%. Pullback of globalization, global trade to decline. Invest in defensive sectors- healthcare, infrastructure, and silver. Fidelity outlook More deglobalisation, reshoring, opportunities for Thailand and Vietnam. Equities prices still high, volatility to continue, stay defensive. Stay in cash and uncorrelated assets, govt bonds. Central bank can remain excessively hawkish and overshoot rate raises. Credit default spreads not currrently priced in for recession as of Nov 2022. Blackrock outlook Inflation cannot be contained without crushing demand. Recession is inevitable. Reprice equities and add bonds. Go with inflation-linked bonds. BNY Mellon Mild recession 70% probability, recovery expected at end of 2023. Inflation goes down to near 2%. Fed central bank raises short term rates and hold at around 5% in mid-2023. Bonds with higher yields become attractive investment options.","title":"Predictions"},{"location":"2022/predictions/#predictions","text":"For 2023, as compiled on 2022-12-29","title":"Predictions"},{"location":"2022/predictions/#gs-outlook","text":"Recession at 30% probability, core inflation falls to 3%, +1% increase to unemployment rate. Peak short term interest rate at 5.25%, no cuts in 2023. Rate hikes +25bp each in Feb, Mar, and May 2023. Recession in Europe caused by increased energy costs.","title":"GS outlook"},{"location":"2022/predictions/#cs-outlook","text":"No recession, GDP \u540c0.8%\uff0cinflation falls to 3.8%. Pullback of globalization, global trade to decline. Invest in defensive sectors- healthcare, infrastructure, and silver.","title":"CS outlook"},{"location":"2022/predictions/#fidelity-outlook","text":"More deglobalisation, reshoring, opportunities for Thailand and Vietnam. Equities prices still high, volatility to continue, stay defensive. Stay in cash and uncorrelated assets, govt bonds. Central bank can remain excessively hawkish and overshoot rate raises. Credit default spreads not currrently priced in for recession as of Nov 2022.","title":"Fidelity outlook"},{"location":"2022/predictions/#blackrock-outlook","text":"Inflation cannot be contained without crushing demand. Recession is inevitable. Reprice equities and add bonds. Go with inflation-linked bonds.","title":"Blackrock outlook"},{"location":"2022/predictions/#bny-mellon","text":"Mild recession 70% probability, recovery expected at end of 2023. Inflation goes down to near 2%. Fed central bank raises short term rates and hold at around 5% in mid-2023. Bonds with higher yields become attractive investment options.","title":"BNY Mellon"},{"location":"2022/think/","text":"Think Recharge Fail forward If you don't fail, you're not even trying... To get something you never had, you have to do something you never did... Every failed experiment is one step closer to success. You've got to take risks... First you will fail at some point in your life. Accept it. You will lose. You will embarrass yourself. You will suck at something. There is no doubt about it.... I didn't get the job. But here's the thing. I didn't quit. I didn't fall back. I walked out of there to prepare for the next audition and the next. I prayed. And I prayed. But I continued to fail and fail and fail. But it didn't matter because you know what? There's an old saying- 'If you hang around the barber shop long enough sooner or later you're going to get a haircut'. So you will catch a break. I did catch a break... Denzel Washington Respect Enlightenment Generations Imagine a contemporary human on a beach holding her mother's hand. Then picture the mother in turn holding the hand of her own mother. Then with your imagination, extend this hand-holding chain additional generations into the past. When this imagined chain of ancestors reaches about 300 miles (480km) in length (this takes 500,000 generations), it will have reached the point where the mother at the head of the line resembles the beings we call chimpanzees. Keep in mind that we started with humans, and that, of course, all the mothers and daughters are directly related to one another. Richard Dawkins There was no single first human. Just as we cannot say for sure where yellow begins exactly on a rainbow- there is no clear point in time one's mother was a chimp-like ape whose daugher was a human. Deep \u5251\u5ba2 \u5341\u5e74\u78e8\u4e00\u528d \u971c\u5203\u672a\u66fe\u8a66 \u4eca\u65e5\u628a\u793a\u541b \u8ab0\u6709\u4e0d\u5e73\u4e8b \u8cc8\u5cf6 \u65e0\u6094\u8fd9\u4e00\u751f \u6ca1\u6709\u6cea\u5149\u98ce\u91cc\u52b2\u95ef \u6000\u7740\u5fc3\u4e2d\u65b0\u5e0c\u671b \u80fd\u51b2\u4e00\u6b21 \u591a\u4e00\u6b21 \u4e0d\u606f\u81ea\u5f3a \u6ca1\u6709\u6cea\u5149\u98ce\u91cc\u52b2\u95ef \u91cd\u690d\u6839\u4e8e\u5c0f\u5c9b\u5cb8 \u5982\u5929\u53ef\u53d8\u98ce\u53ef\u8f6c \u4e0d\u606f\u81ea\u5f3a \u8fd9\u65b9\u5411 \u5362\u56fd\u5b8f From Beyond. No regrets in this life. \u56de\u4e61\u5076\u4e66 \u5c11\u5c0f\u79bb\u5bb6\u8001\u5927\u56de \u4e61\u97f3\u65e0\u6539\u9b13\u6bdb\u8870 \u513f\u7ae5\u76f8\u89c1\u4e0d\u76f8\u8bc6 \u7b11\u95ee\u5ba2\u4ece\u4f55\u5904\u6765 \u8d3a\u77e5\u7ae0 Hilarity Speed reading I took a course in speed reading, learning to read straight down the middle of the page, and was able to go through War and Peace in 20 minutes. It's about Russia. Woody Allen Language A professor was discussing how grammar varied across the world's languages. 'Whilst in some languages a double negative gives a positive, and in other languages a double negative expresses a negative, there are no known languages in which a double positive results in a negative.' From the back of the lecture theater in tones of heavy sarcasm was heard: 'Yeah, yeah.' Unknown Full of shit Steve Jobs had managed to get Don Knuth, the legendary Stanford professor of computer science, to give a lunchtime lecture to the Mac team. Knuth is the author of at least a dozen books, including the massive and somewhat impenetrable trilogy \"The Art of Computer Programming.\" I was sitting in Steve's office when Lynn Takahashi, Steve's assistant, announced Knuth's arrival. Steve bounced out of his chair, bounded over to the door and extended a welcoming hand. \"It's a pleasure to meet you, Professor Knuth,\" Steve said. \"I've read all of your books.\" \"You're full of shit,\" Knuth responded. Efficient markets \"Isn't that a $10 bill lying on the ground?\" asks the student. \"No, it can't be a $10 bill,\" answers the professor. \"If it were, someone would have picked it up by now.\" The professor walks away, and the student picks it up and has a beer.","title":"Think"},{"location":"2022/think/#think","text":"","title":"Think"},{"location":"2022/think/#recharge","text":"","title":"Recharge"},{"location":"2022/think/#fail-forward","text":"If you don't fail, you're not even trying... To get something you never had, you have to do something you never did... Every failed experiment is one step closer to success. You've got to take risks... First you will fail at some point in your life. Accept it. You will lose. You will embarrass yourself. You will suck at something. There is no doubt about it.... I didn't get the job. But here's the thing. I didn't quit. I didn't fall back. I walked out of there to prepare for the next audition and the next. I prayed. And I prayed. But I continued to fail and fail and fail. But it didn't matter because you know what? There's an old saying- 'If you hang around the barber shop long enough sooner or later you're going to get a haircut'. So you will catch a break. I did catch a break... Denzel Washington Respect","title":"Fail forward"},{"location":"2022/think/#enlightenment","text":"","title":"Enlightenment"},{"location":"2022/think/#generations","text":"Imagine a contemporary human on a beach holding her mother's hand. Then picture the mother in turn holding the hand of her own mother. Then with your imagination, extend this hand-holding chain additional generations into the past. When this imagined chain of ancestors reaches about 300 miles (480km) in length (this takes 500,000 generations), it will have reached the point where the mother at the head of the line resembles the beings we call chimpanzees. Keep in mind that we started with humans, and that, of course, all the mothers and daughters are directly related to one another. Richard Dawkins There was no single first human. Just as we cannot say for sure where yellow begins exactly on a rainbow- there is no clear point in time one's mother was a chimp-like ape whose daugher was a human.","title":"Generations"},{"location":"2022/think/#deep","text":"","title":"Deep"},{"location":"2022/think/#_1","text":"\u5341\u5e74\u78e8\u4e00\u528d \u971c\u5203\u672a\u66fe\u8a66 \u4eca\u65e5\u628a\u793a\u541b \u8ab0\u6709\u4e0d\u5e73\u4e8b \u8cc8\u5cf6","title":"\u5251\u5ba2"},{"location":"2022/think/#_2","text":"\u6ca1\u6709\u6cea\u5149\u98ce\u91cc\u52b2\u95ef \u6000\u7740\u5fc3\u4e2d\u65b0\u5e0c\u671b \u80fd\u51b2\u4e00\u6b21 \u591a\u4e00\u6b21 \u4e0d\u606f\u81ea\u5f3a \u6ca1\u6709\u6cea\u5149\u98ce\u91cc\u52b2\u95ef \u91cd\u690d\u6839\u4e8e\u5c0f\u5c9b\u5cb8 \u5982\u5929\u53ef\u53d8\u98ce\u53ef\u8f6c \u4e0d\u606f\u81ea\u5f3a \u8fd9\u65b9\u5411 \u5362\u56fd\u5b8f From Beyond. No regrets in this life.","title":"\u65e0\u6094\u8fd9\u4e00\u751f"},{"location":"2022/think/#_3","text":"\u5c11\u5c0f\u79bb\u5bb6\u8001\u5927\u56de \u4e61\u97f3\u65e0\u6539\u9b13\u6bdb\u8870 \u513f\u7ae5\u76f8\u89c1\u4e0d\u76f8\u8bc6 \u7b11\u95ee\u5ba2\u4ece\u4f55\u5904\u6765 \u8d3a\u77e5\u7ae0","title":"\u56de\u4e61\u5076\u4e66"},{"location":"2022/think/#hilarity","text":"","title":"Hilarity"},{"location":"2022/think/#speed-reading","text":"I took a course in speed reading, learning to read straight down the middle of the page, and was able to go through War and Peace in 20 minutes. It's about Russia. Woody Allen","title":"Speed reading"},{"location":"2022/think/#language","text":"A professor was discussing how grammar varied across the world's languages. 'Whilst in some languages a double negative gives a positive, and in other languages a double negative expresses a negative, there are no known languages in which a double positive results in a negative.' From the back of the lecture theater in tones of heavy sarcasm was heard: 'Yeah, yeah.' Unknown","title":"Language"},{"location":"2022/think/#full-of-shit","text":"Steve Jobs had managed to get Don Knuth, the legendary Stanford professor of computer science, to give a lunchtime lecture to the Mac team. Knuth is the author of at least a dozen books, including the massive and somewhat impenetrable trilogy \"The Art of Computer Programming.\" I was sitting in Steve's office when Lynn Takahashi, Steve's assistant, announced Knuth's arrival. Steve bounced out of his chair, bounded over to the door and extended a welcoming hand. \"It's a pleasure to meet you, Professor Knuth,\" Steve said. \"I've read all of your books.\" \"You're full of shit,\" Knuth responded.","title":"Full of shit"},{"location":"2022/think/#efficient-markets","text":"\"Isn't that a $10 bill lying on the ground?\" asks the student. \"No, it can't be a $10 bill,\" answers the professor. \"If it were, someone would have picked it up by now.\" The professor walks away, and the student picks it up and has a beer.","title":"Efficient markets"},{"location":"2022/Finance/Stats/","text":"Statistics Basic definitions A parameter is a number describing a whole population (eg. population mean). A statistic is a number describing a sample (eg. sample mean). A normal distribution is just one out of an infinite number of bell-shaped distributions, with a specific qualities. A random variable central limit theorem margin of error hypothesis, t-stat","title":"Statistics"},{"location":"2022/Finance/Stats/#statistics","text":"","title":"Statistics"},{"location":"2022/Finance/Stats/#basic-definitions","text":"A parameter is a number describing a whole population (eg. population mean). A statistic is a number describing a sample (eg. sample mean). A normal distribution is just one out of an infinite number of bell-shaped distributions, with a specific qualities. A random variable central limit theorem margin of error hypothesis, t-stat","title":"Basic definitions"},{"location":"2022/Finance/Trading/","text":"Trading options market making MM buys and sell options and earns the bid-ask spread. Suppose MM sells a 1 call option contract, making him delta negative. He needs to hedge the negative delta by buying the underlying equity. If the delta is 0.05, then on 1 option contract, he'd need to buy 5 shares of the underlying equity. With 1 short call and 5 shares, the MM becomes delta neutral. If the price of the underlying goes up, the call option delta also goes up. This means the MM is again not hedged. For example, if the delta goes to 0.10, the MM would need to hold 10 shares. Since he already holds 5 shares, he'd go buy another 5 shares for a total of 10 shares- making him delta neutral. Now if the call becomes in-the-money and the delta reaches 1.0, the MM needs to hold 100 shares of the underlying, in the event the call holder exercises and the MM needs to hand over the 100 shares. implied volatility Once news about a company goes public, the IV should go down- because the unknown becomes known. When the IV goes down, option prices go down as well- because by definition, option prices are built on intrinsic and extrinsic information. IV is part of the extrinsic. extrinsic value The more time to expiration, the more it's going to be worth- from its extrinsic value- made of implied volatility and time value. calendar call spread Calendar call spread is a play on IV. A closer to expiration option has lower IV than a longer to expiration option. Buying and selling of options with the same strike price but with different expirations. A basic calendar call spread would be 1) sell short DTE call and 2) buy long DTE call. The short DTE would have negative vega and the long DTE would have positive vega. Overall, the vega is positive which means for every increase in IV, the overall option price would go up. vega Vega is the change in option price for each 1% move in implied vol. This is a first derivative. Vega is higher in ATM options and longer DTE. gamma Gamma is the change in delta for each move in the underlying equity's price. In physics terms, it is acceleration, a second derivative. gamma squeeze Gamma squeeze is a self-reinforcing push up effect motivated by call option holders. The call seller is required to buy up the underlying equity to delta neutral is short call positions. This buying in effect pushes up the price of the underlying further- which increases the call's delta, further requiring the call seller to buy more underlying. For an equity with few shares outstanding, this behavior induces further buying and higher underlying equity prices. In effect, the underlying reason for a gamma squeeze are the market makers' need to remain delta neutral. fixed income the fed The role of central banks such as the Federal Reserve- is to maintain a stable and growing economy through price stability and full employment. The Fed has two primary tools in its toolbox: Setting short term interest rates. The Fed controls the short end of the yield curve. Buying or selling treasury notes and bonds through open market operations. Selling bonds to the public takes away cash from the public. This lowers the money supply- and reduces demand for goods. This is a tool to use for lowering inflation. During World War II, Uncle Sam sold bonds to the public not to finance the war, but to reduce demand for other goods and reduce inflation. Buying bonds from the public puts money into the hands of the public. This stimulates the economy. This is a tool to use during weak economic times to flood the market with money. \"Quantitative easing\" is this form of open market bond purchases. Bidding up bonds also causes long term interest rates to fall.","title":"Trading"},{"location":"2022/Finance/Trading/#trading","text":"","title":"Trading"},{"location":"2022/Finance/Trading/#options","text":"","title":"options"},{"location":"2022/Finance/Trading/#market-making","text":"MM buys and sell options and earns the bid-ask spread. Suppose MM sells a 1 call option contract, making him delta negative. He needs to hedge the negative delta by buying the underlying equity. If the delta is 0.05, then on 1 option contract, he'd need to buy 5 shares of the underlying equity. With 1 short call and 5 shares, the MM becomes delta neutral. If the price of the underlying goes up, the call option delta also goes up. This means the MM is again not hedged. For example, if the delta goes to 0.10, the MM would need to hold 10 shares. Since he already holds 5 shares, he'd go buy another 5 shares for a total of 10 shares- making him delta neutral. Now if the call becomes in-the-money and the delta reaches 1.0, the MM needs to hold 100 shares of the underlying, in the event the call holder exercises and the MM needs to hand over the 100 shares.","title":"market making"},{"location":"2022/Finance/Trading/#implied-volatility","text":"Once news about a company goes public, the IV should go down- because the unknown becomes known. When the IV goes down, option prices go down as well- because by definition, option prices are built on intrinsic and extrinsic information. IV is part of the extrinsic.","title":"implied volatility"},{"location":"2022/Finance/Trading/#extrinsic-value","text":"The more time to expiration, the more it's going to be worth- from its extrinsic value- made of implied volatility and time value.","title":"extrinsic value"},{"location":"2022/Finance/Trading/#calendar-call-spread","text":"Calendar call spread is a play on IV. A closer to expiration option has lower IV than a longer to expiration option. Buying and selling of options with the same strike price but with different expirations. A basic calendar call spread would be 1) sell short DTE call and 2) buy long DTE call. The short DTE would have negative vega and the long DTE would have positive vega. Overall, the vega is positive which means for every increase in IV, the overall option price would go up.","title":"calendar call spread"},{"location":"2022/Finance/Trading/#vega","text":"Vega is the change in option price for each 1% move in implied vol. This is a first derivative. Vega is higher in ATM options and longer DTE.","title":"vega"},{"location":"2022/Finance/Trading/#gamma","text":"Gamma is the change in delta for each move in the underlying equity's price. In physics terms, it is acceleration, a second derivative.","title":"gamma"},{"location":"2022/Finance/Trading/#gamma-squeeze","text":"Gamma squeeze is a self-reinforcing push up effect motivated by call option holders. The call seller is required to buy up the underlying equity to delta neutral is short call positions. This buying in effect pushes up the price of the underlying further- which increases the call's delta, further requiring the call seller to buy more underlying. For an equity with few shares outstanding, this behavior induces further buying and higher underlying equity prices. In effect, the underlying reason for a gamma squeeze are the market makers' need to remain delta neutral.","title":"gamma squeeze"},{"location":"2022/Finance/Trading/#fixed-income","text":"","title":"fixed income"},{"location":"2022/Finance/Trading/#the-fed","text":"The role of central banks such as the Federal Reserve- is to maintain a stable and growing economy through price stability and full employment. The Fed has two primary tools in its toolbox: Setting short term interest rates. The Fed controls the short end of the yield curve. Buying or selling treasury notes and bonds through open market operations. Selling bonds to the public takes away cash from the public. This lowers the money supply- and reduces demand for goods. This is a tool to use for lowering inflation. During World War II, Uncle Sam sold bonds to the public not to finance the war, but to reduce demand for other goods and reduce inflation. Buying bonds from the public puts money into the hands of the public. This stimulates the economy. This is a tool to use during weak economic times to flood the market with money. \"Quantitative easing\" is this form of open market bond purchases. Bidding up bonds also causes long term interest rates to fall.","title":"the fed"},{"location":"2022/Linux/KernelBypass/","text":"Kernel Bypass OpenOnload OpenOnload is software used for kernel bypass to work with Solarflare network cards. By redirecting network IO to run through its own stack in/out of its network card, applications can avoid network traffic latency encountered when relying on the kernel to send or receive data. With all things kernel related, your application must wait its turn depending on the whim of the kernel scheduler. Other latencies are caused by data copies and context switching when apps switch from kernel to user mode. onload onload is the application to run Solarflare's kernel bypass software. We need to optimize onload settings for each application. Dued to the paucity of optmisation tips on the net, I've put together some battle-field notes for optimising onload. Use onload_stackdump to peek into onload stats and see which area needs tweaking. onload_stackdump lots Here are some areas that need looking into for each onloaded application: packet buffers kernel polls interrupts packet drops lock contentions packet buffers Check for the following statistics reported by onload_stackdump: pkt_scramble0 pkt_scramble1 pkt_scramble2 memory_pressure_enter memory_pressure_drops The onload documentation states for each stat: pkt_scramble0 is the number of times onload scrambled to find free buffers for L0 cache. This is an indication of severe memory pressure. pkt_scramble1 and pkt_scramble2 are similar counts for L1 and L2 caches. memory_pressure_enter is the number of times onload has entered 'memory pressure' state. memory_pressure_drops is the number of packets dropped due to 'memory pressure'. Onload documentation states \"When Onload detects a stack is close to allocating all available packet buffers, it will take action to try and avoid packet buffer exhaustion. Onload will automatically start dropping packets on receive and, where possible, will reduce the receive descriptor ring fill level in an attempt to alleviate the situation.\" For memory related issues, the documentation suggests bumping up EF_MAX_PACKETS. This setting controls the maximum number of packet buffers that can be used by the Onload stack. By default, updating EF_MAX_PACKETS also updates parameters EF_MAX_RX_PACKETS and EF_MAX_TX_PACKETS to 75% of EF_MAX_PACKETS. While increasing EF_MAX_PACKETS should be beneficial to preventing memory pressure problems, the downside of increasing this value too high is a larger memomry footprint and resulting latency. kernel polls Onload_stackdump shows the number of times a socket event was polled from the kernel versus user space, with the latter being preferred. Examples: k_polls: 34441 u_polls: 1870340303 k_polls is the number of times the socket event queue was polled from the kernel while u_polls is the number of times the socket event queue was polled from user space. We'd much prefer applications to read socket events from user space- bypassing kernel scheduling and data copies and context switching. If k_polls > u_polls, then one parameter to try is EF_POLL_USEC. This setting gets onload to continuously poll in user space for the set number of microseconds.. When an application reads from a socket and no data is available, the call will enter the OS kernel and block. When data becomes available, the network adapter will interrupt the CPU, allowing the kernel to reschedule the application to continue. Blocking and interrupts are relatively expensive operations. Onload can be configured to spin on the processor in user mode for up to a specific number of microseconds waiting for data from the network. If the spin period expires the processor will revert to conventional blocking behavior. Non-blocking sockets will always return immeidately as these are unaffected by spinning. If a cpu core can be dedicated to each thread that blocks waiting for network IO, then spinning is the best method to achieve the lowest possible latency. The documentation suggests using EF_POLL_USEC to increase the timeout a user polls sockets before blocking- which then would require an interrupt wakeup from the kernel. While this suggestion may work for single-threaded applications, the downside of a higher poll timeout can also block other threads from polling. No one solution works for all applications. The proper setting depends on the number of threads polling sockets and the level of incoming or outgoing data. interrupts Onload_stackdump shows counts for each event- such as the number of data receive/sent events and the number of times an interrupt was used to poll. Examples: rx_evs: 2092752987 tx_evs: 25770 interrupt_polls: 6688961 interrupt_evs: 12014176 interrupt_wakes: 5336668 rx_evs and tx_evs are the number of events received and transmitted, respectively. interrupt_polls is the number of times the stack is polled and invoked by interrupts. interrupt_evs is the number of events processed invoked by interrupts. Lastly, interrupt_wakes is the number of times the application is woken by interrupt. A high number of events handled by interrupts relative to the total number of packet receive events could mean latency caused by relying on interrupts. The documentation advises setting a higher EF_POLL_USEC . This gets polls to continuously poll the socket before timing out and then relying on interrupts to get data. This reduces the number of interrupts- and context switches- for reading socket packets. But a higher poll timeout comes with a cost of blocking other threads from polling. Finding the optimial setting requires testing. packet drops Packet losses over the network harm performance. The Linux tool ethtool identifies packet drops. ethtool -S <interface> | grep drop rx_noskb_drops: 0 port_rx_nodesc_drops: 504905630 port_rx_dp_di_dropped_packets: 1016728 rx_noskb_drops is the number of packets dropped when there are not enough socket buffers. port_rx_nodesc_drops is the number of packets dropped when there are no further descriptors in the rx ring buffer. port_rx_dp_di_dropped_packets is the number of packts dropped by filters. Onloa's documentation says \"If packet loss is observed at the network level due to a lack of receive buffering try increasing the size of the receive descriptor queue size via EF_RXQ_SIZE . If packet drops are observed at the socket level, it may also be worth experimenting with socket buffer sizes via EF_UDP_RCVBUF . Setting EF_EVS_PER_POLL to a higher value may also improve efficiency\". A larger rx ring buffer with a larger EF_RXQ_SIZE can absorb larger packet bursts without drops but at an increase in process memory working set size. EF_EVS_PER_POLL sets the number of hardware network events to handle before performing other work. This setting presents a trade-off- larger values increase batching- which usually improves efficiency- but may also increase the working set size- which could harm efficiency. lock contentions Onload's documentation states, \"When threads share a stack,a thread holding the stack lock blocks another thread.\" High coutns in the stats interrupt_lock_contends , periodic_lock_contends , and timeout_interrupt_lock_contends can identify these lock contentions. The documentation suggests to use EF_STACK_PER_THREAD to create a stack per thread. If a multi-threaded application is doing lots of socket operations, stack lock contention will lead to send/receive performance jitter. In such cases improved perofmrance can be had when each contending thread has its own stack. This can be managed with EF_STACK_PER_THREAD which creates a separate Onload stack for the stocks created by each thread. If using EF_STACK_PER_THREAD, it may also be possible to bump up EF_POLL_USEC since each user-space poll now no longer blocks other threads. network stack typical network flow Data packets flow from the TX application to the RX listener application. TX RX ------------- ------------- Application Application Transport (L4) Transport (L4) Network (L3) Network (L3) Data link (L2) Data link (L2) NIC driver NIC driver NIC hardware NIC hardware Contents of a data packet: Ethernet header dest MAC, src MAC, type of next structure IP header length, IP type, header checksum, src IP, dest IP TCP header src IP, dest IP, checksum payload checksum rx path Applications in user space -------------------------------------- NIC driver in kernel space tx and rx ring buffer --> packet buffers NIC The NIC driver preallocates packet buffers and the tx and rx ring buffers. Also, tx and rx ring buffers are shared between NIC and NIC driver. What happens when a NIC receives a data packet? It matches the incoming packet's MAC address to the NIC's MAC address. Next it verifies the ethernet checksum. Next the NIC copies the data packet to the rx ring buffer using direct memory access (DMA). DMA alleviates any work by the cpu. The NIC then triggers an interrupt to notify the NIC driver there is incoming data. The cpu interrupts the process in execution. It switches to kernel space to 1) lookup the Interrupt Descriptor Table (IDT), 2) execute the interrupt's registered service routine (ISR). Then the cpu acks the interrupt and switches back to user space. Later, the cpu enters the kernel space again- this time driven by the NIC driver . The NIC driver dynamically allocates an sk buffer (skb) and update its data structure with packet metadata. The NIC driver removes the ethernet header and then passes skb to the network stack. The NIC driver calls L3 layer handling- verifying the IP addresses, checksums, combines fragmented packets and then calls the higher L4 protocol handler. The L4 layer enqueues the skb to the socket read queue. The skb points to the address of the data in the packet buffer. Then it signals the socket. The application in the user space reads the socket- with a system call that switches the process mode to kernel space. This dequeues the packet from the socket receive queue, copies the packet to the application buffer, releases the skb and then returns control back to user space and to the user app. overheads There are too many context switches- back and forth from user to kernel modes. There is context switching during a system read call. There is a packet copy before/during the read process. There is a dynamic allocation of skb by the NIC driver. There is an interrupt for every arriving packet. What a horrible design. A kernel bypass network stack bypasses all these overheads. In a KB setup, there is no context switching (all user space) and there is no packet copy from the kernel to the user handover. reading Reading data packets can be done in two ways- via interrupt or via polling. With interrupts, the NIC notifies the cpu a data packet arrived. Interrupt is a hardware mechanism. This interrupt handling is slower for high speed traffic. With polling, the cpu keeps checking on the NIC. This is a software-level mechanism. The cpu usage is high but this handles high speed traffic.","title":"Kernel Bypass"},{"location":"2022/Linux/KernelBypass/#kernel-bypass","text":"","title":"Kernel Bypass"},{"location":"2022/Linux/KernelBypass/#openonload","text":"OpenOnload is software used for kernel bypass to work with Solarflare network cards. By redirecting network IO to run through its own stack in/out of its network card, applications can avoid network traffic latency encountered when relying on the kernel to send or receive data. With all things kernel related, your application must wait its turn depending on the whim of the kernel scheduler. Other latencies are caused by data copies and context switching when apps switch from kernel to user mode.","title":"OpenOnload"},{"location":"2022/Linux/KernelBypass/#onload","text":"onload is the application to run Solarflare's kernel bypass software. We need to optimize onload settings for each application. Dued to the paucity of optmisation tips on the net, I've put together some battle-field notes for optimising onload. Use onload_stackdump to peek into onload stats and see which area needs tweaking. onload_stackdump lots Here are some areas that need looking into for each onloaded application: packet buffers kernel polls interrupts packet drops lock contentions","title":"onload"},{"location":"2022/Linux/KernelBypass/#packet-buffers","text":"Check for the following statistics reported by onload_stackdump: pkt_scramble0 pkt_scramble1 pkt_scramble2 memory_pressure_enter memory_pressure_drops The onload documentation states for each stat: pkt_scramble0 is the number of times onload scrambled to find free buffers for L0 cache. This is an indication of severe memory pressure. pkt_scramble1 and pkt_scramble2 are similar counts for L1 and L2 caches. memory_pressure_enter is the number of times onload has entered 'memory pressure' state. memory_pressure_drops is the number of packets dropped due to 'memory pressure'. Onload documentation states \"When Onload detects a stack is close to allocating all available packet buffers, it will take action to try and avoid packet buffer exhaustion. Onload will automatically start dropping packets on receive and, where possible, will reduce the receive descriptor ring fill level in an attempt to alleviate the situation.\" For memory related issues, the documentation suggests bumping up EF_MAX_PACKETS. This setting controls the maximum number of packet buffers that can be used by the Onload stack. By default, updating EF_MAX_PACKETS also updates parameters EF_MAX_RX_PACKETS and EF_MAX_TX_PACKETS to 75% of EF_MAX_PACKETS. While increasing EF_MAX_PACKETS should be beneficial to preventing memory pressure problems, the downside of increasing this value too high is a larger memomry footprint and resulting latency.","title":"packet buffers"},{"location":"2022/Linux/KernelBypass/#kernel-polls","text":"Onload_stackdump shows the number of times a socket event was polled from the kernel versus user space, with the latter being preferred. Examples: k_polls: 34441 u_polls: 1870340303 k_polls is the number of times the socket event queue was polled from the kernel while u_polls is the number of times the socket event queue was polled from user space. We'd much prefer applications to read socket events from user space- bypassing kernel scheduling and data copies and context switching. If k_polls > u_polls, then one parameter to try is EF_POLL_USEC. This setting gets onload to continuously poll in user space for the set number of microseconds.. When an application reads from a socket and no data is available, the call will enter the OS kernel and block. When data becomes available, the network adapter will interrupt the CPU, allowing the kernel to reschedule the application to continue. Blocking and interrupts are relatively expensive operations. Onload can be configured to spin on the processor in user mode for up to a specific number of microseconds waiting for data from the network. If the spin period expires the processor will revert to conventional blocking behavior. Non-blocking sockets will always return immeidately as these are unaffected by spinning. If a cpu core can be dedicated to each thread that blocks waiting for network IO, then spinning is the best method to achieve the lowest possible latency. The documentation suggests using EF_POLL_USEC to increase the timeout a user polls sockets before blocking- which then would require an interrupt wakeup from the kernel. While this suggestion may work for single-threaded applications, the downside of a higher poll timeout can also block other threads from polling. No one solution works for all applications. The proper setting depends on the number of threads polling sockets and the level of incoming or outgoing data.","title":"kernel polls"},{"location":"2022/Linux/KernelBypass/#interrupts","text":"Onload_stackdump shows counts for each event- such as the number of data receive/sent events and the number of times an interrupt was used to poll. Examples: rx_evs: 2092752987 tx_evs: 25770 interrupt_polls: 6688961 interrupt_evs: 12014176 interrupt_wakes: 5336668 rx_evs and tx_evs are the number of events received and transmitted, respectively. interrupt_polls is the number of times the stack is polled and invoked by interrupts. interrupt_evs is the number of events processed invoked by interrupts. Lastly, interrupt_wakes is the number of times the application is woken by interrupt. A high number of events handled by interrupts relative to the total number of packet receive events could mean latency caused by relying on interrupts. The documentation advises setting a higher EF_POLL_USEC . This gets polls to continuously poll the socket before timing out and then relying on interrupts to get data. This reduces the number of interrupts- and context switches- for reading socket packets. But a higher poll timeout comes with a cost of blocking other threads from polling. Finding the optimial setting requires testing.","title":"interrupts"},{"location":"2022/Linux/KernelBypass/#packet-drops","text":"Packet losses over the network harm performance. The Linux tool ethtool identifies packet drops. ethtool -S <interface> | grep drop rx_noskb_drops: 0 port_rx_nodesc_drops: 504905630 port_rx_dp_di_dropped_packets: 1016728 rx_noskb_drops is the number of packets dropped when there are not enough socket buffers. port_rx_nodesc_drops is the number of packets dropped when there are no further descriptors in the rx ring buffer. port_rx_dp_di_dropped_packets is the number of packts dropped by filters. Onloa's documentation says \"If packet loss is observed at the network level due to a lack of receive buffering try increasing the size of the receive descriptor queue size via EF_RXQ_SIZE . If packet drops are observed at the socket level, it may also be worth experimenting with socket buffer sizes via EF_UDP_RCVBUF . Setting EF_EVS_PER_POLL to a higher value may also improve efficiency\". A larger rx ring buffer with a larger EF_RXQ_SIZE can absorb larger packet bursts without drops but at an increase in process memory working set size. EF_EVS_PER_POLL sets the number of hardware network events to handle before performing other work. This setting presents a trade-off- larger values increase batching- which usually improves efficiency- but may also increase the working set size- which could harm efficiency.","title":"packet drops"},{"location":"2022/Linux/KernelBypass/#lock-contentions","text":"Onload's documentation states, \"When threads share a stack,a thread holding the stack lock blocks another thread.\" High coutns in the stats interrupt_lock_contends , periodic_lock_contends , and timeout_interrupt_lock_contends can identify these lock contentions. The documentation suggests to use EF_STACK_PER_THREAD to create a stack per thread. If a multi-threaded application is doing lots of socket operations, stack lock contention will lead to send/receive performance jitter. In such cases improved perofmrance can be had when each contending thread has its own stack. This can be managed with EF_STACK_PER_THREAD which creates a separate Onload stack for the stocks created by each thread. If using EF_STACK_PER_THREAD, it may also be possible to bump up EF_POLL_USEC since each user-space poll now no longer blocks other threads.","title":"lock contentions"},{"location":"2022/Linux/KernelBypass/#network-stack","text":"","title":"network stack"},{"location":"2022/Linux/KernelBypass/#typical-network-flow","text":"Data packets flow from the TX application to the RX listener application. TX RX ------------- ------------- Application Application Transport (L4) Transport (L4) Network (L3) Network (L3) Data link (L2) Data link (L2) NIC driver NIC driver NIC hardware NIC hardware Contents of a data packet: Ethernet header dest MAC, src MAC, type of next structure IP header length, IP type, header checksum, src IP, dest IP TCP header src IP, dest IP, checksum payload checksum","title":"typical network flow"},{"location":"2022/Linux/KernelBypass/#rx-path","text":"Applications in user space -------------------------------------- NIC driver in kernel space tx and rx ring buffer --> packet buffers NIC The NIC driver preallocates packet buffers and the tx and rx ring buffers. Also, tx and rx ring buffers are shared between NIC and NIC driver. What happens when a NIC receives a data packet? It matches the incoming packet's MAC address to the NIC's MAC address. Next it verifies the ethernet checksum. Next the NIC copies the data packet to the rx ring buffer using direct memory access (DMA). DMA alleviates any work by the cpu. The NIC then triggers an interrupt to notify the NIC driver there is incoming data. The cpu interrupts the process in execution. It switches to kernel space to 1) lookup the Interrupt Descriptor Table (IDT), 2) execute the interrupt's registered service routine (ISR). Then the cpu acks the interrupt and switches back to user space. Later, the cpu enters the kernel space again- this time driven by the NIC driver . The NIC driver dynamically allocates an sk buffer (skb) and update its data structure with packet metadata. The NIC driver removes the ethernet header and then passes skb to the network stack. The NIC driver calls L3 layer handling- verifying the IP addresses, checksums, combines fragmented packets and then calls the higher L4 protocol handler. The L4 layer enqueues the skb to the socket read queue. The skb points to the address of the data in the packet buffer. Then it signals the socket. The application in the user space reads the socket- with a system call that switches the process mode to kernel space. This dequeues the packet from the socket receive queue, copies the packet to the application buffer, releases the skb and then returns control back to user space and to the user app.","title":"rx path"},{"location":"2022/Linux/KernelBypass/#overheads","text":"There are too many context switches- back and forth from user to kernel modes. There is context switching during a system read call. There is a packet copy before/during the read process. There is a dynamic allocation of skb by the NIC driver. There is an interrupt for every arriving packet. What a horrible design. A kernel bypass network stack bypasses all these overheads. In a KB setup, there is no context switching (all user space) and there is no packet copy from the kernel to the user handover.","title":"overheads"},{"location":"2022/Linux/KernelBypass/#reading","text":"Reading data packets can be done in two ways- via interrupt or via polling. With interrupts, the NIC notifies the cpu a data packet arrived. Interrupt is a hardware mechanism. This interrupt handling is slower for high speed traffic. With polling, the cpu keeps checking on the NIC. This is a software-level mechanism. The cpu usage is high but this handles high speed traffic.","title":"reading"},{"location":"2022/Linux/Linux/","text":"Linux notes virtual memory The OS makes each process believe it has access to a continuous stretch of memory stretching from 0 to MAX. The OS intersperses every process' memory needs to real physical memory spaces. The OS handles the virtual to read memory translations. The OS divides memory into pages- which it uses to handle mapping a page at a time. shared memory Use shmget system call to read write to the same memory space. signals Use signals to send signals to each process. Every process has signal handlers for execution in response to each signal. sockets Use sockets to get two processes on the same or different machines to talk to each other. With different machines, use TCP or UDP networking protocol. On same machine, use Unix sockets. pipes Pipes system call returns two file descriptors. A pipe is a half-duplex commuication- which means it's only one way. Regular pipes work in the same process- shared by parent and child after fork. Named pipes are for different processes. taskset taskset binds a process to run on specific cpu cores. By default, the kernel decides which core to run a process when its scheduler schedules a process. However, when we pin a process to a specific core(s), it's less likely for the process to have cache misses- because the process is likely to have already run on that core previously. With less cache misses- the process should run faster overall. taskset -p <pid> -c <cpu-list> where cpu-list can be a number or a range like 0-9 NUMA NUMA, or non-uniform memory access, is a setup of cpus such that a cluster of cpus can share memory locally via a local bus instead of the system bus. Cpus need to fetch memory quickly. However, because multiple cpus can fetch memory at the same time, this leads to contention and latency. The idea with NUMA is that small clusters can treat its shared memory as its L3 cache. Instead of a core reaching out to the system bus to fetch data from the main memory, it can fetch the same data in this shared L3 cache. Comparisons with UMA, uniform memory access UMA offers limited bandwidth uses a single memory controller, slower than NUMA NUMA offers more bandwidth than UMA uses multiple memory controllers, speeds up memory fetches than UMA better for real time applications hyperthreading Hyperthreading is Intel's name for a hardware technique to run more than one thread on each core. It creates two logical (virtual) processors per actual core, each of which has its own processor state. Each logical processor runs indepedently of the other logical processor. However, both logical processors share the same (L1/L2/L3?) caches and system bus. AMD has similar technology called SMT, simulatenous multithreading. Both allow two threads to run in parallel on the same core. To check whether hyperthreading/SMT is enabled: cat /proc/version low latency kernel Compared to a regular generic kernel, a low latency kernel- also known as a real time kernel- context switches more often. These kernels are tuned to specific needs. Generic kernels favor throughput over latency. Generic kernels want to get things done- with less context switches. Low latency kernels favor latency over throughput. Low latency kernels want to respond to events quicker- with more context switches- consuming more cpu- and usually resulting in lower throughput. To check the kernel version: cat /proc/version multicast/unicast Unicast is a one-to-one traffic flow. If multiple clients request the same data feed from the same server, the server will flood the network with multiple copies of the same data. In a multicast environment, the server only sends one data feed- and it is up to the switches to forward the data to only the interested clients. tmux Tmux is a terminal multiplexer that allows you to run multiple terminals over a single session. Tmux by default uses an awkward ctrl-b to start all tmux commands. To override default key bindings, add a .tmux.conf file. The following file makes ctrl-t the keystroke for triggering tmux: .tmux.conf contents unbind C-b set-option -g prefix C-t bind-key C-t send-prefix bind v split-window -h bind s split-window -v unbind '\"' unbind % bind h select-pane -L bind l select-pane -R bind k select-pane -U bind j select-pane -D Keystroke - Action cheatsheet ctrl-t s | split screen horizontally ctrl-t v | split screen vertically ctrl-t h | move cursor to pane below ctrl-t j | move cursor to pane left ctrl-t k | move cursor to pane above ctrl-t l | move cursor to pane right ctrl-t ctrl-arrow | expands or shrinks the pane ctrl-t z | zoom in or out of pane ctrl-t space | rotate to next layout| ctrl-t u | swap pane up ctrl-t d | swap pane down ctrl-t > | show menu ctrl-t ? | see list of all tmux commands You can lose connection to a terminal for any number of reasons, but the tmux session remains alive behind the scenes if the machine remains up. To check what tmux sessions are still running: tmux ls To connect to a specific session: tmux attach -t 0 To start a tmux session with a specific name like 'mywork': tmux new -s mywork To connect to a specific session by name: tmux attach -t mywork systemd systemd is used to start, stop and monitor status in Ubuntu. list-unit-files start stop restart status journalctl vi proc lspci ethtool top network time protocol ntp","title":"Linux notes"},{"location":"2022/Linux/Linux/#linux-notes","text":"","title":"Linux notes"},{"location":"2022/Linux/Linux/#virtual-memory","text":"The OS makes each process believe it has access to a continuous stretch of memory stretching from 0 to MAX. The OS intersperses every process' memory needs to real physical memory spaces. The OS handles the virtual to read memory translations. The OS divides memory into pages- which it uses to handle mapping a page at a time.","title":"virtual memory"},{"location":"2022/Linux/Linux/#shared-memory","text":"Use shmget system call to read write to the same memory space.","title":"shared memory"},{"location":"2022/Linux/Linux/#signals","text":"Use signals to send signals to each process. Every process has signal handlers for execution in response to each signal.","title":"signals"},{"location":"2022/Linux/Linux/#sockets","text":"Use sockets to get two processes on the same or different machines to talk to each other. With different machines, use TCP or UDP networking protocol. On same machine, use Unix sockets.","title":"sockets"},{"location":"2022/Linux/Linux/#pipes","text":"Pipes system call returns two file descriptors. A pipe is a half-duplex commuication- which means it's only one way. Regular pipes work in the same process- shared by parent and child after fork. Named pipes are for different processes.","title":"pipes"},{"location":"2022/Linux/Linux/#taskset","text":"taskset binds a process to run on specific cpu cores. By default, the kernel decides which core to run a process when its scheduler schedules a process. However, when we pin a process to a specific core(s), it's less likely for the process to have cache misses- because the process is likely to have already run on that core previously. With less cache misses- the process should run faster overall. taskset -p <pid> -c <cpu-list> where cpu-list can be a number or a range like 0-9","title":"taskset"},{"location":"2022/Linux/Linux/#numa","text":"NUMA, or non-uniform memory access, is a setup of cpus such that a cluster of cpus can share memory locally via a local bus instead of the system bus. Cpus need to fetch memory quickly. However, because multiple cpus can fetch memory at the same time, this leads to contention and latency. The idea with NUMA is that small clusters can treat its shared memory as its L3 cache. Instead of a core reaching out to the system bus to fetch data from the main memory, it can fetch the same data in this shared L3 cache. Comparisons with UMA, uniform memory access UMA offers limited bandwidth uses a single memory controller, slower than NUMA NUMA offers more bandwidth than UMA uses multiple memory controllers, speeds up memory fetches than UMA better for real time applications","title":"NUMA"},{"location":"2022/Linux/Linux/#hyperthreading","text":"Hyperthreading is Intel's name for a hardware technique to run more than one thread on each core. It creates two logical (virtual) processors per actual core, each of which has its own processor state. Each logical processor runs indepedently of the other logical processor. However, both logical processors share the same (L1/L2/L3?) caches and system bus. AMD has similar technology called SMT, simulatenous multithreading. Both allow two threads to run in parallel on the same core. To check whether hyperthreading/SMT is enabled: cat /proc/version","title":"hyperthreading"},{"location":"2022/Linux/Linux/#low-latency-kernel","text":"Compared to a regular generic kernel, a low latency kernel- also known as a real time kernel- context switches more often. These kernels are tuned to specific needs. Generic kernels favor throughput over latency. Generic kernels want to get things done- with less context switches. Low latency kernels favor latency over throughput. Low latency kernels want to respond to events quicker- with more context switches- consuming more cpu- and usually resulting in lower throughput. To check the kernel version: cat /proc/version","title":"low latency kernel"},{"location":"2022/Linux/Linux/#multicastunicast","text":"Unicast is a one-to-one traffic flow. If multiple clients request the same data feed from the same server, the server will flood the network with multiple copies of the same data. In a multicast environment, the server only sends one data feed- and it is up to the switches to forward the data to only the interested clients.","title":"multicast/unicast"},{"location":"2022/Linux/Linux/#tmux","text":"Tmux is a terminal multiplexer that allows you to run multiple terminals over a single session. Tmux by default uses an awkward ctrl-b to start all tmux commands. To override default key bindings, add a .tmux.conf file. The following file makes ctrl-t the keystroke for triggering tmux: .tmux.conf contents unbind C-b set-option -g prefix C-t bind-key C-t send-prefix bind v split-window -h bind s split-window -v unbind '\"' unbind % bind h select-pane -L bind l select-pane -R bind k select-pane -U bind j select-pane -D Keystroke - Action cheatsheet ctrl-t s | split screen horizontally ctrl-t v | split screen vertically ctrl-t h | move cursor to pane below ctrl-t j | move cursor to pane left ctrl-t k | move cursor to pane above ctrl-t l | move cursor to pane right ctrl-t ctrl-arrow | expands or shrinks the pane ctrl-t z | zoom in or out of pane ctrl-t space | rotate to next layout| ctrl-t u | swap pane up ctrl-t d | swap pane down ctrl-t > | show menu ctrl-t ? | see list of all tmux commands You can lose connection to a terminal for any number of reasons, but the tmux session remains alive behind the scenes if the machine remains up. To check what tmux sessions are still running: tmux ls To connect to a specific session: tmux attach -t 0 To start a tmux session with a specific name like 'mywork': tmux new -s mywork To connect to a specific session by name: tmux attach -t mywork","title":"tmux"},{"location":"2022/Linux/Linux/#systemd","text":"systemd is used to start, stop and monitor status in Ubuntu. list-unit-files start stop restart status","title":"systemd"},{"location":"2022/Linux/Linux/#journalctl","text":"","title":"journalctl"},{"location":"2022/Linux/Linux/#vi","text":"","title":"vi"},{"location":"2022/Linux/Linux/#proc","text":"","title":"proc"},{"location":"2022/Linux/Linux/#lspci","text":"","title":"lspci"},{"location":"2022/Linux/Linux/#ethtool","text":"","title":"ethtool"},{"location":"2022/Linux/Linux/#top","text":"","title":"top"},{"location":"2022/Linux/Linux/#network-time-protocol-ntp","text":"","title":"network time protocol ntp"},{"location":"2022/ModernCpp/CuriousUseOfTemplates/","text":"Curious Use of Templates Traditional Use of Templates Templates in C++ have existed for more than 20 years. Simply-put, we use templates to reuse code via compile-time inheritance. A simple example is a function which compares multiplies two numbers, say two doubles. And let's say we want to reuse the same code to multiply two integers. A template just hollow out the core logic into a generic function and allow it to be used by any data type. A simple example is as follows: template < typename T > T multiply(T a, T b) { return a * b; } int main() { assert(multiply(2,3) == 6); assert(multiply(2.0,3.1) == 6.2); // beware of floating point errors! } We can apply templates to entire classes as well using the same idea. That's all fine and dandy. But what's really interesting is a curious use of templates for solving parent-child relationship issues. Parent-Child Include Issues A very common problem in software is coding parent-child relationships. A parent keeps a pointer/reference to its child objects. But what if the child wants to make a callback to its parent? It'd keep a pointer/reference back to its parents. This leads to all kinds of dreadful cyclic header include issues. For example, the child class cannot include the parent class's header because the parent header file already includes the child header file. The traditional way of breaking this cyclic relationship is to use a 'forward reference'. Using Forward References Let's say a Parent class keeps a pointer to a Child - and the Child wants a pointer back to the Parent. It can be done this way in traditional C++: In Parent.h #pragma once #include \"Child.h\" class Parent { private : Child* c_; public : Parent() { c_ = new Child( this ); } }; And now in the Child's class declaration, it needs to tell the compiler that Parent exists, but the Child header cannot include the Parent header- or else this would lead to cyclic include errors. To get around this, the Child declaration - can contain a forward reference to a Parent. This tells the compiler- \"trust me, a Parent type exists, let the linker figure it out at link time.\" In Child.h #pragma once class Parent ; // forward reference to Parent class Child { private : Parent* p_; public : Child(Parent* p) : p_(p) { } }; This works. You can also use smart pointers in place of the raw pointers, but the pattern is the same. That is great. Only in moderm C++, we don't really want to use pointers too much. Why? If we stick to objects and references, we can always be sure a real object exists- and skip checking against nullptrs. Breaking includes with Templates Let's once again use a Parent-Child class relationship, but this time with NO pointers . We can do this with templates. Let's keep the same Parent-Child idea. This time, the Parent contains a Child, but a Child with full knowledge of what type of Parent it has. This is a wild idea- as we will see soon. The Parent class has two functions. The first function, WakeChild, tickles the Child. The second function, CallbackFromChild(), is used by the Child to callback the Parent. Here is the Parent declaration and definition: #pragma once #include \"Child.h\" class Parent { private : Child<Parent> c_; public : Parent() : c_(* this ) { } void WakeChild() { c_.WakeUp(); } void CallbackFromChild() { std::cout << \"Feed Child \\n \" ; } }; The Child class is much more interesting. The Child has a templated Parent type- so by definition at compile time, it knows the type of its Parent. The Child header does not even need to include the Parent's header. This is the entire beauty of using Templates to break Parent-Child build issues. #pragma once template < typename TParent > class Child { private : TParent& p_; public : Child(TParent& p) : p_(p) { } void WakeUp() { p_.CallbackFromChild(); } }; At compile time, the compiler ensures the parent type has a public method call CallbackFromChild while this Child class can call. To test this code, all that is needed is code like this: Parent p; p.WakeChild(); The Parent wakes the Child, which in turn, makes a call back to the Parent. The is no use of forward references, no use of pointers, and no issues with cyclic include headers. Brilliant. PL.20220531","title":"Curious Use of Templates"},{"location":"2022/ModernCpp/CuriousUseOfTemplates/#curious-use-of-templates","text":"","title":"Curious Use of Templates"},{"location":"2022/ModernCpp/CuriousUseOfTemplates/#traditional-use-of-templates","text":"Templates in C++ have existed for more than 20 years. Simply-put, we use templates to reuse code via compile-time inheritance. A simple example is a function which compares multiplies two numbers, say two doubles. And let's say we want to reuse the same code to multiply two integers. A template just hollow out the core logic into a generic function and allow it to be used by any data type. A simple example is as follows: template < typename T > T multiply(T a, T b) { return a * b; } int main() { assert(multiply(2,3) == 6); assert(multiply(2.0,3.1) == 6.2); // beware of floating point errors! } We can apply templates to entire classes as well using the same idea. That's all fine and dandy. But what's really interesting is a curious use of templates for solving parent-child relationship issues.","title":"Traditional Use of Templates"},{"location":"2022/ModernCpp/CuriousUseOfTemplates/#parent-child-include-issues","text":"A very common problem in software is coding parent-child relationships. A parent keeps a pointer/reference to its child objects. But what if the child wants to make a callback to its parent? It'd keep a pointer/reference back to its parents. This leads to all kinds of dreadful cyclic header include issues. For example, the child class cannot include the parent class's header because the parent header file already includes the child header file. The traditional way of breaking this cyclic relationship is to use a 'forward reference'.","title":"Parent-Child Include Issues"},{"location":"2022/ModernCpp/CuriousUseOfTemplates/#using-forward-references","text":"Let's say a Parent class keeps a pointer to a Child - and the Child wants a pointer back to the Parent. It can be done this way in traditional C++: In Parent.h #pragma once #include \"Child.h\" class Parent { private : Child* c_; public : Parent() { c_ = new Child( this ); } }; And now in the Child's class declaration, it needs to tell the compiler that Parent exists, but the Child header cannot include the Parent header- or else this would lead to cyclic include errors. To get around this, the Child declaration - can contain a forward reference to a Parent. This tells the compiler- \"trust me, a Parent type exists, let the linker figure it out at link time.\" In Child.h #pragma once class Parent ; // forward reference to Parent class Child { private : Parent* p_; public : Child(Parent* p) : p_(p) { } }; This works. You can also use smart pointers in place of the raw pointers, but the pattern is the same. That is great. Only in moderm C++, we don't really want to use pointers too much. Why? If we stick to objects and references, we can always be sure a real object exists- and skip checking against nullptrs.","title":"Using Forward References"},{"location":"2022/ModernCpp/CuriousUseOfTemplates/#breaking-includes-with-templates","text":"Let's once again use a Parent-Child class relationship, but this time with NO pointers . We can do this with templates. Let's keep the same Parent-Child idea. This time, the Parent contains a Child, but a Child with full knowledge of what type of Parent it has. This is a wild idea- as we will see soon. The Parent class has two functions. The first function, WakeChild, tickles the Child. The second function, CallbackFromChild(), is used by the Child to callback the Parent. Here is the Parent declaration and definition: #pragma once #include \"Child.h\" class Parent { private : Child<Parent> c_; public : Parent() : c_(* this ) { } void WakeChild() { c_.WakeUp(); } void CallbackFromChild() { std::cout << \"Feed Child \\n \" ; } }; The Child class is much more interesting. The Child has a templated Parent type- so by definition at compile time, it knows the type of its Parent. The Child header does not even need to include the Parent's header. This is the entire beauty of using Templates to break Parent-Child build issues. #pragma once template < typename TParent > class Child { private : TParent& p_; public : Child(TParent& p) : p_(p) { } void WakeUp() { p_.CallbackFromChild(); } }; At compile time, the compiler ensures the parent type has a public method call CallbackFromChild while this Child class can call. To test this code, all that is needed is code like this: Parent p; p.WakeChild(); The Parent wakes the Child, which in turn, makes a call back to the Parent. The is no use of forward references, no use of pointers, and no issues with cyclic include headers. Brilliant. PL.20220531","title":"Breaking includes with Templates"},{"location":"2022/ModernCpp/Guide/","text":"Street Fighting Guide to Modern C++ Map, operator< Unordered_map, hash Emplace, Emplace_Back When adding new objects to a collection such as a vector, in pre-C++11 days, a caller might create the object first and then insert or push_back this object into the vector. The STL container, owing to its value-semantics roots, makes a copy of the object. This duplicate copy is essentially a wasted effort. Why not just create the object in place, in the container itself? That is essentially the work of emplace and emplace_back. #include <iostream> #include <vector> #include <algorithm> #include <string> struct HeavyObject { std::string name; }; int main() { std::vector<HeavyObject> v; v.emplace_back(HeavyObject{ \"World\" }); auto iter = v.cbegin(); v.emplace(iter, HeavyObject{ \"Hello\" }); std::for_each(v.cbegin(), v.cend(), []( const HeavyObject& h) { std::cout << h.name << '\\n' ; }); return 0; } Hello World Try_Emplace Vectors can contain duplicate objects, whereas a map can only contain unique objects, each with a unique key. When emplace() tries insert a duplicate object into a map, STL finds the key already existing in the map- and destroys the newly created object. This is a waste of effort. Try_emplace() checks for an object's existence first and only creates a new object if it doesn't exist in the map. #include <iostream> #include <map> #include <string> struct HeavyObject { HeavyObject(std::string ln, std::string fn) : lname(ln), fname(fn) { std::cout << \"Created \" << lname << \" \" << fname << '\\n' ; } std::string lname, fname; }; int main() { std::map< int , HeavyObject> m; m.try_emplace(1, \"Mouse\" , \"Mickey\" ); m.try_emplace(1, \"Mouse\" , \"Mickey\" ); return 0; } Created Mouse Mickey Note the parameters passed into try_emplace() are perfectly forwarded to the mapped value's constructor. Perfect forwarding means the compiler passes on lvalues as lvalues and rvalues as rvalues. Piecewise Construction Sometimes we have a class with its copy constructor deleted . Why? Because we really just want one instance of this class. Or sometimes we want one instance for performance reasons. We don't want to worry about unncessary memory allocations and cleanups on the heap at runtime. If a class is not copy-constructible, and if we use it as a key in a map, we run into a problem. Using emplace or insert normally, we can't create this object as the key and use it in the map, because the map cannot take a copy of this key. This is where a map's piece_wise construction can be used to work around this non-copy-constructable key problem. Example below. #include <iostream> #include <map> #include <string> #include <utility> struct MyThing { MyThing(std::string ln, std::string fn) : lname(ln), fname(fn) { } MyThing( const MyThing&) = delete ; MyThing& operator = ( const MyThing&) = delete ; bool operator <( const MyThing& other) const { return (lname < other.lname && fname < other.fname); } std::string lname, fname; }; int main() { std::map<MyThing, int > m; // traditional c++98 style of inserting map items fails // when key object is not copy-constructable // auto item = std::pair<MyThing, int>(MyThing(\"Mouse\", \"Mickey\"), 1); // m.insert(item); // this also fails because we cannot create MyThing as a key // m.emplace(MyThing(\"Mouse\", \"Mickey\"),2); // this again fails because we cannot create MyThing as a key // m.emplace(\"Mouse\", \"Mickey\", 2); // C++17, this fails // m.try_emplace( \"Mouse\", \"Mickey\", 2); // C++17, this fails, fails to create a copy of MyThing // m.try_emplace( {\"Mouse\", \"Mickey\"}, 2); // C++11, this works, create key and values in-place separately m.emplace(std::piecewise_construct, std::forward_as_tuple( \"Mouse\" , \"Mickey\" ), std::forward_as_tuple(2) ); return 0; } Lambdas Lambdas are essentially nameless \"anonymous\" functions declared in the code right where they are invoked. Compared to functions or functors, this locality of declaration saves a lookup in the editor to the inner workings of the function. On the other hand, readability becomes an issue for overly long lambdas. A point of confusion is a lambda's capture clause of its definition. A lambda can capture values or references of variables on the stack for use inside its function. It can even capture a variable by way of a std::move operator (the original variable can no longer be used afterwards). Tip : use lambdas for short one-to-two liner functions. Example of a functor and an equivalent lambda. #include <iostream> #include <vector> #include <algorithm> struct OddChecker { void operator()( int i) { std::string tmp = (i & 1) ? \"odd\" : \"even\" ; std::cout << tmp << '\\n' ; } }; int main() { std::vector< int > v {0,1,2,3}; std::for_each(v.cbegin(), v.cend(), OddChecker()); std::for_each(v.cbegin(), v.cend(), []( int i) { std::string tmp = (i & 1) ? \"odd\" : \"even\" ; std::cout << tmp << '\\n' ; }); int bump = 3; std::string location( \"bump\" ); std::for_each(v.cbegin(), v.cend(), [bump, &location]( int i) { std::cout << location << \" \" << i+bump << '\\n' ; }); } even odd even odd even odd even odd bump 3 bump 4 bump 5 bump 6 Decltype Decltype is used mainly in template meta-programming. Decltype is used to get type of one variable for use to declare another variable. Example: float a = 2.0; decltype (a) b = a; This usage looks overly convoluted. Why not use auto instead? The only practical usage is in building template classes or functions. Example: #include <iostream> template < class T , class U > auto mul(T x, U y) -> decltype (x*y) { return x*y; } int main() { double a = 2.0; float b = 3.0; auto c = mul(a, b); std::cout << c << '\\n' ; } Function templates Class templates Type traits","title":"Street Fighting Guide to Modern C++"},{"location":"2022/ModernCpp/Guide/#street-fighting-guide-to-modern-c","text":"","title":"Street Fighting Guide to Modern C++"},{"location":"2022/ModernCpp/Guide/#map-operator","text":"","title":"Map, operator&lt;"},{"location":"2022/ModernCpp/Guide/#unordered_map-hash","text":"","title":"Unordered_map, hash"},{"location":"2022/ModernCpp/Guide/#emplace-emplace_back","text":"When adding new objects to a collection such as a vector, in pre-C++11 days, a caller might create the object first and then insert or push_back this object into the vector. The STL container, owing to its value-semantics roots, makes a copy of the object. This duplicate copy is essentially a wasted effort. Why not just create the object in place, in the container itself? That is essentially the work of emplace and emplace_back. #include <iostream> #include <vector> #include <algorithm> #include <string> struct HeavyObject { std::string name; }; int main() { std::vector<HeavyObject> v; v.emplace_back(HeavyObject{ \"World\" }); auto iter = v.cbegin(); v.emplace(iter, HeavyObject{ \"Hello\" }); std::for_each(v.cbegin(), v.cend(), []( const HeavyObject& h) { std::cout << h.name << '\\n' ; }); return 0; } Hello World","title":"Emplace, Emplace_Back"},{"location":"2022/ModernCpp/Guide/#try_emplace","text":"Vectors can contain duplicate objects, whereas a map can only contain unique objects, each with a unique key. When emplace() tries insert a duplicate object into a map, STL finds the key already existing in the map- and destroys the newly created object. This is a waste of effort. Try_emplace() checks for an object's existence first and only creates a new object if it doesn't exist in the map. #include <iostream> #include <map> #include <string> struct HeavyObject { HeavyObject(std::string ln, std::string fn) : lname(ln), fname(fn) { std::cout << \"Created \" << lname << \" \" << fname << '\\n' ; } std::string lname, fname; }; int main() { std::map< int , HeavyObject> m; m.try_emplace(1, \"Mouse\" , \"Mickey\" ); m.try_emplace(1, \"Mouse\" , \"Mickey\" ); return 0; } Created Mouse Mickey Note the parameters passed into try_emplace() are perfectly forwarded to the mapped value's constructor. Perfect forwarding means the compiler passes on lvalues as lvalues and rvalues as rvalues.","title":"Try_Emplace"},{"location":"2022/ModernCpp/Guide/#piecewise-construction","text":"Sometimes we have a class with its copy constructor deleted . Why? Because we really just want one instance of this class. Or sometimes we want one instance for performance reasons. We don't want to worry about unncessary memory allocations and cleanups on the heap at runtime. If a class is not copy-constructible, and if we use it as a key in a map, we run into a problem. Using emplace or insert normally, we can't create this object as the key and use it in the map, because the map cannot take a copy of this key. This is where a map's piece_wise construction can be used to work around this non-copy-constructable key problem. Example below. #include <iostream> #include <map> #include <string> #include <utility> struct MyThing { MyThing(std::string ln, std::string fn) : lname(ln), fname(fn) { } MyThing( const MyThing&) = delete ; MyThing& operator = ( const MyThing&) = delete ; bool operator <( const MyThing& other) const { return (lname < other.lname && fname < other.fname); } std::string lname, fname; }; int main() { std::map<MyThing, int > m; // traditional c++98 style of inserting map items fails // when key object is not copy-constructable // auto item = std::pair<MyThing, int>(MyThing(\"Mouse\", \"Mickey\"), 1); // m.insert(item); // this also fails because we cannot create MyThing as a key // m.emplace(MyThing(\"Mouse\", \"Mickey\"),2); // this again fails because we cannot create MyThing as a key // m.emplace(\"Mouse\", \"Mickey\", 2); // C++17, this fails // m.try_emplace( \"Mouse\", \"Mickey\", 2); // C++17, this fails, fails to create a copy of MyThing // m.try_emplace( {\"Mouse\", \"Mickey\"}, 2); // C++11, this works, create key and values in-place separately m.emplace(std::piecewise_construct, std::forward_as_tuple( \"Mouse\" , \"Mickey\" ), std::forward_as_tuple(2) ); return 0; }","title":"Piecewise Construction"},{"location":"2022/ModernCpp/Guide/#lambdas","text":"Lambdas are essentially nameless \"anonymous\" functions declared in the code right where they are invoked. Compared to functions or functors, this locality of declaration saves a lookup in the editor to the inner workings of the function. On the other hand, readability becomes an issue for overly long lambdas. A point of confusion is a lambda's capture clause of its definition. A lambda can capture values or references of variables on the stack for use inside its function. It can even capture a variable by way of a std::move operator (the original variable can no longer be used afterwards). Tip : use lambdas for short one-to-two liner functions.","title":"Lambdas"},{"location":"2022/ModernCpp/Guide/#example-of-a-functor-and-an-equivalent-lambda","text":"#include <iostream> #include <vector> #include <algorithm> struct OddChecker { void operator()( int i) { std::string tmp = (i & 1) ? \"odd\" : \"even\" ; std::cout << tmp << '\\n' ; } }; int main() { std::vector< int > v {0,1,2,3}; std::for_each(v.cbegin(), v.cend(), OddChecker()); std::for_each(v.cbegin(), v.cend(), []( int i) { std::string tmp = (i & 1) ? \"odd\" : \"even\" ; std::cout << tmp << '\\n' ; }); int bump = 3; std::string location( \"bump\" ); std::for_each(v.cbegin(), v.cend(), [bump, &location]( int i) { std::cout << location << \" \" << i+bump << '\\n' ; }); } even odd even odd even odd even odd bump 3 bump 4 bump 5 bump 6","title":"Example of a functor and an equivalent lambda."},{"location":"2022/ModernCpp/Guide/#decltype","text":"Decltype is used mainly in template meta-programming. Decltype is used to get type of one variable for use to declare another variable. Example: float a = 2.0; decltype (a) b = a; This usage looks overly convoluted. Why not use auto instead? The only practical usage is in building template classes or functions. Example: #include <iostream> template < class T , class U > auto mul(T x, U y) -> decltype (x*y) { return x*y; } int main() { double a = 2.0; float b = 3.0; auto c = mul(a, b); std::cout << c << '\\n' ; }","title":"Decltype"},{"location":"2022/ModernCpp/Guide/#function-templates","text":"","title":"Function templates"},{"location":"2022/ModernCpp/Guide/#class-templates","text":"","title":"Class templates"},{"location":"2022/ModernCpp/Guide/#type-traits","text":"","title":"Type traits"},{"location":"2022/ModernCpp/LowLatency/","text":"Low Latency Concepts RCU Reading a constant list scales almost linearly for additional threads. For a list that updates occasionally, still need to manage read-write race conditions. Using traditional read-write locks and atomics don't scale much because locks block. Multi cores may need to sync before and after writes. Every mutex/lock is heavy-weight and expensive. Core RCU idea Copy the old structure to a new structure Update the new structure (any concurrent readers still read from old structure) Update the global pointer to point to new structure. New readers read from new structure at this point. Sleep until last concurrent reader finishes reading old structure. Once kernel wakes this sleep, it is safe to deallocate old structure. DMA Direct Memory Access controller's job is to move data from different ports in/out of memory. This alleviates this job from the CPU- which can keep working on computing tasks- while the DMA does its job. The CPU tells the DMA the source and target of the data- and tell the DMA to send an interrupt when it's done. The cpu backs off from using the bus while the DMA moves data over the bus. The cpu just continues to work using its L1 and L2 caches. This period is called cycle stealing. RDMA Remote Direct Memory Access technology allows reading data from the memory of a remote machine- without using any CPU cycles of the host machine. This frees up CPU cycles of the host machine. The term zero copy often comes up. TCP copies data in and out of system buffers on both the client and server machines. RDMA moves data directly from the server machine to the client. RDMA bypasses kernel. TCP traffic relies on going thru the kernel stack and on the kernel scheduler. Downside- requires using new RDMA api calls. Kernel bypass solutions like Solarflare Onload and Mellanox requires no software changes. CPU architectures Sandy Bridge- 2011-2013, 32 nm, 64K L1, 256K L2 Ivy Bridge- 2012-2015, 22nm, 64K L1, 256K L2 Haswell- 2013-2022, 22nm, 64K L1, 256K L2 Broadwell- 2014-2018, 14nm, 64K L1, 256K L2 Skylake- 2015-2019, 14nm, 64K L1, 256K L2 Cannon Lake- 2018-2020, 10nm, 64K L1 per core, 256K L2 per core Cypress Cove- 2021-now, 10nm, 80K L1 per core Mesh? FPGA Field Programmable Gate Arrays- are circuits with programmable logic on NICs that operate directly on data coming in over the network. NTP Network Time Protocol. Accurate to 10ms (0.01 seconds). Client t0 t3 ----------------------------------------------> t1 t2 Time Server t0 = time client sends time request t1 = time server receives time request t2 = time server sends time reply t3 = time client receives 'time' from server The Time Server sends back to the Client a message packet containing t0, t1, and t2. The Client knows t3. We want to know how long it took the message to go from the Server to the Client- because once we know the time, we can figure out the real time. We get the travel time by averaging the times the messages spent traveling to and from the two machines. So we guess the one-way travel time (TT) as: TT = ((t1-t0) + (t3-t2)) / 2 So this means the time at point t3 should really be t2+TT Doing NTP in a feedback loop refines the time precision until the variability in time t3 goes under a certain threshold. PTP Precision Time Protocol. Similar idea to NTP but more accurate to 1us (0.000001 seconds). Caches L3 cache is a contended resource for multiple threads. Multiple cores share the same L3 cache. L2 cache is 256K for code and data- as of 2022. L1 cache","title":"Low Latency Concepts"},{"location":"2022/ModernCpp/LowLatency/#low-latency-concepts","text":"","title":"Low Latency Concepts"},{"location":"2022/ModernCpp/LowLatency/#rcu","text":"Reading a constant list scales almost linearly for additional threads. For a list that updates occasionally, still need to manage read-write race conditions. Using traditional read-write locks and atomics don't scale much because locks block. Multi cores may need to sync before and after writes. Every mutex/lock is heavy-weight and expensive. Core RCU idea Copy the old structure to a new structure Update the new structure (any concurrent readers still read from old structure) Update the global pointer to point to new structure. New readers read from new structure at this point. Sleep until last concurrent reader finishes reading old structure. Once kernel wakes this sleep, it is safe to deallocate old structure.","title":"RCU"},{"location":"2022/ModernCpp/LowLatency/#dma","text":"Direct Memory Access controller's job is to move data from different ports in/out of memory. This alleviates this job from the CPU- which can keep working on computing tasks- while the DMA does its job. The CPU tells the DMA the source and target of the data- and tell the DMA to send an interrupt when it's done. The cpu backs off from using the bus while the DMA moves data over the bus. The cpu just continues to work using its L1 and L2 caches. This period is called cycle stealing.","title":"DMA"},{"location":"2022/ModernCpp/LowLatency/#rdma","text":"Remote Direct Memory Access technology allows reading data from the memory of a remote machine- without using any CPU cycles of the host machine. This frees up CPU cycles of the host machine. The term zero copy often comes up. TCP copies data in and out of system buffers on both the client and server machines. RDMA moves data directly from the server machine to the client. RDMA bypasses kernel. TCP traffic relies on going thru the kernel stack and on the kernel scheduler. Downside- requires using new RDMA api calls. Kernel bypass solutions like Solarflare Onload and Mellanox requires no software changes.","title":"RDMA"},{"location":"2022/ModernCpp/LowLatency/#cpu-architectures","text":"Sandy Bridge- 2011-2013, 32 nm, 64K L1, 256K L2 Ivy Bridge- 2012-2015, 22nm, 64K L1, 256K L2 Haswell- 2013-2022, 22nm, 64K L1, 256K L2 Broadwell- 2014-2018, 14nm, 64K L1, 256K L2 Skylake- 2015-2019, 14nm, 64K L1, 256K L2 Cannon Lake- 2018-2020, 10nm, 64K L1 per core, 256K L2 per core Cypress Cove- 2021-now, 10nm, 80K L1 per core","title":"CPU architectures"},{"location":"2022/ModernCpp/LowLatency/#mesh","text":"","title":"Mesh?"},{"location":"2022/ModernCpp/LowLatency/#fpga","text":"Field Programmable Gate Arrays- are circuits with programmable logic on NICs that operate directly on data coming in over the network.","title":"FPGA"},{"location":"2022/ModernCpp/LowLatency/#ntp","text":"Network Time Protocol. Accurate to 10ms (0.01 seconds). Client t0 t3 ----------------------------------------------> t1 t2 Time Server t0 = time client sends time request t1 = time server receives time request t2 = time server sends time reply t3 = time client receives 'time' from server The Time Server sends back to the Client a message packet containing t0, t1, and t2. The Client knows t3. We want to know how long it took the message to go from the Server to the Client- because once we know the time, we can figure out the real time. We get the travel time by averaging the times the messages spent traveling to and from the two machines. So we guess the one-way travel time (TT) as: TT = ((t1-t0) + (t3-t2)) / 2 So this means the time at point t3 should really be t2+TT Doing NTP in a feedback loop refines the time precision until the variability in time t3 goes under a certain threshold.","title":"NTP"},{"location":"2022/ModernCpp/LowLatency/#ptp","text":"Precision Time Protocol. Similar idea to NTP but more accurate to 1us (0.000001 seconds).","title":"PTP"},{"location":"2022/ModernCpp/LowLatency/#caches","text":"L3 cache is a contended resource for multiple threads. Multiple cores share the same L3 cache. L2 cache is 256K for code and data- as of 2022. L1 cache","title":"Caches"},{"location":"2022/ModernCpp/MakeTips/","text":"Make Tips Makefile how-to The general format of the makefile is: target: dependency1 dependency2 <tab> command to build target target is what you want to build, eg: main.o dependency is when to rebuild target when dependency changes, eg: main.cpp command is the compiler command to build target, eg: g++ In Unix, g++ is both a compiler and a linker . Sample makefile: CXXFLAGS = -std=c++17 -Wall -O0 -g LDFLAGS = -lgtest -lgtest_main -lpthread # by default, the first target is the default target # # build the executable from the binary objects m03: memory_tests.o $( CXX ) $^ -o $@ $( LDFLAGS ) # g++ -o m03 memory_tests.o # # macro definitions # $@ = the target # $? = all pre-requisites newer than the target # #^ = all pre-requisites (dependencies) memory_tests.o: memory_tests.cpp # use make's default rule for building cpp into o # $(CXX) -c $(CPPFLAGS) $(CXXFLAGS) $^ -o $@ clean: rm -f *.o m03 Compiler flags C++ build command: g++ -o Standards: -std=c++11, -std=c++14, -std=c++17, -std=c++20 Verbosity: -Wall all warnings, -Werror warnings into error, -Wextra Compiler flags: -DFLAG, -DVAR=1 Optimisation: -O0 none, -O2, -O3 more optimisation Debugging: -g build with debugging symbols for gdb debugger Compile only: -c Linker flags Verbosity: -Wl Libraries: -lpthread include Posix threads library, -static-libstdc++","title":"Make Tips"},{"location":"2022/ModernCpp/MakeTips/#make-tips","text":"","title":"Make Tips"},{"location":"2022/ModernCpp/MakeTips/#makefile-how-to","text":"The general format of the makefile is: target: dependency1 dependency2 <tab> command to build target target is what you want to build, eg: main.o dependency is when to rebuild target when dependency changes, eg: main.cpp command is the compiler command to build target, eg: g++ In Unix, g++ is both a compiler and a linker . Sample makefile: CXXFLAGS = -std=c++17 -Wall -O0 -g LDFLAGS = -lgtest -lgtest_main -lpthread # by default, the first target is the default target # # build the executable from the binary objects m03: memory_tests.o $( CXX ) $^ -o $@ $( LDFLAGS ) # g++ -o m03 memory_tests.o # # macro definitions # $@ = the target # $? = all pre-requisites newer than the target # #^ = all pre-requisites (dependencies) memory_tests.o: memory_tests.cpp # use make's default rule for building cpp into o # $(CXX) -c $(CPPFLAGS) $(CXXFLAGS) $^ -o $@ clean: rm -f *.o m03","title":"Makefile how-to"},{"location":"2022/ModernCpp/MakeTips/#compiler-flags","text":"C++ build command: g++ -o Standards: -std=c++11, -std=c++14, -std=c++17, -std=c++20 Verbosity: -Wall all warnings, -Werror warnings into error, -Wextra Compiler flags: -DFLAG, -DVAR=1 Optimisation: -O0 none, -O2, -O3 more optimisation Debugging: -g build with debugging symbols for gdb debugger Compile only: -c","title":"Compiler flags"},{"location":"2022/ModernCpp/MakeTips/#linker-flags","text":"Verbosity: -Wl Libraries: -lpthread include Posix threads library, -static-libstdc++","title":"Linker flags"},{"location":"2022/ModernCpp/MultiplexedIO/","text":"Multiplexed IO Background Traditional I/O calls such as read() blocks on the call until data returns. If there is no data in a pipe, read() blocks. The traditional I/O model can work under two models- use a non-blocking I/O file descriptor use multple processes or threads When reading a non-block file descriptor of a pipe with no data, the read system call will return an error and not block. The reader can then continuously poll or poll intermittently. Both methods have problems. A continuous poll maxes out CPU usage while an intermittent poll introduces I/O latency. Using multiple processes or threads to perform the I/O and free up the parent process/thread can work- but this adds additional complexity in arranging communication between the processes and threads. For reading to/writing from multiple file descriptors, there are 4 methods: select() poll() signal driven I/O epoll()","title":"Multiplexed IO"},{"location":"2022/ModernCpp/MultiplexedIO/#multiplexed-io","text":"","title":"Multiplexed IO"},{"location":"2022/ModernCpp/MultiplexedIO/#background","text":"Traditional I/O calls such as read() blocks on the call until data returns. If there is no data in a pipe, read() blocks. The traditional I/O model can work under two models- use a non-blocking I/O file descriptor use multple processes or threads When reading a non-block file descriptor of a pipe with no data, the read system call will return an error and not block. The reader can then continuously poll or poll intermittently. Both methods have problems. A continuous poll maxes out CPU usage while an intermittent poll introduces I/O latency. Using multiple processes or threads to perform the I/O and free up the parent process/thread can work- but this adds additional complexity in arranging communication between the processes and threads. For reading to/writing from multiple file descriptors, there are 4 methods: select() poll() signal driven I/O epoll()","title":"Background"},{"location":"2022/ModernCpp/MultiplexedIO/#_1","text":"","title":""},{"location":"2022/Notes/most/","text":"The Most Important Thing A book on investment philosophy by Howard Marks. There is no one most important thing. Howard Mark's list of eighteen most important things are ALL important. They must be thought about all at the same time when investing. Investing is a complex activity. \"These are the guideposts that keep me on track.\" \"A philosophy has to be the sum of many ideas accumulated over a long period of time from a variety of sources. One cannot develop an effective philosophy wihtout having been exposed to life's lessons.\" In other words, one develops a style- or a philosophy- from wisdom. This is what makes each individual unique because everyone is exposed to different ideas over the course of one's lifetime. \"Experience is what you got when you didn't get what you wanted.\" In other words, one only learns from experiencing pain and failure. Second Level Thinking In investing, no single rule always works. The environment and circumstances never repeats exactly. (This reminds me of chaos theory where small differences in initial conditions generate huge differences in results over time.) Everyone can accomplish average investment returns- by investing in index funds. But successful investors want more. They want to beat the market. Millions compete in the market to generate superior returns, but not everyone can be superior. Who'd win? The ones who are a step ahead, the ones with superior insight and intution. This is the second level thinking. Others are well armed with information and computer algorithsm. To do better than average, you must have something they do not. You must be more right than others. You must be different . First level thinking is \"this company is good, let's buy it.\" Second level thinking is \"this company is good, let's buy it- but everyone knows it's a good company. It's overrated and overpriced, let's sell it.\" Second level thinking is deep, complex and convoluted. It sounds more like 3D chess- where you're thinking many moves ahead. First level thinking is the most simple and direct move, but SLT is thinking further down the horizon. The workload required for SLT is tremendously greater than for FLT. Conventional first level thinking, following the herd, leads to average to mediocre performance. Supeior performance requires thinking other than the consensus. It requires you to think different . First level thinkers think the same way the other first level thinkers do- and they reach the same conclusions. This cannot beat the market because collectively, they are the market. To achieve superior results, you have to hold nonconsensus (different) views regarding value and they have to be different. Agreeing with the broad view will not lead to superior results. Market Efficiency EMT (Efficient Market Theory) says there are many participants in the market with equal access to all relevant information. Their collection actions drive market prices to reflect all that is known in the market. Prices already reflect the consensus. Holding the consensus view then brings an average return. EMT states that superior returns can be achieved by taking on additional risks. Another ramification of EMT is to give up seeking for superior investments - just invest in a basket of assets, or an index. Howard Marks says EMT cannot be dismissed- and its conclusions are probably true for asset classes that are efficient- where information is publicly known for all investors. However, second level thinkers thrive on inefficiency. They must find an edge in information or analysis that no one else knows or believes. An inefficient market is a market that does not contain all known information and can be taken advantage of. No market is completely 100% efficient or 100% inefficient. The market efficiency dynamically ranges in between extremes at all times. A market can be inefficient at times- and that's when opportunities sprout up. But at those times, you have to ask questions such as - why haven't others picked up and acted on the same information or analysis? \"I should limit my efforts to relatively inefficient markets where hard work and skill would pay off best.\" Value Howard Marks doesn't believe in technical analysis or momentum investing. \"Value investors score their biggest gains when they buy an underpriced asset, average down unfailingly and have their analysis proved out. Thus, there are two essential ingredients for profit in a declining market: you have to have a view on intrinsic value, and you have to hold that view strongly enough to be able to hang in and buy even as price declines suggest that you're wrong. And third: you have to be right\" Price and Value Let's say you're able to come up with an estimate of intrinsic value for a stock or other asset. Let's even say your estimate is right. You're not done. In order to know what action to take, you have to look at the asset's price relative to its value.\" Howard Marks mentions a investor psychology as a power factor on price. \"Investor psychology can cause a security to be priced just about anywhere in the short run, regardless of its fundamentals.\" \"The key is who likes the investment now and who doesn't. Future price changes will be determined by whether it comes to be liked by more people or fewer people in the future.\" \"Investing is a popularity contest, and the most dangerous thing is to buy something at the peak of its popularity. At that point, all favorable facts and opinions are already factored into its price, and no new buyers are left to emerge.\" Understanding Risk \"Theory says high return is associated with high risk because the former exists to compensate for the latter. But pragmatic value investors feel just the opposite. They believe high return and low risk can be achieved simulatenously by buying things for less than they're worth. In the same way, overpaying implies both low return and high risk.\" Let's aim for buying something with good value at a low price. \"Riskier investments are those for which the outcome is less certain. That is, the probabily distribution of returns is wider. When priced fairly, riskier investments should entail: - higher expected returns - the possibility of lower returns, and - in some cases, the possibility of losses\" The traditional graph where higher risk means higher returns is not totally correct. A high return for higher risk is only one possible outcome for a range of possible outcomes. Other possible outcomes are higher losses. A higher risk asset has a wider range of possible outcomes. \"The most common bell-shaped distrbiution is called the 'normal' distribution. However, people often use the terms bell-shaped and normal interchangeably and they're not the same. The former is a general type of distribution, while the latter is a specific bell-shaped distribution with very definite statistical properties.\" \"In the years leading up to the crisis, financial engineers, or 'quants' played a big part in creating and evaluating financial products such as deriatvies and structured entitites. In many cases they made the assumption that future events would be normally distributed. But the normal distribution assumed events in the distant tails will happen extremely infrequently, while the distribution of financial developments- shaped by humans, with their tendancy to go to emotion-driven extremes of behavior- should probably be seen as having 'fatter' tails. Thus, when widespread mortgage defaults began to occur, events thought to be unlikely befell mortgage-related vehicles on a regular basis. Investors in vehicles that had been constructed on the basis of normal-distributions, without much allowance for 'tail events' (black swans) often saw the wheels come off. Investors run for the exits at the same time, and that's when extremes happen. This almost relates to the motion of fluids or people in crowded streets. When both achieve a critical mass, disasters happen. \"There's a big difference between probability and outcome. Probable things fail to happen- and improbable things happen- all the time.\" \"Most people view risk taking primarily as a way to make money. Bearing higher risk generally produces higher returns. The market has set things up to look like that'll be the case; if it didn't, people wouldn't make risky investments. But it can't always work that way, or else risky investments wouldn't be risky. And when risk bearing doesn't work, it really doesn't work, and people are reminded what risk's all about.\" Recognizing Risk \"Risk means uncertainty about which outcome will occur and the possibility of loss when the unfavorable ones do.\" High risk comes from paying too much- when the market sentiment is extremely bullish. This means there is less risk when paying far from the top. \"The risk-is-gone myth is one of the most dangerous sources of risk and a major contributor to any bubble. At the extreme of the pendulums's upswing, the belief that risk is low and that the investment in question is sure to produce profits intoxicates the herd and cuases its members to forget caution, worry and fear of loss, and instead to obsess about the risk of missing opportunity.\" This comment is true for every bubble and subsequent crash. \"The recent crisis came about primarily because investors partook of novel, complex and dangerous things, in greater amounts than ever before. They took on too much leverage and committed too much capital to illiquid investments. Why did they do these things? It all happened because investors believed too much, worried too little, and thus took too much risk. In short, they believed they were living in a low-risk world.\" \"When everyone believes something embodies no risk, they usually bid it up to the point where it's enormously risky. No risk is feared, and thus no reward for risk bearing- no 'risk premium'- is demanded or provided. That can make the thing that's most esteemed the riskiest.","title":"The Most Important Thing"},{"location":"2022/Notes/most/#the-most-important-thing","text":"A book on investment philosophy by Howard Marks. There is no one most important thing. Howard Mark's list of eighteen most important things are ALL important. They must be thought about all at the same time when investing. Investing is a complex activity. \"These are the guideposts that keep me on track.\" \"A philosophy has to be the sum of many ideas accumulated over a long period of time from a variety of sources. One cannot develop an effective philosophy wihtout having been exposed to life's lessons.\" In other words, one develops a style- or a philosophy- from wisdom. This is what makes each individual unique because everyone is exposed to different ideas over the course of one's lifetime. \"Experience is what you got when you didn't get what you wanted.\" In other words, one only learns from experiencing pain and failure.","title":"The Most Important Thing"},{"location":"2022/Notes/most/#second-level-thinking","text":"In investing, no single rule always works. The environment and circumstances never repeats exactly. (This reminds me of chaos theory where small differences in initial conditions generate huge differences in results over time.) Everyone can accomplish average investment returns- by investing in index funds. But successful investors want more. They want to beat the market. Millions compete in the market to generate superior returns, but not everyone can be superior. Who'd win? The ones who are a step ahead, the ones with superior insight and intution. This is the second level thinking. Others are well armed with information and computer algorithsm. To do better than average, you must have something they do not. You must be more right than others. You must be different . First level thinking is \"this company is good, let's buy it.\" Second level thinking is \"this company is good, let's buy it- but everyone knows it's a good company. It's overrated and overpriced, let's sell it.\" Second level thinking is deep, complex and convoluted. It sounds more like 3D chess- where you're thinking many moves ahead. First level thinking is the most simple and direct move, but SLT is thinking further down the horizon. The workload required for SLT is tremendously greater than for FLT. Conventional first level thinking, following the herd, leads to average to mediocre performance. Supeior performance requires thinking other than the consensus. It requires you to think different . First level thinkers think the same way the other first level thinkers do- and they reach the same conclusions. This cannot beat the market because collectively, they are the market. To achieve superior results, you have to hold nonconsensus (different) views regarding value and they have to be different. Agreeing with the broad view will not lead to superior results.","title":"Second Level Thinking"},{"location":"2022/Notes/most/#market-efficiency","text":"EMT (Efficient Market Theory) says there are many participants in the market with equal access to all relevant information. Their collection actions drive market prices to reflect all that is known in the market. Prices already reflect the consensus. Holding the consensus view then brings an average return. EMT states that superior returns can be achieved by taking on additional risks. Another ramification of EMT is to give up seeking for superior investments - just invest in a basket of assets, or an index. Howard Marks says EMT cannot be dismissed- and its conclusions are probably true for asset classes that are efficient- where information is publicly known for all investors. However, second level thinkers thrive on inefficiency. They must find an edge in information or analysis that no one else knows or believes. An inefficient market is a market that does not contain all known information and can be taken advantage of. No market is completely 100% efficient or 100% inefficient. The market efficiency dynamically ranges in between extremes at all times. A market can be inefficient at times- and that's when opportunities sprout up. But at those times, you have to ask questions such as - why haven't others picked up and acted on the same information or analysis? \"I should limit my efforts to relatively inefficient markets where hard work and skill would pay off best.\"","title":"Market Efficiency"},{"location":"2022/Notes/most/#value","text":"Howard Marks doesn't believe in technical analysis or momentum investing. \"Value investors score their biggest gains when they buy an underpriced asset, average down unfailingly and have their analysis proved out. Thus, there are two essential ingredients for profit in a declining market: you have to have a view on intrinsic value, and you have to hold that view strongly enough to be able to hang in and buy even as price declines suggest that you're wrong. And third: you have to be right\"","title":"Value"},{"location":"2022/Notes/most/#price-and-value","text":"Let's say you're able to come up with an estimate of intrinsic value for a stock or other asset. Let's even say your estimate is right. You're not done. In order to know what action to take, you have to look at the asset's price relative to its value.\" Howard Marks mentions a investor psychology as a power factor on price. \"Investor psychology can cause a security to be priced just about anywhere in the short run, regardless of its fundamentals.\" \"The key is who likes the investment now and who doesn't. Future price changes will be determined by whether it comes to be liked by more people or fewer people in the future.\" \"Investing is a popularity contest, and the most dangerous thing is to buy something at the peak of its popularity. At that point, all favorable facts and opinions are already factored into its price, and no new buyers are left to emerge.\"","title":"Price and Value"},{"location":"2022/Notes/most/#understanding-risk","text":"\"Theory says high return is associated with high risk because the former exists to compensate for the latter. But pragmatic value investors feel just the opposite. They believe high return and low risk can be achieved simulatenously by buying things for less than they're worth. In the same way, overpaying implies both low return and high risk.\" Let's aim for buying something with good value at a low price. \"Riskier investments are those for which the outcome is less certain. That is, the probabily distribution of returns is wider. When priced fairly, riskier investments should entail: - higher expected returns - the possibility of lower returns, and - in some cases, the possibility of losses\" The traditional graph where higher risk means higher returns is not totally correct. A high return for higher risk is only one possible outcome for a range of possible outcomes. Other possible outcomes are higher losses. A higher risk asset has a wider range of possible outcomes. \"The most common bell-shaped distrbiution is called the 'normal' distribution. However, people often use the terms bell-shaped and normal interchangeably and they're not the same. The former is a general type of distribution, while the latter is a specific bell-shaped distribution with very definite statistical properties.\" \"In the years leading up to the crisis, financial engineers, or 'quants' played a big part in creating and evaluating financial products such as deriatvies and structured entitites. In many cases they made the assumption that future events would be normally distributed. But the normal distribution assumed events in the distant tails will happen extremely infrequently, while the distribution of financial developments- shaped by humans, with their tendancy to go to emotion-driven extremes of behavior- should probably be seen as having 'fatter' tails. Thus, when widespread mortgage defaults began to occur, events thought to be unlikely befell mortgage-related vehicles on a regular basis. Investors in vehicles that had been constructed on the basis of normal-distributions, without much allowance for 'tail events' (black swans) often saw the wheels come off. Investors run for the exits at the same time, and that's when extremes happen. This almost relates to the motion of fluids or people in crowded streets. When both achieve a critical mass, disasters happen. \"There's a big difference between probability and outcome. Probable things fail to happen- and improbable things happen- all the time.\" \"Most people view risk taking primarily as a way to make money. Bearing higher risk generally produces higher returns. The market has set things up to look like that'll be the case; if it didn't, people wouldn't make risky investments. But it can't always work that way, or else risky investments wouldn't be risky. And when risk bearing doesn't work, it really doesn't work, and people are reminded what risk's all about.\"","title":"Understanding Risk"},{"location":"2022/Notes/most/#recognizing-risk","text":"\"Risk means uncertainty about which outcome will occur and the possibility of loss when the unfavorable ones do.\" High risk comes from paying too much- when the market sentiment is extremely bullish. This means there is less risk when paying far from the top. \"The risk-is-gone myth is one of the most dangerous sources of risk and a major contributor to any bubble. At the extreme of the pendulums's upswing, the belief that risk is low and that the investment in question is sure to produce profits intoxicates the herd and cuases its members to forget caution, worry and fear of loss, and instead to obsess about the risk of missing opportunity.\" This comment is true for every bubble and subsequent crash. \"The recent crisis came about primarily because investors partook of novel, complex and dangerous things, in greater amounts than ever before. They took on too much leverage and committed too much capital to illiquid investments. Why did they do these things? It all happened because investors believed too much, worried too little, and thus took too much risk. In short, they believed they were living in a low-risk world.\" \"When everyone believes something embodies no risk, they usually bid it up to the point where it's enormously risky. No risk is feared, and thus no reward for risk bearing- no 'risk premium'- is demanded or provided. That can make the thing that's most esteemed the riskiest.","title":"Recognizing Risk"},{"location":"about/bio/","text":"Patrick Leung is a native of Hong Kong, China. Patrick specialises in building electronic trading engines in C++ and risk analytics in C# for financial firms. Patrick currently resides in Singapore and enjoys the lush forest greenery when not in the office. He also enjoys a good game of table tennis and runs around Bedok Resevoir. Patrick is a graduate of Stuyvesant High School in NYC, the Cooper Union School of Engineering and the Lubin School of Business. Patrick can be reached via twitter @patrickleungwl or via email at patrickleungwl @ gmail.com.","title":"Bio"},{"location":"archives/2014/2014-03-11-weakreferences-in-java/","tags":"java, memory","text":"Java as a language has been in the public eye for close to two decades now. And there shouldn't really be anything new to an old techie, should there? Well, surprise to say- there are some features that I rarely use. One of these features is the \"WeakReference\". What are WeakReferences used for? WeakReferences are used for keeping objects in memory for only as long as a variable references it. As soon as this strong reference disappears, this object held by the WeakReference is up for garbage collection. This makes WeakReferences quite handy for keeping high storage-cost objects in memory for only as long as you really need it. Example, let's make a dummy class that does nothing but make heavy memory allocations: package drills ; import java.util.ArrayList ; public class DumbWeight { private ArrayList<Integer> _weights; public DumbWeight( int weight) { _weights = new ArrayList<Integer>(weight); for ( int i=0; i<weight; i++) { _weights.add( new Integer(i)); } } } And here is the test code. The test code creates a thousand \"DumbWeight\" objects- each allocating one hundred thousand Integers. While the WeakReferences keep track of the DumbWeights, we remove any strong references to them. This leaves the WeakReference as the only link to the DumbWeights. The Garbage Collector eventually spots this- and wipes out the DumbWeights over time. The CheckReferences method periodically scans the set of WeakReferences to see if the DumbWeights still exist. package drills ; import java.lang.ref.* ; import java.util.* ; public class MyTest { /** checkWeakReferences * * Check how many weak references still exist and not collected */ private void checkWeakReferences(Set<WeakReference> s) { int numCollected = 0; Iterator<WeakReference> i = s.iterator(); while (i.hasNext()) { WeakReference w = i.next(); DumbWeight d = w.get(); if (d== null ) { ++numCollected; } } System.out.format( \"checkWeakRefs: size=%d, numCollected=%dn\" , s.size(), numCollected ); } /** testWeakReferences * * If the GC collects weak references, then we should be * able to create objects using WR indefinitely. * public void testWeakReferences() { Set<WeakReference> s = new HashSet<WeakReference>(); System.out.println( \"*****************************\" ); System.out.println( \"Starting testWeakReferences\" ); System.out.println( \"Creating 1000 weak references\" ); for ( int i=0; i&lt;1000; i++) { DumbWeight d = new DumbWeight(100000); WeakReference w = new WeakReference(d); s.add(w); d = null ; if (s.size()%100==0) { checkWeakReferences(s); } } System.out.println( \"Completed testWeakReferences\" ); } public static void main(String[] args) { MyTest m = new MyTest(); m.testWeakReferences(); } } The output of one such test run is shown below. The memory usage of this Test app stays in the 220 meg range on a Linux laptop with 2Gb RAM. ***************************** Starting testWeakReferences Creating 1000 weak references checkWeakRefs: size=100, numCollected=98 checkWeakRefs: size=200, numCollected=182 checkWeakRefs: size=300, numCollected=235 checkWeakRefs: size=400, numCollected=318 checkWeakRefs: size=500, numCollected=489 checkWeakRefs: size=600, numCollected=576 checkWeakRefs: size=700, numCollected=663 checkWeakRefs: size=800, numCollected=750 checkWeakRefs: size=900, numCollected=837 checkWeakRefs: size=1000, numCollected=924 Completed testWeakReferences As shown, because the objects, the DumbWeight instances, are only \"weakly referenced\" and not strongly referenced, the GC always collects them whenever it runs. Hope the test code makes clear this feature of WeakReference.","title":"WeakReferences in Java"},{"location":"archives/2014/2014-03-13-weakreferences-in-csharp/","tags":"csharp, memory","text":"Overheard Microsoft taunting Oracle the other day- \"Anything you can do, I can do better.\" 8-) When it comes to memory management, C# certainly has many comparable features found in Java and more. Following the previous example of testing WeakReferences in Java, we'll now run a similar test in C#. First, we'll need a dummy memory resource-heavy object. We'll use the same DumbWeight class, whose sole function is to allocate memory. using System.Collection.Generic ; namespace Drills { class DumbWeight { private List< int > _weights; public DumbWeight( int weight) { _weights = new List< int >(weight); for ( int i=0; i<weight; i++) { _weights.Add(i); } } } } And once again, we run our test by 1) creating a thousand DumbWeight instances, 2) maintain a set of WeakReferences pointing to these DumbWeight instances, 3) free up any strong (direct) references to the DumbWeights, and 4) watch what happens over time. using System ; using System.Collections.Generic ; namespace Drills { class MyTest { //---------------------------------------------------------- // Checks how many objects referenced by WeakReferences are // still alive- not yet collected by the GC. // private void checkWeakReferences(List< int > ltWeakRefs) { int numCollecte=0; foreach (WeakReference w in ltWeakRefs) { if (!w.IsAlive) ++numCollected; } Console.Out.WriteLine( \"checkWeakRefs: size={0}, numCollected={1}\" , ltWeakRefs.Count, numCollected); } //---------------------------------------------------------- // Create a thousand objects pointed to only by WeakReferences. // Every once in a while, scan the WeakReferences to see // if their referenced objects still exist or have been collected. // public void testWeakReferences() { List< int > ltWeakRefs = new List< int >(); for ( int i=0; i<1000; i++ ) { DumbWeight d = new DumbWeight(100000); WeakReference w = new WeakReference(d); ltWeakRefs.Add(w); d = null ; if (s.Count % 100 == 0) checkWeakReferences(ltWeakRefs); } Console.Out.WriteLine( \"Completed testWeakReferences\" ); } static void Main( string [] args) { MyTest t = new MyTest(); t.testWeakReferences(); } } } The test app's output looks like the following: checkWeakRefs: size=100, numCollected=96 checkWeakRefs: size=200, numCollected=192 checkWeakRefs: size=300, numCollected=296 checkWeakRefs: size=400, numCollected=392 checkWeakRefs: size=500, numCollected=496 checkWeakRefs: size=600, numCollected=592 checkWeakRefs: size=700, numCollected=696 checkWeakRefs: size=800, numCollected=792 checkWeakRefs: size=900, numCollected=896 checkWeakRefs: size=1000, numCollected=992 The results show that C#'s WeakReference works just like Java's. The only noticeable difference is that C# offers you a way to check the existence of the WeakReference's refent using its IsAlive property. In Java, the way to check a WeakReference's refent is by getting calling get() to get its contained object and checking for null. C#'s way seems more elegant although functionally there is no difference.","title":"WeakReferences in CSharp"},{"location":"archives/2014/2014-03-15-garbage-collector-differences/","tags":"java, csharp, memory","text":"More on our old friend, the Garbage Collector- also known on the streets as the 'GC'. Common Default Behavior At indeterminate times, the GC comes around, finds and frees up every unreferenced object- these are objects that cannot be traced to a long living root object every object referenced only by a WeakReference and- for Java only- if free memory is low, every object referenced only by a SoftReference C# Has No SoftReferences C# does not have SoftReferences. Why this is so? Two leading theories on StackOverflow say Java has four levels of reference strength- (strong, soft, weak, and phantom)- and that's way too confusing. C# just keeps it simple at two- strong and weak. Nice. On 32-bit Windows platforms, C#, unlike Java, uses an entire process' addressable memory space- 4GB. It's 2GB in practical terms because the OS/kernal claims usage on the other 2GB, but it's also possible to push the user space limits to 3GB using boot flags. With more memory at is disposal, C# apps are less likely than Java apps to struggle for memory- which is how SoftReferences are likely to be used.With Java on Linux, the way to find the maxium heap size is via: java -XX:+PrintFlagsFinal -version | grep i maxheapsize When Is the Garbage Collector Coming? In C#, it is not uncommon to see code explicitly requesting a garbage collection. The GC collects immediately at the point in the code. In Java however, the GC collection call is only a request. The GC alays collects at an indeterminate time in the future.","title":"Garbage Collector Differences between Java and CSharp"},{"location":"archives/2014/2014-03-15-garbage-collector-differences/#common-default-behavior","text":"At indeterminate times, the GC comes around, finds and frees up every unreferenced object- these are objects that cannot be traced to a long living root object every object referenced only by a WeakReference and- for Java only- if free memory is low, every object referenced only by a SoftReference","title":"Common Default Behavior"},{"location":"archives/2014/2014-03-15-garbage-collector-differences/#c-has-no-softreferences","text":"C# does not have SoftReferences. Why this is so? Two leading theories on StackOverflow say Java has four levels of reference strength- (strong, soft, weak, and phantom)- and that's way too confusing. C# just keeps it simple at two- strong and weak. Nice. On 32-bit Windows platforms, C#, unlike Java, uses an entire process' addressable memory space- 4GB. It's 2GB in practical terms because the OS/kernal claims usage on the other 2GB, but it's also possible to push the user space limits to 3GB using boot flags. With more memory at is disposal, C# apps are less likely than Java apps to struggle for memory- which is how SoftReferences are likely to be used.With Java on Linux, the way to find the maxium heap size is via: java -XX:+PrintFlagsFinal -version | grep i maxheapsize","title":"C# Has No SoftReferences"},{"location":"archives/2014/2014-03-15-garbage-collector-differences/#when-is-the-garbage-collector-coming","text":"In C#, it is not uncommon to see code explicitly requesting a garbage collection. The GC collects immediately at the point in the code. In Java however, the GC collection call is only a request. The GC alays collects at an indeterminate time in the future.","title":"When Is the Garbage Collector Coming?"},{"location":"archives/2014/2014-03-17-delayed_background/","tags":"java, threads","text":"With Java 1.5, if you want a function to execute at a certain time in the future, it is no longer necessary to create timers and callbacks. Java 1.5 has a ExecutorService that can execute tasks at scheduled times. Below shows a quick example of how it can be used. package drills ; import java.text.DateFormat ; import java.text.SimpleDateFormat ; import java.util.Calendar ; import java.util.Date ; import java.util.concurrent.Executors ; import java.util.concurrent.ScheduledExecutorService ; import java.util.concurrent.TimeUnit ; public class Tester { DateFormat _df; public Tester() { _df = new SimpleDateFormat( \"yyyyMMdd HH:mm:ss\" ); } public String GetTimeNow() { Date dt = new Date(); return _df.format(dt); } public void RunTest() { Runnable worker = new Runnable() { public void run() { System.out.format( \"%s: Worker running\\n\" , GetTimeNow()); } }; ScheduledExecutorService ex = Executors.newSingleThreadScheduledExecutor(); System.out.format( \"%s: Scheduled worker to run in 5 seconds\\n\" , GetTimeNow()); ex.schedule(worker, 5, TimeUnit.SECONDS); try { Thread.sleep(10000); } catch (Exception e) { // Even if interrupted exception is thrown during sleep, keep going } System.out.println( \"Test completed\" ); } public static void main(String[] args) { Tester t = new Tester(); t.RunTest(); } } The test app output looks like this: 20140317 23:56:53: Scheduled worker to run in 5 seconds 20140317 23:56:58: Worker running Test completed","title":"Delayed Background Thread Runnable"},{"location":"archives/2014/2014-03-20-java-assertions/","tags":"java, threads","text":"Ran into a puzzle the other day. My assertions in Java were not working. That was a puzzle- since assertions always worked in C#. Turns out- assertions in Java are turned off by default. To enable assertions, one must execute the Java class with -ea. Example: java -ea Test.java","title":"Assertions in Java"},{"location":"archives/2014/2014-03-20-java-string-literals/","tags":"java, memory","text":"Strings in Java can be declared either literally- String s = \"123\"; or as a String instance- String s = new String(\"123\"); What are the differences between these two strings? package drills ; public class Tester { public static void main(String[] args) { // Test differences between String v = new String(...) // and String v = \"...\" // String literals are stored in a string pool- cached and reused. // String objects are stored in the heap as new objects. // Two string literals with the same characters are the same // in every possible way. String s1 = \"abcdef\" ; String s2 = \"abcdef\" ; assert (s1 == s2); assert (s1.hashCode() == s2.hashCode()); assert (s1.equals(s2) && s2.equals(s1)); // Two string objects with the same characters are the same // only with hashCode() and equals()- but are different object // instances String s3 = new String( \"abcdef\" ); String s4 = new String( \"abcdef\" ); assert (s3 != s4); assert (s3.hashCode() == s4.hashCode()); assert (s3.equals(s4) && s4.equals(s3)); // String literals and String objects are separate string // instances, but hashCodes are all equal assert (s1 != s3 &amp;&amp; s1 != s4); assert (s1.hashCode() == s2.hashCode()); assert (s2.hashCode() == s3.hashCode()); assert (s3.hashCode() == s4.hashCode()); // Though separate instances, contents are also still equal assert (s1.equals(s3) && s1.equals(s4)); assert (s2.equals(s3) && s2.equals(s4)); System.out.println( \"Tests completed\" ); } } Summary: Regardless of how strings are declared, for a given character sequence, their hashCodes() and equals() all return the same value. String literals reuse the same string instance if already exists. String objects always create a new instance (unless using the intern method).","title":"Java String Literals Versus String Objects"},{"location":"archives/2014/2014-03-21-exceptions-in-java-constructors/","tags":"java, memory","text":"This connundrum always troubled me when I coded in C++. What happens to an object when the object's constructor throws an exception? Is the object fully constructed or not? If not, does that mean its destructor never gets called? If so, then what happens to the memory that the constructor allocated prior to coming across an exception? In C++, there was the problem of leaky memory if constructors are prone to exceptions. This led to remembering to keep constructors light and simple- because a half-constructor object is not fully constructed and its destructor will not get called- leaving this half-constructed object to leak already allocated memory. Does Java have this half-constructed memory leak problem? Thinking this for a bit- the answer is no- because Java keeps objects in a managed memory heap. Whatever objects are not referenced by root objects get collected by the GC. So, constructors throwing exceptions should pose no problems in Java, correct? Only a test case can tell for sure. package drills ; import java.util.ArrayList ; public class Tester { // If a constructor allocates huge amount of memory // then throws an exception // does the GC collect that memory? // // We'll create 10,000 dummy Tester class objects- // each allocating huge chunks of memory. // // Will the test program complete all 10,000 object // creations? private ArrayList<Integer> _a; public Tester() { _a = new ArrayList<Integer>(); for ( int i=0; i<1000000; i++) { _a.add(i); } int j = 10/0; } public static void main(String[] args) { for ( int i=0; i<10000; i++) { try { Tester d = new Tester(); } catch (Exception e) { if (i%1000==0) System.out.println(i); } } System.out.println( \"Test completed\" ); } } The output shows: 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 Test completed Proved. No memory leaks given exceptions in Java contructors.","title":"Exceptions in Java Constructors"},{"location":"archives/2014/2014-03-22-searching-for-primes-with-c/","tags":"c, primes","text":"As a software developer, I regularly do drills with different languages. This is rather analogous to how musicians play scales with their instructions. This past weekend, I brushed off some C cobwebs with a quick exercise to find prime numbers using the Sieve of Eratosthenes. I remember from Jon Bentley's \"Programming Pearls\" - back in the old days- when 64K RAM was considered a luxury, programmers came up with ingenius algorithms to conserve memory usage. I remember bit arrays were one fairly frugal data structures. I took it for a spin with the following prime search. #include \"stdio.h\" #include \"string.h\" #include \"ctype.h\" #include \"malloc.h\" #include \"math.h\" #include \"assert.h\" /* Show primes using Sieve of Eratosthenes */ void show_bits( unsigned n) { int i; for (i=( sizeof ( int )*8)-1; i>0; i--) { (n&(1<<i)) ? putchar( '1' ) : putchar( '0' ); } printf( \" \\n \" ); } // is number u already marked? // lookup our bit index map // returns 1 if true // 0 if false int is_bit_marked( unsigned *nums, unsigned u) { unsigned bytenum = u / 32.0; unsigned offset = u % 32; //printf( \"is_bit_marked: %u, byte %u, bit %u\\n\", u, bytenum, offset ); unsigned selected_byte = nums[bytenum]; unsigned mask = 0x01; mask = mask << offset; // rightshift offset times //printf( \"before mask: \" ); //show_bits(selected_byte); //printf( \"after mask: \" ); selected_byte &= mask; // and operation //show_bits(selected_byte); return ( selected_byte > 0 ); } // given a number, find the byte and offset (the bit index) that // represents the number. // void mark_bit( unsigned *nums, unsigned u) { unsigned bytenum = u / 32.0; unsigned offset = u % 32; //printf( \"mark_bit: %u, byte %u, bit %u\\n\", u, bytenum, offset ); unsigned mask = 0x01; mask = mask << offset; // rightshift offset times nums[bytenum] |= mask; //show_bits(selected_byte); } int main() { unsigned x, y = 0; printf( \"Length of unsigned %i \\n\\n \" , sizeof ( unsigned )); // 32 bits per unsigned // to check for primes up to 1024*1024, // we'd need 1024*1024/32 unsigned variables // = 32,768 or 32k // unsigned space_needed = 32768*16; unsigned nums[space_needed]; memset(nums,0x00,space_needed); // test our functions mark_bit(nums, 10); mark_bit(nums, 200); assert( is_bit_marked(nums, 2)==0 ); assert( is_bit_marked(nums,24)==0 ); assert( is_bit_marked(nums,300)==0 ); assert( is_bit_marked(nums,10)==1 ); assert( is_bit_marked(nums,200)==1 ); // continue on with main program memset(nums,0x00,space_needed); unsigned t=2; unsigned maxnum = 16*1024*1024; for (t=2; t<maxnum; t++) { //printf(\"Checking %u\\n\", t); if (is_bit_marked(nums,t)==1) continue ; // mark every mutiple of t, but not t itself unsigned i=t+t; while (i<maxnum) { mark_bit(nums, i); i+=t; } } int printed=0; for ( int t=2; t<maxnum; t++) { if (is_bit_marked(nums,t)==0) { printf( \"%10u\" , t); ++printed; } if (printed>4) { printed=0; printf( \" \\n \" ); } } printf( \" \\n \" ); }","title":"Searching for Primes with C"},{"location":"archives/2014/2014-03-24-decorator-pattern-in-plain-speak/","tags":"patterns","text":"I've just had enough of the abstract high-faluting language used in the GOF's Design Patterns. Absolutely enough . I'm sure there's more than enough readers who can't understand any one of the GOF's denser patterns. The Decorator Pattern is one such dense connundrum. I mean- just give it to me straight what does it do? why use it? how to build it? In plain terms, if there is a need to add functionality to a class instance (object)- without changing its inherent behavior, then it's a scenario to use a Decorator pattern. For adding functionality to a class, why not use inheritance or adding the class into another class thru aggregation or composition? All of these methods achieve the goal of adding new functionality to a base class- however this is all done at compile time. In proper software development circles, it is more appropriate to stay flexible and nimble- by delaying the implementation until the last possible moment. This flexibility is usually achieved by means of configuration (think Spring)- that wires up final implementation classes at runtime. Likewise, the Decorator pattern can add new functionality to individual objects- rather than classes at runtime. In plain street English, Decorators are \"Wrappers\". Decorator classes wrap around a base class- and add new functionality. GOFers usually diagram what they mean by means of UML. But how about just a simple Ascii diagram for passing on simple ideas without the exact ER formalisms??? In a Decorator pattern, there are four main classes. An AbstractWidget class. A ConcreteWidget class. A AbstractWrapper derived from AbstractWidget, wraps around a AbstractWidget in constructor. A ConcreteWrapper firmly adds new functionality to the wrapped Widget. In simple psuedo code terms- AbstractWidget { abstract baseMethod(); } ConcreteWidget : AbstractWidget { @Override baseMethod(); } AbstractWrapper : AbstractWidget { AbstractWrapper( AbstractWidget ) @Override baseMethod(); } ConcreteWrapper : AbstractWrapper { ConcreteWrapper( AbstractWidget ) @Override baseMethod(); } To put this pattern into practical terms, let's imagine two types of automobiles- HondaAccord and TeslaRoadster, each sold with two types of options- SunRoof and TintedWindows. Each combination of options- none, SunRoof only, TintedWindows only, SunRoof + TintedWindows- yields a unique final assembly for the car. We can model each car + options combination with a base car class and a set of boolean flags. The problem with this model is that if we add a new option, we'd have to mess with the base car class. The Decorator allows us to add new options to a car without changing the base car class. The code sample below shows one possible Decorator implementation. // -------------------------------------------- // CarMake // The Abstract Widget // package drills; public abstract class CarMake { abstract public String getName(); CarMake() { } } // -------------------------------------------- // HondaAccord // The concrete widget // package drills; public class HondaAccord extends CarMake { public HondaAccord () { } @Override public String getName() { return \"HondaAccord\" ; } } // -------------------------------------------- // TeslaRoadster // Second concrete widget // package drills; public class TeslaRoadster extends CarMake { public TeslaRoadster() { } @Override public String getName() { return \"TeslaRoadster\" ; } } // -------------------------------------------- // CarDecorator // Abstractor decorator (wrapper) // package drills; public abstract class CarDecorator extends CarMake { @Override public CarDecorator(CarMake c) { } } // -------------------------------------------- // SunRoofCarDecorator // package drills; public class SunRoofCarDecorator extends CarDecorator { CarMake _wrappedCar; public SunRoofCarDecorator(CarMake c) { super(c); _wrappedCar = c; } @Override public String getName() { return _wrappedCar.getName() + \", SunRoof\" ; } } // -------------------------------------------- // TintedWindowsCarDecorator // package drills; public class TintedWindowsCarDecorator extends CarDecorator { CarMake _wrappedCar; public TintedWindowsCarDecorator(CarMake c) { super(c); _wrappedCar = c; } @Override public String getName() { return _wrappedCar.getName() + \", TintedWindows\" ; } } // -------------------------------------------- // Tester // package drills; public class Tester { public static void main(String[] args) { // Car A, HondaAccord has nothing // Car B, HondaAccord has SunRoof // Car C, HondaAccord has TintedWindows // Car D, HondaAccord has SunRoof and TintedWindows // Car E, TeslaRoadster has nothing // Car F, TeslaRoadster has SunRoof // Car G, TeslaRoadster has TintedWindows // Car H, TeslaRoadster has SunRoof and TintedWindows CarMake a = new HondaAccord(); CarMake b = new SunRoofCarDecorator(a); CarMake c = new TintedWindowsCarDecorator(a); CarMake d = new SunRoofCarDecorator(c); CarMake e = new TeslaRoadster(); CarMake f = new SunRoofCarDecorator(e); CarMake g = new TintedWindowsCarDecorator(e); CarMake h = new TintedWindowsCarDecorator(f); System. out .println( \"A = \" + a.getName()); System. out .println( \"B = \" + b.getName()); System. out .println( \"C = \" + c.getName()); System. out .println( \"D = \" + d.getName()); System. out .println( \"E = \" + e.getName()); System. out .println( \"F = \" + f.getName()); System. out .println( \"G = \" + g.getName()); System. out .println( \"H = \" + h.getName()); } } The test program output looks as follows: A = HondaAccord B = HondaAccord, SunRoof C = HondaAccord, TintedWindows D = HondaAccord, TintedWindows, SunRoof E = TeslaRoadster F = TeslaRoadster, SunRoof G = TeslaRoadster, TintedWindows H = TeslaRoadster, SunRoof, TintedWindows From this bare-bones example, you can see how we can programmatically alter an object's behavior at runtime- without affecting the original object's behavior.","title":"Decorator Pattern in Plain Speak"},{"location":"archives/2014/2014-04-20-equals-hashcode-and-comparable-interface/","tags":"patterns","text":"When should a class overwrite equals() and hashCode()? And when should a class implement the Comparable interface? A class should overwrite equals() when the class represents a value item- meaning ideas like dates, times, colors, or other unique representations of things. An object representing 2001-9-11 should equal another object also representing 2001-9-11, no? These two objects are equal despite being two different objects in memory. And each time you overwrite equals, you also have to overwrite hashCode()- because otherwise, each collection class that stores objects according to their hashCodes would not recognize them as being the same object. Lastly, a class should implement the Comparable interface when you want to overwrite the default sorting. So if you want to sort the object backwards or add case insensitivity, you can do so in your own Comparable compareTo() routine. package drills ; import java.util.ArrayList ; import java.util.Collections ; import java.util.HashSet ; import java.util.List ; import java.util.ListIterator ; import java.util.Set ; public final class MartianDateTime implements Comparable<MartianDateTime> { // This test class demonstrates how to // 1. override equals() // 2. overrides hashCode() // Why override equals()? When a class represents value, two instances of the same // class with the same value SHOULD be equal to each other. // An example is a MartianDateTime class. If two instances both represent 10AM, then // they should be considered equal. (On the other hand, perhaps a static factory // constructor should ensure only one instance of the same datetime get created.) // // Why override hashCode()? If you override equals() to mean two instances are // equal, then they should also be considered equal when adding them to a // Collection like hashSet or hashMap which uses an object's hashCode() to // represent uniqueness. private int martianHour; private int martianMinute; private int martianSecond; private int hashCode; // Make MartianDateTime an immutable class // seal it // make it constructed from a factory builder private MartianDateTime( int hour, int minute, int second) { martianHour = hour; martianMinute = minute; martianSecond = second; hashCode = 0; } // --------------------------------------------------------------------- // MartianDateTime // Static factory constructor static public MartianDateTime BuildMartianDateTime( int hour, int minute, int second) { return new MartianDateTime(hour, minute, second); } // --------------------------------------------------------------------- // toString() @Override public String toString() { return String.format( \"%d:%d:%d\" , martianHour, martianMinute, martianSecond); } // --------------------------------------------------------------------- // equals() // return true if compare against self // return false if compare against another type - use instanceof() // cast to correct type // return true if all significant fields compare equal @Override public boolean equals(Object o) { if ( this == o) return true ; if (!(o instanceof MartianDateTime)) return false ; MartianDateTime other = (MartianDateTime)o; if (other.martianHour != this .martianHour || other.martianMinute != this .martianMinute || other.martianSecond != this .martianSecond ) return false ; return true ; } // --------------------------------------------------------------------- // hashCode // A good hashCode method should // - unequal objects should return unequal hashcodes // - good hashing function should distribute objects across a range evenly // // simple recipe for a hashing function // 1. start with a prime number // 2. mix in contributions from each significant field @Override public int hashCode() { int tmp = hashCode; if (tmp==0) { tmp = 17; tmp = 31 * tmp + martianHour; tmp = 31 * tmp + martianMinute; tmp = 31 * tmp + martianSecond; hashCode = tmp; } return hashCode; } // --------------------------------------------------------------------- // compareTo // If this object is greater than comparedTo object, then return 1 @Override public int compareTo(MartianDateTime o) { if ( this .martianHour > o.martianHour) return 1; if (( this .martianHour == o.martianHour) && ( this .martianMinute > o.martianMinute)) return 1; if (( this .martianHour == o.martianHour) && ( this .martianMinute == o.martianMinute) && ( this .martianSecond > o.martianSecond)) return 1; if (( this .martianHour == o.martianHour) && ( this .martianMinute == o.martianMinute) && ( this .martianSecond == o.martianSecond)) return 0; return -1; } // --------------------------------------------------------------------- // test code public static void main(String[] args) { // Construct 3 MartianDateTime instances MartianDateTime dt1 = MartianDateTime.BuildMartianDateTime(10,8,8); MartianDateTime dt2 = MartianDateTime.BuildMartianDateTime(10,8,9); MartianDateTime dt3 = MartianDateTime.BuildMartianDateTime(10,8,8); // Instances with the same datetimes are equal assert (!dt1.equals(dt2)); assert (dt1.equals(dt3)); // Should not be able to add two instances with the same \"equal-ness\" // into the same hashset Set<MartianDateTime> s = new HashSet<MartianDateTime>(); s.add(dt1); s.add(dt2); assert (s.contains(dt3)); List<MartianDateTime> listMdt = new ArrayList<MartianDateTime>(); listMdt.add(dt1); listMdt.add(dt2); listMdt.add(dt3); ListIterator<MartianDateTime> li = listMdt.listIterator(); System.out.println( \"Print list of MartianDateTimes\" ); while (li.hasNext()) { MartianDateTime m=li.next(); if (m== null ) break ; System.out.println(m.toString()); } Collections.sort(listMdt); ListIterator<MartianDateTime> sl = listMdt.listIterator(); System.out.println( \"Print list of sorted MartianDateTimes\" ); while (sl.hasNext()) { MartianDateTime m=sl.next(); if (m== null ) break ; System.out.println(m.toString()); } System.out.println( \"Passed all tests\" ); } }","title":"Equals Hashcode and Comparable Interface in Java"},{"location":"archives/2014/2014-04-20-equals-hashcode-and-comparable-interface/#when-should-a-class-overwrite-equals-and-hashcode","text":"And when should a class implement the Comparable interface? A class should overwrite equals() when the class represents a value item- meaning ideas like dates, times, colors, or other unique representations of things. An object representing 2001-9-11 should equal another object also representing 2001-9-11, no? These two objects are equal despite being two different objects in memory. And each time you overwrite equals, you also have to overwrite hashCode()- because otherwise, each collection class that stores objects according to their hashCodes would not recognize them as being the same object. Lastly, a class should implement the Comparable interface when you want to overwrite the default sorting. So if you want to sort the object backwards or add case insensitivity, you can do so in your own Comparable compareTo() routine. package drills ; import java.util.ArrayList ; import java.util.Collections ; import java.util.HashSet ; import java.util.List ; import java.util.ListIterator ; import java.util.Set ; public final class MartianDateTime implements Comparable<MartianDateTime> { // This test class demonstrates how to // 1. override equals() // 2. overrides hashCode() // Why override equals()? When a class represents value, two instances of the same // class with the same value SHOULD be equal to each other. // An example is a MartianDateTime class. If two instances both represent 10AM, then // they should be considered equal. (On the other hand, perhaps a static factory // constructor should ensure only one instance of the same datetime get created.) // // Why override hashCode()? If you override equals() to mean two instances are // equal, then they should also be considered equal when adding them to a // Collection like hashSet or hashMap which uses an object's hashCode() to // represent uniqueness. private int martianHour; private int martianMinute; private int martianSecond; private int hashCode; // Make MartianDateTime an immutable class // seal it // make it constructed from a factory builder private MartianDateTime( int hour, int minute, int second) { martianHour = hour; martianMinute = minute; martianSecond = second; hashCode = 0; } // --------------------------------------------------------------------- // MartianDateTime // Static factory constructor static public MartianDateTime BuildMartianDateTime( int hour, int minute, int second) { return new MartianDateTime(hour, minute, second); } // --------------------------------------------------------------------- // toString() @Override public String toString() { return String.format( \"%d:%d:%d\" , martianHour, martianMinute, martianSecond); } // --------------------------------------------------------------------- // equals() // return true if compare against self // return false if compare against another type - use instanceof() // cast to correct type // return true if all significant fields compare equal @Override public boolean equals(Object o) { if ( this == o) return true ; if (!(o instanceof MartianDateTime)) return false ; MartianDateTime other = (MartianDateTime)o; if (other.martianHour != this .martianHour || other.martianMinute != this .martianMinute || other.martianSecond != this .martianSecond ) return false ; return true ; } // --------------------------------------------------------------------- // hashCode // A good hashCode method should // - unequal objects should return unequal hashcodes // - good hashing function should distribute objects across a range evenly // // simple recipe for a hashing function // 1. start with a prime number // 2. mix in contributions from each significant field @Override public int hashCode() { int tmp = hashCode; if (tmp==0) { tmp = 17; tmp = 31 * tmp + martianHour; tmp = 31 * tmp + martianMinute; tmp = 31 * tmp + martianSecond; hashCode = tmp; } return hashCode; } // --------------------------------------------------------------------- // compareTo // If this object is greater than comparedTo object, then return 1 @Override public int compareTo(MartianDateTime o) { if ( this .martianHour > o.martianHour) return 1; if (( this .martianHour == o.martianHour) && ( this .martianMinute > o.martianMinute)) return 1; if (( this .martianHour == o.martianHour) && ( this .martianMinute == o.martianMinute) && ( this .martianSecond > o.martianSecond)) return 1; if (( this .martianHour == o.martianHour) && ( this .martianMinute == o.martianMinute) && ( this .martianSecond == o.martianSecond)) return 0; return -1; } // --------------------------------------------------------------------- // test code public static void main(String[] args) { // Construct 3 MartianDateTime instances MartianDateTime dt1 = MartianDateTime.BuildMartianDateTime(10,8,8); MartianDateTime dt2 = MartianDateTime.BuildMartianDateTime(10,8,9); MartianDateTime dt3 = MartianDateTime.BuildMartianDateTime(10,8,8); // Instances with the same datetimes are equal assert (!dt1.equals(dt2)); assert (dt1.equals(dt3)); // Should not be able to add two instances with the same \"equal-ness\" // into the same hashset Set<MartianDateTime> s = new HashSet<MartianDateTime>(); s.add(dt1); s.add(dt2); assert (s.contains(dt3)); List<MartianDateTime> listMdt = new ArrayList<MartianDateTime>(); listMdt.add(dt1); listMdt.add(dt2); listMdt.add(dt3); ListIterator<MartianDateTime> li = listMdt.listIterator(); System.out.println( \"Print list of MartianDateTimes\" ); while (li.hasNext()) { MartianDateTime m=li.next(); if (m== null ) break ; System.out.println(m.toString()); } Collections.sort(listMdt); ListIterator<MartianDateTime> sl = listMdt.listIterator(); System.out.println( \"Print list of sorted MartianDateTimes\" ); while (sl.hasNext()) { MartianDateTime m=sl.next(); if (m== null ) break ; System.out.println(m.toString()); } System.out.println( \"Passed all tests\" ); } }","title":"When should a class overwrite equals() and hashCode()?"},{"location":"archives/2014/2014-11-02-how-to-use-yield/","tags":"patterns","text":"Always wanted to be clear on how Yield works. This is a feature that traditional C or C++ do not have. using System ; using System.Collections.Generic ; namespace TestYield { class TestYield { // -------------------------------------------------- // AllOdds // // Yield provides an easy way to make an enumerator. // Without Yield, you'd have to generate the entire list // of items to iterate thru- and return that list to the // user. // -------------------------------------------------- static public IEnumerable< int > AllOdds() { for ( int i = 1; i < Int16.MaxValue; i++) { if (i % 2 == 1) yield return i; } } // -------------------------------------------------- // Main // // Use the enumerator above- and can stop the enumerator // from generating the next item by breaking at any time. // -------------------------------------------------- static void Main( string [] args) { int count = 0; foreach ( int i in AllOdds()) { Console.WriteLine( \"{0}\" , i); if (++count > 10) break ; } } } }","title":"How to use Yield"},{"location":"archives/2014/2014-11-03-simple-delegate-example/","tags":"delegates, csharp","text":"Just playing with a simple delegate example. using System ; namespace TestDelegate { class TestDel { // Declare signature of operator methods delegate int OperatorSig( int a, int b); TestDel() { } int Add( int a, int b) { return a + b; } int Subtract( int a, int b) { return a - b; } static void Main( string [] args) { TestDel td = new TestDel(); OperatorSig myAdder = new OperatorSig(td.Add); OperatorSig mySuber = new OperatorSig(td.Subtract); Console.Out.WriteLine( \"Adder Result is {0}\" , myAdder(2, 3)); Console.Out.WriteLine( \"Suber Result is {0}\" , mySuber(2, 3)); Console.In.ReadLine(); } } }","title":"Simple Delegate Example"},{"location":"archives/2014/2014-11-04-invoking-delegates-asynchronously/","tags":"patterns","text":"It's a slow day at work. Let's try an asynch delegate. using System ; using System.Threading ; using System.Runtime.Remoting.Messaging ; // To access the AsyncResult type namespace TestAsyncDelegate { class TestDel { delegate int OperatorSig( int a, int b); TestDel() { } // -------------------------------------------------------------- // Add // // Random work method that takes an arbitrarily set 2.4 seconds // to complete. // -------------------------------------------------------------- public int Add( int a, int b) { Console.Out.WriteLine( \"ThreadId={0}, Adding starts\" , Thread.CurrentThread.ManagedThreadId ); Thread.Sleep(2400); Console.Out.WriteLine( \"ThreadId={0}, Adding completed\" , Thread.CurrentThread.ManagedThreadId ); return a + b; } // -------------------------------------------------------------- // ResultCallback // // This function gets called when the delegate method completes // asynchronously in the background. // We call EndInvoke to get the delegate results. // -------------------------------------------------------------- public void ResultCallback(IAsyncResult iar) { AsyncResult ar = (AsyncResult)iar; // Get class object reference. OperatorSig del = (OperatorSig)ar.AsyncDelegate; // Get reference to delegate. int result = del.EndInvoke(iar); Console.Out.WriteLine( \"ThreadId={0}, Add result = {1}\" , Thread.CurrentThread.ManagedThreadId, result); } // -------------------------------------------------------------- // Main // // -------------------------------------------------------------- static void Main( string [] args) { TestDel td = new TestDel(); // create delegate and invoke to run asynchronously OperatorSig myAdder = new OperatorSig(td.Add); IAsyncResult res = myAdder.BeginInvoke( 10, 5, new AsyncCallback(td.ResultCallback), null ); // main thread keeps doing something else while (!res.IsCompleted) { for ( int i = 0; i < 10; i++) { Console.Out.WriteLine( \"ThreadId={0}, Main thread working\" , Thread.CurrentThread.ManagedThreadId ); Thread.Sleep(1000); } } } } } Runtime results shown here: ThreadId=3, Adding starts ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=3, Adding completed ThreadId=3, Add result = 15 ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=1, Main thread working ThreadId=1, Main thread working","title":"Invoking Delegates Asynchronously"},{"location":"archives/2014/2014-11-05-all-about-events/","tags":"patterns","text":"Let's discuss a little bit more about Events. How are Events different from Delegates? For events- The event keyword is a modifier- to a delegate type, the most frequent being EventHandler for event handling situations. The event keyword allows a delegate type to be exposed in an interface. Events come with add and remove methods, much like get and set methods for properties. Events have a strict method signature (object ok, EventArgs e). Here is some simple test code demonstrating the use of Events. using System ; using System.Collections.Generic ; using System.Linq ; using System.Text ; using System.Threading.Tasks ; namespace TestEvents { class TinyMechErrorArgs : EventArgs { public int MechError { get ; set ; } public TinyMechErrorArgs( int error) { MechError = error; } } // ---------------------------------------------------------------- // TinyMech // // Machine that publishes error events // // ---------------------------------------------------------------- class TinyMech { // EventHandlers must have args (object sender, EventArgs e) public event EventHandler ErrorEventHappened; public void Run() { Random r = new Random(); for ( int i=0; i<1000; i++) { if (r.Next(100)==1) { ErrorEventHappened( this , new TinyMechErrorArgs(i)); } } } } // ---------------------------------------------------------------- // TinyReporter // // Machine that listens for errors and reports it to main console // // ---------------------------------------------------------------- class TinyReporter { public void ListenToMachine(TinyMech m) { m.ErrorEventHappened += ReportError; } private void ReportError( object sender, EventArgs e) { if (sender is TinyMech) { TinyMechErrorArgs ea = (TinyMechErrorArgs) e; Console.Out.WriteLine( \"Error on {0}\" , ea.MechError); } } } class Program { static void Main( string [] args) { TinyMech m = new TinyMech(); TinyReporter r = new TinyReporter(); r.ListenToMachine(m); m.Run(); Console.In.ReadLine(); } } }","title":"All About Events"},{"location":"archives/2015/2015-05-03-are-generic-collections-faster/","tags":"patterns","text":"The oft-repeated assertion is that generic collections run faster than their non-generic versions. But is this true? And if so, just how much faster? I wrote some quick code to run a test. using System ; using System.Collections.Generic ; using System.Collections ; namespace TestBoxing { class Program { static void TimeArrayList() { Console.Out.WriteLine( \"TimeArrayList start\" ); // Test creating and reading a million boxed ints DateTime dtStart = DateTime.Now; ArrayList intList = new ArrayList(); for ( int i = 0; i < 10000000; i++) { intList.Add(i); } DateTime dtCreateEnd = DateTime.Now; for ( int j = 0; j < 10000000; j++) { int retrievedInt = ( int )intList[j]; if (retrievedInt % 1000000 == 0) Console.Out.Write( \".\" ); } Console.Out.WriteLine(); DateTime dtReadEnd = DateTime.Now; TimeSpan wholeTime = dtReadEnd.Subtract(dtStart); TimeSpan addTime = dtCreateEnd.Subtract(dtStart); TimeSpan readTime = dtReadEnd.Subtract(dtCreateEnd); Console.Out.WriteLine( \"ArrayList took {0} ms in total, {1} ms to add, {2} to read\\n\" , wholeTime.TotalMilliseconds, addTime.TotalMilliseconds, readTime.TotalMilliseconds); } static void TimeGenericList() { Console.Out.WriteLine( \"TimeGenericList start\" ); // Test creating and reading a million boxed ints DateTime dtStart = DateTime.Now; List< int > intList = new List< int >(); for ( int i = 0; i < 10000000; i++) { intList.Add(i); } DateTime dtCreateEnd = DateTime.Now; for ( int j = 0; j < 10000000; j++) { int retrievedInt = intList[j]; if (retrievedInt % 1000000 == 0) Console.Out.Write( \".\" ); } Console.Out.WriteLine(); DateTime dtReadEnd = DateTime.Now; TimeSpan wholeTime = dtReadEnd.Subtract(dtStart); TimeSpan addTime = dtCreateEnd.Subtract(dtStart); TimeSpan readTime = dtReadEnd.Subtract(dtCreateEnd); Console.Out.WriteLine( \"GenericList took {0} ms in total, {1} ms to add, {2} to read\\n\" , wholeTime.TotalMilliseconds, addTime.TotalMilliseconds, readTime.TotalMilliseconds); } static void Main( string [] args) { TimeGenericList(); TimeArrayList(); TimeArrayList(); TimeGenericList(); Console.ReadKey(); } } } The result? TimeGenericList start .......... GenericList took 646 ms in total, 251 ms to add, 395 to read TimeArrayList start .......... ArrayList took 3870 ms in total, 3409 ms to add, 461 to read TimeArrayList start .......... ArrayList took 3593 ms in total, 3146 ms to add, 447 to read TimeGenericList start .......... GenericList took 786 ms in total, 400 ms to add, 386 to read It's fairly conclusive. Adding new items to a generic list is roughly 9 times faster than the non-generic version. My guess is this slowness comes from boxing the item before adding it to the list. Retrieving and unboxing the item from a non-generic list is not much slower than the generic version.","title":"Are Generic Collections Faster than Non-Generic Collections?"},{"location":"archives/2015/2015-12-17-how-backgroundworker-works/","tags":"patterns","text":"I've decided to take a deeper look at all available multi-threading options in .net 4.5. One of the simpler options is the BackgroundWorker. To investigate, I've setup a simple BackgroundWorker with progress and completion reporting. using System ; using System.Collections.Generic ; using System.Linq ; using System.Text ; using System.ComponentModel ; using System.Threading ; namespace TestBackgroundWorker { class TestBkGrdWorker { private void LogMsg( string msg) { Console.Out.WriteLine( \"{0} ThreadId={1}, {2}\" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId, msg); } // RunTest // // Function run by main thread // Main thread sets up the background worker instance // and fires it off public void RunTest() { BackgroundWorker bkWorker = new BackgroundWorker(); bkWorker.WorkerReportsProgress = true ; // setup functions the background worker calls // to do work, report progress, and to report completion bkWorker.DoWork += bkWorker_DoWork; bkWorker.ProgressChanged += bkWorker_ProgressChanged; bkWorker.RunWorkerCompleted += bkWorker_RunWorkerCompleted; // trigger background worker to run async bkWorker.RunWorkerAsync(); // main thread do something while background worker do something else for ( int i = 0; i &lt; 5; i++) { LogMsg( string .Format( \"Main thread working, BackgroundWorker busy={0}\" , bkWorker.IsBusy)); Thread.Sleep(1000); } } // bkWorker_ProgressChanged // // Report progress void bkWorker_ProgressChanged( object sender, ProgressChangedEventArgs e) { LogMsg( string .Format( \"Background worker update progress, {0:00.0}% done\" , e.ProgressPercentage)); } // bkWorker_RunWorkerCompleted // // Report work is completed void bkWorker_RunWorkerCompleted( object sender, RunWorkerCompletedEventArgs e) { LogMsg( \"Background worker completed\" ); } // bkWorker_DoWork // // Function run by background worker. // Random work method that takes an arbitrarily set 2 seconds // to complete, with a progress report every 200ms. void bkWorker_DoWork( object sender, DoWorkEventArgs e) { LogMsg( \"Background worker starting\" ); float percentDone = 0.0f; for ( int i = 0; i &lt; 10; i++) { Thread.Sleep(200); percentDone += 10.0f; BackgroundWorker bkwkr = sender as BackgroundWorker; if (bkwkr != null ) { bkwkr.ReportProgress(( int )percentDone); } } LogMsg( \"Background worker completed\" ); } // Main // Start up a background worker test instance static void Main( string [] args) { TestBkGrdWorker testWkr = new TestBkGrdWorker(); testWkr.RunTest(); } } } The output looks as follows: 12:12:04.680 ThreadId=3, Background worker starting 12:12:04.680 ThreadId=1, Main thread working, BackgroundWorker busy=True 12:12:04.945 ThreadId=4, Background worker update progress, 10.0% done 12:12:05.148 ThreadId=4, Background worker update progress, 20.0% done 12:12:05.350 ThreadId=4, Background worker update progress, 30.0% done 12:12:05.553 ThreadId=4, Background worker update progress, 40.0% done 12:12:05.756 ThreadId=4, Background worker update progress, 50.0% done 12:12:05.756 ThreadId=1, Main thread working, BackgroundWorker busy=True 12:12:05.959 ThreadId=4, Background worker update progress, 60.0% done 12:12:06.162 ThreadId=4, Background worker update progress, 70.0% done 12:12:06.364 ThreadId=4, Background worker update progress, 80.0% done 12:12:06.567 ThreadId=4, Background worker update progress, 90.0% done 12:12:06.770 ThreadId=3, Background worker completed 12:12:06.770 ThreadId=3, Background worker update progress, 100.0% done 12:12:06.770 ThreadId=4, Background worker completed 12:12:06.770 ThreadId=1, Main thread working, BackgroundWorker busy=True 12:12:07.784 ThreadId=1, Main thread working, BackgroundWorker busy=False 12:12:08.798 ThreadId=1, Main thread working, BackgroundWorker busy=False","title":"How BackgroundWorker Works"},{"location":"archives/2015/2015-12-18-multi-threading-cheatsheet/","tags":"patterns","text":"Here is a cheatsheet of .net 4.5 multi-threading options- with the pros and cons of each. BackgroundWorker Easy to start working in background Easy to periodically update the UI thread Theads Heavy weight multi-threading, but gives full control","title":"Multi-threading Cheat Sheet"},{"location":"archives/2015/2015-12-19-variable-params/","tags":"patterns","text":"Today just put together a test case to show usage of functions with variable number of parameters. using System ; using System.Threading ; namespace TestVariableParams { class Tester { // use object[] to allow for arguments of any type static void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } static void Main( string [] args) { LogMsg( \"Test {0}\" , \"first arg\" ); LogMsg( \"This is a test {0} {1}\" , \"first arg\" , \"second arg\" ); LogMsg( \"This is a test with int args {0} {1}\" , 123, 456); } } } The output shows- 10:05:04.208 ThreadId=1 Test first arg 10:05:04.244 ThreadId=1 This is a test first arg second arg 10:05:04.244 ThreadId=1 This is a test with int args 123 456","title":"Using Variable Params"},{"location":"archives/2015/2015-12-20-backgroundworker/","tags":"patterns","text":"I\u2019ve decided to take a deeper look at all available multi-threading options in .net 4.5. One of the simpler options is the BackgroundWorker. To investigate, I\u2019ve setup a simple BackgroundWorker with progress and completion reporting. using System ; using System.ComponentModel ; using System.Threading ; namespace TestBackgroundWorker { class TestBkGrdWorker { static void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } // RunTest // // Function run by main thread // Main thread sets up the background worker instance // and fires it off public void RunTest() { BackgroundWorker bkWorker = new BackgroundWorker(); bkWorker.WorkerReportsProgress = true ; // setup functions the background worker calls // to do work, report progress, and to report completion bkWorker.DoWork += bkWorker_DoWork; bkWorker.ProgressChanged += bkWorker_ProgressChanged; bkWorker.RunWorkerCompleted += bkWorker_RunWorkerCompleted; AutoResetEvent myFlag = new AutoResetEvent( false ); // trigger background worker to run async bkWorker.RunWorkerAsync(myFlag); LogMsg( \"Main thread working, BackgroundWorker busy={0}\" , bkWorker.IsBusy); myFlag.WaitOne(); // wait for someone to signal this flag LogMsg( \"RunTest thread resumes control upon completion of background thread\" ); } // bkWorker_ProgressChanged // // Report progress void bkWorker_ProgressChanged( object sender, ProgressChangedEventArgs e) { LogMsg( \"Background worker update progress, {0:00.0}% done\" , e.ProgressPercentage); } // bkWorker_RunWorkerCompleted // // Report work is completed void bkWorker_RunWorkerCompleted( object sender, RunWorkerCompletedEventArgs e) { LogMsg( \"Background worker completed\" ); } // bkWorker_DoWork // // Function run by background worker. // Random work method that takes an arbitrarily set 2 seconds // to complete, with a progress report every 200ms. void bkWorker_DoWork( object sender, DoWorkEventArgs e) { LogMsg( \"Background worker starting\" ); float percentDone = 0.0f; for ( int i = 0; i < 10; i++) { Thread.Sleep(200); percentDone += 10.0f; BackgroundWorker bkwkr = sender as BackgroundWorker; if (bkwkr != null ) { bkwkr.ReportProgress(( int )percentDone); } } LogMsg( \"Background worker completed\" ); AutoResetEvent myFlag = e.Argument as AutoResetEvent; if (myFlag != null ) { myFlag.Set(); } } // Main // Start up a background worker test instance static void Main( string [] args) { TestBkGrdWorker testWkr = new TestBkGrdWorker(); testWkr.RunTest(); } } } The output: 18:05:51.835 ThreadId=3 Background worker starting 18:05:51.805 ThreadId=1 Main thread working, BackgroundWorker busy=True 18:05:52.107 ThreadId=4 Background worker update progress, 10.0% done 18:05:52.287 ThreadId=4 Background worker update progress, 20.0% done 18:05:52.487 ThreadId=4 Background worker update progress, 30.0% done 18:05:52.687 ThreadId=4 Background worker update progress, 40.0% done 18:05:52.889 ThreadId=4 Background worker update progress, 50.0% done 18:05:53.091 ThreadId=4 Background worker update progress, 60.0% done 18:05:53.291 ThreadId=4 Background worker update progress, 70.0% done 18:05:53.493 ThreadId=4 Background worker update progress, 80.0% done 18:05:53.693 ThreadId=4 Background worker update progress, 90.0% done 18:05:53.893 ThreadId=4 Background worker update progress, 100.0% done 18:05:53.893 ThreadId=3 Background worker completed 18:05:53.903 ThreadId=1 RunTest thread resumes control upon completion of background thread","title":"Using BackgroundWorker"},{"location":"archives/2015/2015-12-21-rhino-mocks/","tags":"patterns","text":"Testing Rhino Mocks today for use in unit tests. IAdder.cs using System ; namespace TestAdderLib { public interface IAdder { int AddTwoNums( int a, int b); } } Adder.cs using System ; using System.Threading ; namespace TestAdderLib { public class Adder : IAdder { public int AddTwoNums( int a, int b) { Thread.Sleep(1000); return a + b; } } } TestCalculatorWithRhino.cs using System ; using Microsoft.VisualStudio.TestTools.UnitTesting ; using Calculator ; using TestAdderLib ; using Rhino.Mocks ; namespace TestCalculatorWithRhino { internal class ManuallyCodedAdderStub : IAdder { public int AddTwoNums( int a, int b) { int result = a + b; return result; } } [TestClass] public class TestCalculator { [TestMethod] public void TestCalculatorDirectly() { CalculatorV1 c = new CalculatorV1(); Assert.AreEqual(2, c.Add(1, 1)); Assert.AreEqual(5, c.Add(2, 3)); } [TestMethod] public void TestCalculatorWithManualAdderStub() { var adderStub = new ManuallyCodedAdderStub(); CalculatorV1 c = new CalculatorV1(); c.myAdder = adderStub; Assert.AreEqual(2, c.Add(1, 1)); Assert.AreEqual(5, c.Add(2, 3)); } [TestMethod] public void TestCalculatorWithGeneratedAdderStub() { MockRepository mocks = new MockRepository(); IAdder mockedAdderStub = mocks.DynamicMock<IAdder>(); using (mocks.Record()) { mockedAdderStub.AddTwoNums(1, 1); LastCall.Return(2); mockedAdderStub.AddTwoNums(2, 3); LastCall.Return(5); } CalculatorV1 c = new CalculatorV1(); c.myAdder = mockedAdderStub; Assert.AreEqual(2, c.Add(1, 1)); Assert.AreEqual(5, c.Add(2, 3)); } } }","title":"Using Rhino Mocks"},{"location":"archives/2015/2015-12-22-threads/","tags":"patterns","text":"We're not supposed to use raw managed threads anymore- given that .net 4+ has given us much more advanced multi-threading features. However, I'll still post some test code to illustrate how threads work. using System ; using System.Text ; using System.Threading ; namespace TestThreads { class ThreadTester { private Thread _workerThread; private void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } // LongComputeTask // // Function run by background worker. void LongComputeTask( object threadId) { LogMsg( \"LongComputeTask starting\" ); float percentDone = 0.0f; for ( int i = 0; i < 10; i++) { Thread.Sleep(500); percentDone += 10.0f; LogMsg( \"LongComputeTask {0:0.0f}% completed\" , percentDone); } LogMsg( \"LongComputeTask completed\" ); } // RunTest // // Function run by main thread // Main thread sets up the background thread // and fires it off public void RunTest() { _workerThread = new Thread(LongComputeTask); _workerThread.Start(1); // main thread do something while background thread do something else for ( int i = 0; i < 2; i++) { LogMsg( \"Main thread working\" ); Thread.Sleep(1000); } LogMsg( \"Main thread completed, wait for worker thread\" ); _workerThread.Join(); } // Main // Start up a background worker test instance static void Main( string [] args) { ThreadTester testWkr = new ThreadTester(); testWkr.RunTest(); } } } The output: 19:05:36.155 ThreadId=1 Main thread working 19:05:36.185 ThreadId=3 LongComputeTask starting 19:05:36.693 ThreadId=3 LongComputeTask 10.0f% completed 19:05:37.183 ThreadId=1 Main thread working 19:05:37.193 ThreadId=3 LongComputeTask 20.0f% completed 19:05:37.695 ThreadId=3 LongComputeTask 30.0f% completed 19:05:38.185 ThreadId=1 Main thread completed, wait for worker thread 19:05:38.195 ThreadId=3 LongComputeTask 40.0f% completed 19:05:38.695 ThreadId=3 LongComputeTask 50.0f% completed 19:05:39.195 ThreadId=3 LongComputeTask 60.0f% completed 19:05:39.695 ThreadId=3 LongComputeTask 70.0f% completed 19:05:40.195 ThreadId=3 LongComputeTask 80.0f% completed 19:05:40.697 ThreadId=3 LongComputeTask 90.0f% completed 19:05:41.197 ThreadId=3 LongComputeTask 100.0f% completed 19:05:41.197 ThreadId=3 LongComputeTask completed","title":"Using Threads"},{"location":"archives/2015/2015-12-23-threadpool/","tags":"patterns","text":"Testing ThreadPool usage today- using System ; using System.Threading ; namespace TestThreadPool { class ThreadPoolTester { private void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId=3D{1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } // LongComputeTask // // Function run by background worker. private void LongComputeTask(Object stateInfo) { LogMsg( \"LongComputeTask starting\" ); float percentDone =3D 0.0f; for ( int i =3D 0; i < 10; i++) { Thread.Sleep(500); percentDone +=3D 10.0f; LogMsg( \"LongComputeTask {0:0.0f}% completed\" , percentDone); } LogMsg( \"LongComputeTask completed\" ); AutoResetEvent myFlag =3D stateInfo as AutoResetEvent; if (myFlag !=3D null ) { myFlag.Set(); } } private void GetMaxThreadPoolThreads() { int workerThreads, portThreads; ThreadPool.GetMaxThreads( out workerThreads, out portThreads); LogMsg( \"MaxWorkerThreads=3D{0} MaxPortThreads=3D{1}\" , workerThreads, portThreads); } // RunTest // // Function run by main thread // Main thread sets up the background thread // and fires it off public void RunTest() { GetMaxThreadPoolThreads(); var myFlag =3D new AutoResetEvent( false ); ThreadPool.QueueUserWorkItem( new WaitCallback(LongComputeTask), myFlag); myFlag.WaitOne(); } static void Main( string [] args) { var tester =3D new ThreadPoolTester(); tester.RunTest(); } } } The output- 19:05:59.297 ThreadId=3D1 MaxWorkerThreads=3D1023 MaxPortThreads=3D1000 19:05:59.332 ThreadId=3D3 LongComputeTask starting 19:05:59.842 ThreadId=3D3 LongComputeTask 10.0f% completed 19:05:00.342 ThreadId=3D3 LongComputeTask 20.0f% completed 19:05:00.842 ThreadId=3D3 LongComputeTask 30.0f% completed 19:05:01.342 ThreadId=3D3 LongComputeTask 40.0f% completed 19:05:01.844 ThreadId=3D3 LongComputeTask 50.0f% completed 19:05:02.344 ThreadId=3D3 LongComputeTask 60.0f% completed 19:05:02.846 ThreadId=3D3 LongComputeTask 70.0f% completed 19:05:03.346 ThreadId=3D3 LongComputeTask 80.0f% completed 19:05:03.846 ThreadId=3D3 LongComputeTask 90.0f% completed 19:05:04.346 ThreadId=3D3 LongComputeTask 100.0f% completed 19:05:04.346 ThreadId=3D3 LongComputeTask completed","title":"Using ThreadPool"},{"location":"archives/2015/2015-12-24-mutex/","tags":"patterns","text":"Testing mutexes today. Mutexes can be used to ensure only one instance of an app runs at any one time. using System ; using System.Threading ; namespace TestMutex { class MutexTester { private void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } // LongComputeTask // // Function run by background worker. private void LongComputeTask() { LogMsg( \"LongComputeTask starting\" ); float percentDone = 0.0f; for ( int i = 0; i <10; i++) { Thread.Sleep(1000); percentDone += 2.0f; LogMsg( \"LongComputeTask {0:0.0f}% completed\" , percentDone); } LogMsg( \"LongComputeTask completed\" ); } // RunTest // // Function run by main thread // Main thread sets up the background thread // and fires it off public void RunTest() { // Acquire mutex here, ensure only 1 instance of this program // run at any one time var myMutex = new Mutex( false , \"TestMutex\" ); myMutex.WaitOne(); LongComputeTask(); myMutex.ReleaseMutex(); } static void Main( string [] args) { var tester = new MutexTester(); tester.RunTest(); } } } Window One >TestMutex.exe 19:05:05.661 ThreadId=1 LongComputeTask starting 19:05:06.701 ThreadId=1 LongComputeTask 2.0f% completed 19:05:07.703 ThreadId=1 LongComputeTask 4.0f% completed 19:05:08.703 ThreadId=1 LongComputeTask 6.0f% completed 19:05:09.705 ThreadId=1 LongComputeTask 8.0f% completed 19:05:10.705 ThreadId=1 LongComputeTask 10.0f% completed 19:05:11.705 ThreadId=1 LongComputeTask 12.0f% completed 19:05:12.707 ThreadId=1 LongComputeTask 14.0f% completed 19:05:13.707 ThreadId=1 LongComputeTask 16.0f% completed 19:05:14.707 ThreadId=1 LongComputeTask 18.0f% completed 19:05:15.709 ThreadId=1 LongComputeTask 20.0f% completed 19:05:15.709 ThreadId=1 LongComputeTask completed Window Two- notice that this second instance of the test app does not start until the first instance completes. 19:05:15.709 ThreadId=1 LongComputeTask starting 19:05:16.741 ThreadId=1 LongComputeTask 2.0f% completed 19:05:17.741 ThreadId=1 LongComputeTask 4.0f% completed 19:05:18.743 ThreadId=1 LongComputeTask 6.0f% completed 19:05:19.743 ThreadId=1 LongComputeTask 8.0f% completed 19:05:20.743 ThreadId=1 LongComputeTask 10.0f% completed 19:05:21.745 ThreadId=1 LongComputeTask 12.0f% completed 19:05:22.745 ThreadId=1 LongComputeTask 14.0f% completed 19:05:23.745 ThreadId=1 LongComputeTask 16.0f% completed 19:05:24.747 ThreadId=1 LongComputeTask 18.0f% completed 19:05:25.747 ThreadId=1 LongComputeTask 20.0f% completed 19:05:25.747 ThreadId=1 LongComputeTask completed","title":"Using Mutexes"},{"location":"archives/2015/2015-12-25-autoresetevent/","tags":"patterns","text":"Testing AutoResetEvent today. using System ; using System.Threading ; namespace TestAutoResetEvent { class AutoResetEventTester { private void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } // LongComputeTask // // Function run by background worker. private void LongComputeTask(Object stateInfo) { LogMsg( \"LongComputeTask starting\" ); float percentDone = 0.0f; for ( int i = 0; i < 10; i++) { Thread.Sleep(500); percentDone += 10.0f; LogMsg( \"LongComputeTask {0:0.0f}% completed\" , percentDone); } LogMsg( \"LongComputeTask completed\" ); AutoResetEvent myFlag = stateInfo as AutoResetEvent; if (myFlag != null ) { myFlag.Set(); } } // RunTest // // Function run by main thread // Main thread sets up the background thread // and fires it off public void RunTest() { var myFlag = new AutoResetEvent( false ); ThreadPool.QueueUserWorkItem( new WaitCallback(LongComputeTask), myFlag); myFlag.WaitOne(); } static void Main( string [] args) { var tester = new AutoResetEventTester(); tester.RunTest(); } } } The output- 19:05:51.698 ThreadId=3 LongComputeTask starting 19:05:52.232 ThreadId=3 LongComputeTask 10.0f% completed 19:05:52.732 ThreadId=3 LongComputeTask 20.0f% completed 19:05:53.232 ThreadId=3 LongComputeTask 30.0f% completed 19:05:53.738 ThreadId=3 LongComputeTask 40.0f% completed 19:05:54.238 ThreadId=3 LongComputeTask 50.0f% completed 19:05:54.738 ThreadId=3 LongComputeTask 60.0f% completed 19:05:55.240 ThreadId=3 LongComputeTask 70.0f% completed 19:05:55.740 ThreadId=3 LongComputeTask 80.0f% completed 19:05:56.240 ThreadId=3 LongComputeTask 90.0f% completed 19:05:56.740 ThreadId=3 LongComputeTask 100.0f% completed 19:05:56.740 ThreadId=3 LongComputeTask completed","title":"Using AutoResetEvent"},{"location":"archives/2015/2015-12-26-tasks/","tags":"patterns","text":"Testing usage of Tasks today. using System ; using System.Threading ; using System.Threading.Tasks ; namespace TestTasks { class TasksTester { private void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } private void DoWork( object e) { LogMsg( \"Background worker starting\" ); float percentDone = 0.0f; for ( int i = 0; i < 10; i++) { Thread.Sleep(200); percentDone += 10.0f; } LogMsg( \"Background worker completed\" ); AutoResetEvent ae = e as AutoResetEvent; ae.Set(); } // RunTest // // Function run by main thread // Main thread sets up the background worker instance // and fires it off public void RunTest() { AutoResetEvent myFlag = new AutoResetEvent( false ); //Action<object> myAction = DoWork; //var myBkTask = new Task(myAction, myFlag); var myBkTask = new Task( delegate { DoWork(myFlag); }); myBkTask.Start(); LogMsg( \"Main thread worker waiting\" ); myFlag.WaitOne(); LogMsg( \"Main thread worker completed\" ); } // Main // Start up a background worker test instance static void Main( string [] args) { var testWkr = new TasksTester(); testWkr.RunTest(); } } } The output is- 19:05:47.041 ThreadId=1, Main thread worker waiting 19:05:47.060 ThreadId=3, Background worker starting 19:05:49.108 ThreadId=3, Background worker completed 19:05:49.108 ThreadId=1, Main thread worker completed","title":"Using Tasks"},{"location":"archives/2015/2015-12-27-tasks2/","tags":"patterns","text":"Testing with Tasks again. using System ; using System.Threading ; using System.Threading.Tasks ; namespace TestTasks2 { class TasksTester { private void LogMsg( string msg, params object [] args) { Console.Out.Write( \"{0} ThreadId={1} \" , DateTime.Now.ToString( \"HH:MM:ss.fff\" ), Thread.CurrentThread.ManagedThreadId); Console.Out.WriteLine(msg, args); } private void DoWork() { LogMsg( \"Background worker starting\" ); float percentDone = 0.0f; for ( int i = 0; i < 10; i++) { Thread.Sleep(200); percentDone += 10.0f; } LogMsg( \"Background worker completed\" ); } // RunTest // // Function run by main thread // Main thread sets up the background worker instance // and fires it off public void RunTest() { var myBkTask = new Task(DoWork); var myBkTask2 = new Task(DoWork); myBkTask.Start(); myBkTask2.Start(); LogMsg( \"Main thread worker waiting\" ); myBkTask.Wait(); myBkTask2.Wait(); LogMsg( \"Main thread worker completed\" ); } // Main // Start up a background worker test instance static void Main( string [] args) { var testWkr = new TasksTester(); testWkr.RunTest(); } } } The output- 19:05:48.736 ThreadId=4, Background worker starting 19:05:48.721 ThreadId=1, Main thread worker waiting 19:05:48.735 ThreadId=3, Background worker starting 19:05:50.752 ThreadId=4, Background worker completed 19:05:50.762 ThreadId=3, Background worker completed 19:05:50.762 ThreadId=1, Main thread worker completed","title":"Using Tasks-2"},{"location":"archives/2016/2016-04-02-lky-on-management/","tags":"patterns","text":"Wisdom distilled from some of the great visionary Lee Kuan Yew's many speeches- Constantly Innovate \"Standing still is a sure way to extinction.\" \"We have to move upwards to new niches, find a new path to succeed. If we succeed, others will later follow our path but first, we must work out that path and be succeessful. We should not brag about our strategies, especially before they have worked... we must quietly sort our options to test out and implement them. Some will fail, but the key ones must succeed if we are to stay ahead and be a beacon for progress.\" On Talent \"I have learned that one high-calibre mind in charge of a Ministry makes the difference between success and failure of a major project. A top mind, given a task, brings together a group of other able men, organises them into a cohesive team, and away the project goes...\" \"Whenever I had lesser men in charge, the average or slightly above-average, I have had to keep pushing and probing them, to review problems, to identify roadblocks, to suggest solutions, to come back and to discover that less than the best has been achieved. To be exasperated and, often to be totally frustrated, is the price for not having an able and talented man in charge.\" \"(English financier) Gresham pointed that bad money drives out good money from circulation. Well, bad leaders drive out good men from high positions.\" \"Ability can be assessed fairly accurately by a person's academic record and achievements at work. Character is not so easily measured. After some successes but too many failures, I concluded that it was more important, though more difficult, to assess a person's character.\" On Plateaus \"What I fear is complacency. When things always become better, people tend to want more for less work.\" Deliver What You Promise \"What you say, you must mean, and what you mean, you must deliver. I always understate what I intend to do and overachieve.\" Make Sure Every Button Works \"I want to make sure that every button works and even if you are using it only once in a while, please make sure every morning that it works. And if it doesn't when I happen to be around, then somebody is going to be in for a tough time because I do not want sloppiness.\" Free of Ideology \"If there was one formula for our success, it was that we were constantly studying how to make things work, or how to make them work better. I was never a prisoner of any theory. What guided me were reason and reality. The acid test I applied to every theory or scheme was, would it work? This was the golden thread that ran through my years in office.\"","title":"LKY on Management"},{"location":"archives/2016/2016-04-02-lky-on-management/#constantly-innovate","text":"\"Standing still is a sure way to extinction.\" \"We have to move upwards to new niches, find a new path to succeed. If we succeed, others will later follow our path but first, we must work out that path and be succeessful. We should not brag about our strategies, especially before they have worked... we must quietly sort our options to test out and implement them. Some will fail, but the key ones must succeed if we are to stay ahead and be a beacon for progress.\"","title":"Constantly Innovate"},{"location":"archives/2016/2016-04-02-lky-on-management/#on-talent","text":"\"I have learned that one high-calibre mind in charge of a Ministry makes the difference between success and failure of a major project. A top mind, given a task, brings together a group of other able men, organises them into a cohesive team, and away the project goes...\" \"Whenever I had lesser men in charge, the average or slightly above-average, I have had to keep pushing and probing them, to review problems, to identify roadblocks, to suggest solutions, to come back and to discover that less than the best has been achieved. To be exasperated and, often to be totally frustrated, is the price for not having an able and talented man in charge.\" \"(English financier) Gresham pointed that bad money drives out good money from circulation. Well, bad leaders drive out good men from high positions.\" \"Ability can be assessed fairly accurately by a person's academic record and achievements at work. Character is not so easily measured. After some successes but too many failures, I concluded that it was more important, though more difficult, to assess a person's character.\"","title":"On Talent"},{"location":"archives/2016/2016-04-02-lky-on-management/#on-plateaus","text":"\"What I fear is complacency. When things always become better, people tend to want more for less work.\"","title":"On Plateaus"},{"location":"archives/2016/2016-04-02-lky-on-management/#deliver-what-you-promise","text":"\"What you say, you must mean, and what you mean, you must deliver. I always understate what I intend to do and overachieve.\"","title":"Deliver What You Promise"},{"location":"archives/2016/2016-04-02-lky-on-management/#make-sure-every-button-works","text":"\"I want to make sure that every button works and even if you are using it only once in a while, please make sure every morning that it works. And if it doesn't when I happen to be around, then somebody is going to be in for a tough time because I do not want sloppiness.\"","title":"Make Sure Every Button Works"},{"location":"archives/2016/2016-04-02-lky-on-management/#free-of-ideology","text":"\"If there was one formula for our success, it was that we were constantly studying how to make things work, or how to make them work better. I was never a prisoner of any theory. What guided me were reason and reality. The acid test I applied to every theory or scheme was, would it work? This was the golden thread that ran through my years in office.\"","title":"Free of Ideology"},{"location":"archives/2016/2016-04-02-tech-to-study/","tags":"tech, study","text":"A short list of tech to study and review. Redis node.js javascript jQuery Bootstrap git github Jekyll Ethereum Bitcoin","title":"Tech to Study"},{"location":"archives/2016/2016-04-03-insprirational-quotes/","tags":"quotes","text":"The Man In The Arena \"It is not the critic who counts; not the man who points out how the strong man stumbles, or where the doer of deeds could have done them better. The credit belongs to the man who is actually in the area, whose face is marred by dust and sweat and blood; who strives valiantly; who errs, who comes short again and again, because there is no effort without error and shortcoming; but who does actually strive to do the deeds; who knows great enthusiams, the great devotions; who spends himself in a worthy cause; who at the best knows in the end the triumph of high achievement, and who at the worst, if he fails, at least fails while daring greatly, so that his place shall never be with those cold and timid souls who neither know victory or defeat.\" Thedore Roosevelt No Limits . \"If you always put limit on everything you do, physical or anything else it will spread into your work and into your life. There are no limits. There are only plateaus, and you must not stay there, you must go beyond them.\" Bruce Lee Never Forget . Absort what is useful. Discard what is not. Add what is uniquely your own.\" Bruce Lee","title":"Inspirational Quotes"},{"location":"archives/2016/2016-04-03-insprirational-quotes/#the-man-in-the-arena","text":"\"It is not the critic who counts; not the man who points out how the strong man stumbles, or where the doer of deeds could have done them better. The credit belongs to the man who is actually in the area, whose face is marred by dust and sweat and blood; who strives valiantly; who errs, who comes short again and again, because there is no effort without error and shortcoming; but who does actually strive to do the deeds; who knows great enthusiams, the great devotions; who spends himself in a worthy cause; who at the best knows in the end the triumph of high achievement, and who at the worst, if he fails, at least fails while daring greatly, so that his place shall never be with those cold and timid souls who neither know victory or defeat.\" Thedore Roosevelt","title":"The Man In The Arena"},{"location":"archives/2016/2016-04-03-insprirational-quotes/#no-limits","text":". \"If you always put limit on everything you do, physical or anything else it will spread into your work and into your life. There are no limits. There are only plateaus, and you must not stay there, you must go beyond them.\" Bruce Lee","title":"No Limits"},{"location":"archives/2016/2016-04-03-insprirational-quotes/#never-forget","text":". Absort what is useful. Discard what is not. Add what is uniquely your own.\" Bruce Lee","title":"Never Forget"},{"location":"archives/2016/2016-04-07-getting-things-done/","tags":"patterns","text":"From the book \"Getting Things Done Secrets\" by Rus Slater- If you want to get on in your career or your home life you will need to get things done. In the modern world, however, there are lots of different people wanting lots of different things to be done, and you can't do everything for everyone unless you get much better at a number of different things. Knowing what things to do Recognize that everyone only has 86,400 seconds a day. Use them wisely. Time waits for no one. Ask for clear instructions . If someone asks you to do something for them, make sure you are 100% certain about what's required. Whenever possible, get a written instruction or request- the act of writing down instructions makes people think more carefully and fully about what they actually want. Try to get the request in as much specific detail as possible. Getting it right first time is always better than having to come back and do it again. See the relevance of the bigger picture . Knowing how your tasks relate to the bigger picture helps both you and your boss to organize the workload. Plan for output, not activity. Aim for specific achievements . It is very satisfying to see that you have achieved something, rather than just spending time doing something. DREAM to get more done. Delegate it. Refuse it. Escalate it. Action it. Make a time for it. Have a personal vision or mission . Write down your long-term career goals and what you need to do in the medium term to achieve them. Make to-do lists. Find out how others do it . It is always worth investigating how others may have done a task in the past. Then compare it with your task and use your judgement to decide whether to follow a tried and trusted method or to develop a new, better way. Know how to KISS- keep it short and simple . If you have a choice between a simple and a complex way to do something, always go for the simple way. Look at effort versus payoff. Judge every task by cost and reward . Work first on the tasks with the least cost and highest return. By assessing the ratio of effort to payoff, you ensure that you are doing thing that are worthwhile. Go for quick wins . A quick win is a personal motivator. You get to tick something off the to do list, which means you have a little less left to do and something to say you have finished. Learn to say no . Dont say 'yes' to every request. If we say yes to every request, one of two things will happen- either we will end up working 24 hours a day or we will end up letting people down because we said yes to something we cannot do.","title":"Getting Things Done"},{"location":"archives/2016/2016-04-07-getting-things-done/#knowing-what-things-to-do","text":"Recognize that everyone only has 86,400 seconds a day. Use them wisely. Time waits for no one. Ask for clear instructions . If someone asks you to do something for them, make sure you are 100% certain about what's required. Whenever possible, get a written instruction or request- the act of writing down instructions makes people think more carefully and fully about what they actually want. Try to get the request in as much specific detail as possible. Getting it right first time is always better than having to come back and do it again. See the relevance of the bigger picture . Knowing how your tasks relate to the bigger picture helps both you and your boss to organize the workload. Plan for output, not activity. Aim for specific achievements . It is very satisfying to see that you have achieved something, rather than just spending time doing something. DREAM to get more done. Delegate it. Refuse it. Escalate it. Action it. Make a time for it. Have a personal vision or mission . Write down your long-term career goals and what you need to do in the medium term to achieve them. Make to-do lists. Find out how others do it . It is always worth investigating how others may have done a task in the past. Then compare it with your task and use your judgement to decide whether to follow a tried and trusted method or to develop a new, better way. Know how to KISS- keep it short and simple . If you have a choice between a simple and a complex way to do something, always go for the simple way. Look at effort versus payoff. Judge every task by cost and reward . Work first on the tasks with the least cost and highest return. By assessing the ratio of effort to payoff, you ensure that you are doing thing that are worthwhile. Go for quick wins . A quick win is a personal motivator. You get to tick something off the to do list, which means you have a little less left to do and something to say you have finished. Learn to say no . Dont say 'yes' to every request. If we say yes to every request, one of two things will happen- either we will end up working 24 hours a day or we will end up letting people down because we said yes to something we cannot do.","title":"Knowing what things to do"},{"location":"archives/2016/2016-05-01-sg-math-primary-five-ratio/","tags":"math","text":"As my kid has been progressing through the Singapore school system, I've never been seriously challenged by primary school math until now. I was embarrassingly stomped by the following question. It took me some time to figure it out. I've posted the question and answer for everyone's benefit. Mr Lee had some red and white paint. 1/3 of the paint was red. He used 1/2 of the red paint and 5/6 of the white paint. In the end, he had a total of 10 liters of paint left. How much paint did he have at first? This question gave me a real headache until I found a way out. I've generated the solution in this pdf here","title":"Singapore Math Primary 5 Five Ratio Question"},{"location":"archives/2016/2016-05-02-sg-math-second_math_question/","tags":"history","text":"Second challenge question from my kid. Again it took me some time to work out the problem. Singapore math questions are rather more like puzzles than math questions. What practical value do figuring out who has how many pencils serve in real life? To solve these questions, one needs some basic intelligence and an ample supply of heart- also known as perservence- or grit. Without grit, a weak-minded individual would just give up. And that's exactly what the Singapore government wants. Singapore math serves nothing more than to separate the strong from the weak. It is a simply a basic sorting tool for this meritocractic society. My kid asked me how can I do my job if I get stomped by a primary school question? First, the Singapore math question to me is more of a logic puzzle than a math question. And second, no one knows everything. However, the key point is that we do not stay stomped. We use everything in our resources to solve the problem. We attack the problem from different angles. Sooner or later until ceaseless attacks, the solution reveals itself. We are only defeated if we give up. Kenneth had a total of 576 black and red pens in the ratio 9:7. After he had given away an equal number of each type of pens, the number of black and red pens left was in the ratio 7:4. How many pens did he give away altogether? I've generated the solution in this pdf here","title":"Singapore Math Primary 5 Second Math Question"},{"location":"archives/2016/2016-09-11-fifteen-years-on/","tags":"history","text":"For the Public Record A quick look at the calendar shows it's that time of the year again. The date creeps up on you. This year, however- marks the fifteenth year since that horrible day- a day that's been seared into my memory. Fifteen years is a great number of years that's passed. Volumes have already been written to record, to analyse, and to reflect on what happened that day. It seems a proper civic duty to add my own recollections of that day from my point of view to the public record. For this reason- I record the following entry. Like Any Other Day September 11, 2001- was just like any other early autumn day. I was a young Goldman Sachs programmer heading into work that morning in Lower Manhattan. I had recently transferred to the electronic trading team and was looking forward to a day of testing GS's system with Cantor Fitzgerald's eSpeed. I was slightly peeved when the N train I took to work from Brooklyn stopped without explanation at Pacific Street. Thinking that it was a usual MTA malfunction, I walked over to the nearby Atlatnic Street station to transfer to the uptown 4 train. This train took me to the Battery Park Bowling Green station- which was only 2 blocks away the offices at 125 Broad Street. The time was 9:15AM. I remember the exact time because at that point I was slightly peeved at being made tardy for work by the failing public transit system. As I rushed up the station exit staircase to make up for lost time, a work colleague grabbed me on the shoulder. He was heading in the opposite direction on the way down the station staircase. In terse words, he told me to go home. Puzzled, I asked why. He said- \"Look up. Two planes crashed into the World Trade Center.\" and quickly disappeared down the stairs. \"Look Up\" Right at the top of the station exit stairs, I arced my head up and looked straight up Broadway. Against a cloudless blue sky, I saw huge rising plumes of smoke. Fortunately, I was a tech enthusiast- and happened to be carrying a digital camera at the time. Remember- this was back in 2001- in the era before iPhones and before iPods. I took this snapshot- Though my colleague had told me what happened, it just didn't register that what he said was real. In 2001, terrorism was the sort of news event that only happened in the Middle East or Africa. Even though there was a WTC bombing in 1994, it was already a forgotten memory. And because of that, I did not feel any fear. \"Just Get To Work\" It never occurred to me to leave. My objective- quite stupefying now looking back- but oddly rational at the time- was to get to work . It must be the years of social conditioning that makes someone show up to work even as the world burns. I walked two blocks eastward to Goldman Sach's office building at 85 Broad Sreet- and found a throng of people gathered at the entrance. It seemed that just about everyone had come down from the building. Unbeknownst to me at the time- but I learned a few days afterwards- my GS colleagues had just witnessed the second plane crash into the towers and were making their way out of the building as I was trying to make my way in. Seeing that my efforts to enter the office building would fail, I guessed that my absence from the office would be excused that day. At around 9:20AM, I took this snapshot of 85 Broad Street. At the time, there was no panic in the streets. People milled about in general confusion as they planned their next steps. Since there was no way then to get to work- I had no other destination than to walk up Broadway- towards the source of the smoke. Having a digital camera available at the time presented an opportunity that further egged me into taking a closer look at the smoke. As I made my way past Wall Street along Broadway, the skyscrapers blocked my view of the towers and I could not imagine what was on fire. At around 9:25AM, I took a third snapshot of the smoke above lower Manattan office buildings. Surreal The scene was surreal. With smoke in the skies, I saw what looked like pieces of paper floating down from the sky. As I walked further up Broadway, I finally reached Liberty Plaza. This plaza, with a clearing void of any buildings- finally allowed me to get a good view of the towers. What I saw dumbstruck me for a second. I saw a whole section of one tower was on fire. I raised my camera for this shot. I took another shot with the camera's digitial zoom turned on. I wasn't sure what I felt. It was a sense of disbelief. Was this all real? Even though I was witnessing the horror not more than a few hundred meters away, the whole scene did not feel real. It could be that I did not feel to be in any immediate danger. I did not feel the heat from the flames or the noxious fumes from its smoke. I did not feel horror- because the strange thing is that I could not imagine what horror it was to be inside the floors where the fires were burning. Adding to the surreality of the moment- were loose leaflets floating down weightlessly from the sky. They seem to float for an eternity as they fluttered earthbound. Then as I ambled around to get a better angle of the view, I saw the second tower appear from behind the first tower- looking like twin smoke stacks. The view from google maps from the exact same angle today looks like this- As I walked closer and closer to the towers, I finally met resistance at the corner of Liberty Plaza and Broadway. There a few of New York City's finest had cordoned off the area. I saw several firetrucks parked nearby- and took another quick snap facing west. With my path westward blocked by the authorities, I continued walking northward up Broadway. At the corner of Cortland and Broadway, I was able to catch another view of the burning towers. I took two snaps- At that point in time, I gazed at the scene for a few minutes- along with a growing throng of onlookers. Meanwhile, the fire burned away. I thought that the fire would be put out all right by the firefighters. Or the fire would just burn itself out. It was just a matter of time. Any other possibility had not entered my mind. Huge Dust Clouds After staring at the fire for a few minutes- with nothing much else going on, I thought to walk back to Broad Street for another look. As I was walking toward Broad Street, I noticed out of the corner of my eye an abnormally huge cloud of brownish dust in the air. I wondered where did that dust come from? It was only a minute or two afterwards that I thought the dust cloud could've come from secondary bomb attacks. I remember reading that was a favorite strategy of terrorists- attack first in one primary location, then as the victims wander out in confusion, attack them again with a secondary explosive device. I thought this huge dust cloud had come from a second wave of attacks. It was only then that I realised someone was trying to kill me . It got personal at this point. It was only then that I started to think about leaving the area. And if there were secondary explosive devices, I thought the best way out of Lower Manhattan was by way of the lower east shoreline- near South Street Seaport. And in the worst case scenario, if the situation got worse, I coud always jump into the river to escape any further conflagration. Stragglers Going Uptown I reached South Street- and took several pictures as I walked north. The first photo, takened at approximately 10:10AM shows the thick haze that just appeared - where all my previous photos showed clear blue skies. As I walked along, I overheard others say the towers fell down. I did not believe it. I took a look back- and only saw thick haze where the towers should appear. The thick smoke was so enveloping that I wasn't sure where were the towers. Walking further northward, I took another picture of the stragglers- like myself. No Sight of The Towers Once I passed under the shadow of Brooklyn Bridge, I immediately felt more secure. It was as if the bridge was a demarcation line between a war zone and everywhere else. As I reached Pike Street, I slowed down and looked back. I took several shots and none of them show the towers. The foreground of this photo shows what look a staging area for a squad of auxillary police.","title":"Fifteen Years On"},{"location":"archives/2016/2016-09-11-fifteen-years-on/#for-the-public-record","text":"A quick look at the calendar shows it's that time of the year again. The date creeps up on you. This year, however- marks the fifteenth year since that horrible day- a day that's been seared into my memory. Fifteen years is a great number of years that's passed. Volumes have already been written to record, to analyse, and to reflect on what happened that day. It seems a proper civic duty to add my own recollections of that day from my point of view to the public record. For this reason- I record the following entry.","title":"For the Public Record"},{"location":"archives/2016/2016-09-11-fifteen-years-on/#like-any-other-day","text":"September 11, 2001- was just like any other early autumn day. I was a young Goldman Sachs programmer heading into work that morning in Lower Manhattan. I had recently transferred to the electronic trading team and was looking forward to a day of testing GS's system with Cantor Fitzgerald's eSpeed. I was slightly peeved when the N train I took to work from Brooklyn stopped without explanation at Pacific Street. Thinking that it was a usual MTA malfunction, I walked over to the nearby Atlatnic Street station to transfer to the uptown 4 train. This train took me to the Battery Park Bowling Green station- which was only 2 blocks away the offices at 125 Broad Street. The time was 9:15AM. I remember the exact time because at that point I was slightly peeved at being made tardy for work by the failing public transit system. As I rushed up the station exit staircase to make up for lost time, a work colleague grabbed me on the shoulder. He was heading in the opposite direction on the way down the station staircase. In terse words, he told me to go home. Puzzled, I asked why. He said- \"Look up. Two planes crashed into the World Trade Center.\" and quickly disappeared down the stairs.","title":"Like Any Other Day"},{"location":"archives/2016/2016-09-11-fifteen-years-on/#look-up","text":"Right at the top of the station exit stairs, I arced my head up and looked straight up Broadway. Against a cloudless blue sky, I saw huge rising plumes of smoke. Fortunately, I was a tech enthusiast- and happened to be carrying a digital camera at the time. Remember- this was back in 2001- in the era before iPhones and before iPods. I took this snapshot- Though my colleague had told me what happened, it just didn't register that what he said was real. In 2001, terrorism was the sort of news event that only happened in the Middle East or Africa. Even though there was a WTC bombing in 1994, it was already a forgotten memory. And because of that, I did not feel any fear.","title":"\"Look Up\""},{"location":"archives/2016/2016-09-11-fifteen-years-on/#just-get-to-work","text":"It never occurred to me to leave. My objective- quite stupefying now looking back- but oddly rational at the time- was to get to work . It must be the years of social conditioning that makes someone show up to work even as the world burns. I walked two blocks eastward to Goldman Sach's office building at 85 Broad Sreet- and found a throng of people gathered at the entrance. It seemed that just about everyone had come down from the building. Unbeknownst to me at the time- but I learned a few days afterwards- my GS colleagues had just witnessed the second plane crash into the towers and were making their way out of the building as I was trying to make my way in. Seeing that my efforts to enter the office building would fail, I guessed that my absence from the office would be excused that day. At around 9:20AM, I took this snapshot of 85 Broad Street. At the time, there was no panic in the streets. People milled about in general confusion as they planned their next steps. Since there was no way then to get to work- I had no other destination than to walk up Broadway- towards the source of the smoke. Having a digital camera available at the time presented an opportunity that further egged me into taking a closer look at the smoke. As I made my way past Wall Street along Broadway, the skyscrapers blocked my view of the towers and I could not imagine what was on fire. At around 9:25AM, I took a third snapshot of the smoke above lower Manattan office buildings.","title":"\"Just Get To Work\""},{"location":"archives/2016/2016-09-11-fifteen-years-on/#surreal","text":"The scene was surreal. With smoke in the skies, I saw what looked like pieces of paper floating down from the sky. As I walked further up Broadway, I finally reached Liberty Plaza. This plaza, with a clearing void of any buildings- finally allowed me to get a good view of the towers. What I saw dumbstruck me for a second. I saw a whole section of one tower was on fire. I raised my camera for this shot. I took another shot with the camera's digitial zoom turned on. I wasn't sure what I felt. It was a sense of disbelief. Was this all real? Even though I was witnessing the horror not more than a few hundred meters away, the whole scene did not feel real. It could be that I did not feel to be in any immediate danger. I did not feel the heat from the flames or the noxious fumes from its smoke. I did not feel horror- because the strange thing is that I could not imagine what horror it was to be inside the floors where the fires were burning. Adding to the surreality of the moment- were loose leaflets floating down weightlessly from the sky. They seem to float for an eternity as they fluttered earthbound. Then as I ambled around to get a better angle of the view, I saw the second tower appear from behind the first tower- looking like twin smoke stacks. The view from google maps from the exact same angle today looks like this- As I walked closer and closer to the towers, I finally met resistance at the corner of Liberty Plaza and Broadway. There a few of New York City's finest had cordoned off the area. I saw several firetrucks parked nearby- and took another quick snap facing west. With my path westward blocked by the authorities, I continued walking northward up Broadway. At the corner of Cortland and Broadway, I was able to catch another view of the burning towers. I took two snaps- At that point in time, I gazed at the scene for a few minutes- along with a growing throng of onlookers. Meanwhile, the fire burned away. I thought that the fire would be put out all right by the firefighters. Or the fire would just burn itself out. It was just a matter of time. Any other possibility had not entered my mind.","title":"Surreal"},{"location":"archives/2016/2016-09-11-fifteen-years-on/#huge-dust-clouds","text":"After staring at the fire for a few minutes- with nothing much else going on, I thought to walk back to Broad Street for another look. As I was walking toward Broad Street, I noticed out of the corner of my eye an abnormally huge cloud of brownish dust in the air. I wondered where did that dust come from? It was only a minute or two afterwards that I thought the dust cloud could've come from secondary bomb attacks. I remember reading that was a favorite strategy of terrorists- attack first in one primary location, then as the victims wander out in confusion, attack them again with a secondary explosive device. I thought this huge dust cloud had come from a second wave of attacks. It was only then that I realised someone was trying to kill me . It got personal at this point. It was only then that I started to think about leaving the area. And if there were secondary explosive devices, I thought the best way out of Lower Manhattan was by way of the lower east shoreline- near South Street Seaport. And in the worst case scenario, if the situation got worse, I coud always jump into the river to escape any further conflagration.","title":"Huge Dust Clouds"},{"location":"archives/2016/2016-09-11-fifteen-years-on/#stragglers-going-uptown","text":"I reached South Street- and took several pictures as I walked north. The first photo, takened at approximately 10:10AM shows the thick haze that just appeared - where all my previous photos showed clear blue skies. As I walked along, I overheard others say the towers fell down. I did not believe it. I took a look back- and only saw thick haze where the towers should appear. The thick smoke was so enveloping that I wasn't sure where were the towers. Walking further northward, I took another picture of the stragglers- like myself.","title":"Stragglers Going Uptown"},{"location":"archives/2016/2016-09-11-fifteen-years-on/#no-sight-of-the-towers","text":"Once I passed under the shadow of Brooklyn Bridge, I immediately felt more secure. It was as if the bridge was a demarcation line between a war zone and everywhere else. As I reached Pike Street, I slowed down and looked back. I took several shots and none of them show the towers. The foreground of this photo shows what look a staging area for a squad of auxillary police.","title":"No Sight of The Towers"},{"location":"archives/2016/2016-09-18-get-through-hard/","tags":"history","text":"To get to easy, you have to get through hard.","title":"Get through hard"},{"location":"archives/2016/2016-10-08-the-management-masterclass/","tags":"management","text":"From the book \"The Management Masterclass\" by Emma De Vita- Authenticity To be authentic is to be real, genuine, trustworthy. An authentic person is true to his or her own character. Sell your differences. Remember your roots. Break the mould. Communicator Make time and take time. Clear you rmind. Give your undivided attention. Don't interrupt. Ask what they mean. Check body language. Keep your opinions to yourself. Check what they really feel. Hear what's not being said. Play back what you've heard. Getting stuff done Decide on just a few things to get done. Slow down- give each task the time it deserves.","title":"The Management Masterclass"},{"location":"archives/2016/2016-10-09-the-spirit-of-kaizen/","tags":"management, kaizen","text":"From the book \"The Spirit of Kaizen\" by Robert Maurer- The key idea from this book on Kaizen is that people are scared by big changes. Instead of making big changes to fix big problems, make small changes instead. First, small changes are quick and easy to implement and do not meet resistance by scaring people. Second, small changes over time is similar to compound interest- the small changes accumulate giant effects. When making a change- there are two basic strategies- innovation and kaizen. Innovation calls for a radical, immediate rethink of the status quo. Kaizen, on the other hand, asks for nothing other than small, doable steps toward improvement. Continuous improvement says- Look for hundreds of small things you can improve. Look for improvements on existing jobs with your present equipment. Kaizen says- Use exiting resources Ask team members to participate Remain alert for problems to solve Look for ways to improve customer service Make very very small steps toward change Jim Collin's Good To Great says- We kept thinking we shold find the 'one big thing,' the miracle moment that defined breakthrough....But...no matter how dramatic the end reslt, the good-to-great transformation never happened in one fell swoop. There was no single defining action, no grand program, no one killer innovation, no solitary lucky break, no wrenching revolution. Good to great comes about by a cumulative process- step by step, action by action, decision by decision, turn by turn of the flywheel- that adds up to sustains and spectacular results.* High-reliability organisations know they cannot afford to play games of secrecy. Their attention to small mistakes flows from the recognition that human beings, no matter how gifted, are fallible. Instead of expecting staff members to be perfect, HROs require them to be transparent... If you make a mistake, tell us so that we can prevent a bigger problem. FIX THE PROBLEM, NOT THE BLAME.","title":"The Spirit of Kaizen"},{"location":"archives/2016/2016-12-08-riskfree-profit-strategies/","tags":"strategy","text":"Working in the shadow of traders, I overhear some of their money making strategies. So yesterday at the Washington Zoo, I spotted a perfect money making opportunity reminiscent of traders' strategies. There was a souvenir penny-engraving machine that presses souvenir pennies for 50 cents plus the one penny. Next to it was a machine that makes change for one and five dollar bills. Given a dollar bill, the machine returns 4 quarters and 2 pennies. Given a 5 dollar bill, the machine returns 20 quarters and 10 pennies. Whoa!!! That's a mega opportunity the size of a dump truck. In rates and currency markets, if there is even an opportunity to exploit risk free arbitrages of a single penny, traders would press this opportunity to the full- using leverage (borrowed funds via repos). I quickly exchanged two five-dollar bills for a 20 cents risk-free profit. There was a small risk that the machine might run out of quarters (liquidity risk) which would've sunk my profits. However, I lost my hard-earned 20 cents gains immediately when my daughter asked to get a drink from the neighboring soda machine.","title":"Risk-free Profit Strategies"},{"location":"archives/2016/2016-12-30-revisting-generic-collections/","tags":"patterns","text":"Earlier I asked if generic collections were faster than non-generic collections? I cooked up a quick test to confirm my suspicions that non-generics were slower because of the work it needs to box primitives and then add the reference to the collection- whereas for generic collections, it just needed to add the primitive to its own memory allocation. But then a colleague asked- how about performance for collections of objects? Wouldn't a generic collection do the same as a non-generic collection? Both collections only contain references to objects on the heap- and there should be no difference, right? I updated my old test to check this assertion. \ufeff using System ; using System.Collections.Generic ; using System.Collections ; namespace TestGenericCollection { class TestGenericListVsArrayList { const int _numItems = 10000000; static void TimeArrayListOfObjects() { Console.Out.WriteLine( \"TimeArrayListOfObjects start\" ); DateTime dtInsertStart = DateTime.Now; ArrayList stringList = new ArrayList(); for ( int i = 0; i < _numItems; i++) { stringList.Add(Convert.ToString(i)); } DateTime dtReadStart = DateTime.Now; for ( int j = 0; j < _numItems; j++) { string retrievedInt = ( string )stringList[j]; if (j % _numItems/10 == 0) Console.Out.Write( \".\" ); } ShowStats(dtInsertStart, dtReadStart, \"ArrayListOfObjects\" ); } static void TimeArrayListOfPrimitives() { Console.Out.WriteLine( \"TimeArrayListOfPrimitives start\" ); DateTime dtInsertStart = DateTime.Now; ArrayList intList = new ArrayList(); for ( int i = 0; i < _numItems; i++) { intList.Add(i); } DateTime dtReadStart = DateTime.Now; for ( int j = 0; j < _numItems; j++) { int retrievedInt = ( int )intList[j]; if (j % _numItems/10 == 0) Console.Out.Write( \".\" ); } ShowStats(dtInsertStart, dtReadStart, \"ArrayListOfPrimitives\" ); } static void TimeGenericListOfObjects() { Console.Out.WriteLine( \"TimeGenericListOfObjects start\" ); DateTime dtInsertStart = DateTime.Now; List< string > intList = new List< string >(); for ( int i = 0; i < _numItems; i++) { intList.Add(Convert.ToString(i)); } DateTime dtReadStart = DateTime.Now; for ( int j = 0; j < _numItems; j++) { string retrievedInt = intList[j]; if (j % _numItems/10 == 0) Console.Out.Write( \".\" ); } ShowStats(dtInsertStart, dtReadStart, \"GenericListOfObjects\" ); } static void TimeGenericListOfPrimitives() { Console.Out.WriteLine( \"TimeGenericListOfPrimitives start\" ); DateTime dtInsertStart = DateTime.Now; List< int > intList = new List< int >(); for ( int i = 0; i < _numItems; i++) { intList.Add(i); } DateTime dtReadStart = DateTime.Now; for ( int j = 0; j < _numItems; j++) { int retrievedInt = intList[j]; if (j % _numItems / 10 == 0) Console.Out.Write( \".\" ); } ShowStats(dtInsertStart, dtReadStart, \"GenericListOfPrimitives\" ); } /// <summary> /// ShowStats show time procedure took to insert 1M items and to read 1M items /// </summary> /// <param name=\"dtInsertStart\">Time when insert started</param> /// <param name=\"dtReadStart\">Time when read started</param> /// <param name=\"msg\">Name of procedure</param> static void ShowStats(DateTime dtInsertStart, DateTime dtReadStart, string msg) { DateTime dtTimeNow = DateTime.Now; TimeSpan wholeTime = dtTimeNow.Subtract(dtInsertStart); TimeSpan insertTime = dtReadStart.Subtract(dtInsertStart); TimeSpan readTime = dtTimeNow.Subtract(dtReadStart); Console.Out.WriteLine( \"{3} took {0} ms in total, {1} ms to insert, {2} to read\\n\" , wholeTime.TotalMilliseconds, insertTime.TotalMilliseconds, readTime.TotalMilliseconds, msg); } static void Main( string [] args) { switch (args[0]) { case \"1\" : TimeGenericListOfPrimitives(); break ; case \"2\" : TimeGenericListOfObjects(); break ; case \"3\" : TimeArrayListOfPrimitives(); break ; case \"4\" : TimeArrayListOfObjects(); break ; } } } } The result? >TestGenerics.exe 1 TimeGenericListOfPrimitives start .......... GenericListOfPrimitives took 358.8006 ms in total, 202.8004 ms to insert, 156.0002 to read >TestGenerics.exe 2 TimeGenericListOfObjects start .......... GenericListOfObjects took 4336.8077 ms in total, 4180.8074 ms to insert, 156.0003 to read >TestGenerics.exe 3 TimeArrayListOfPrimitives start .......... ArrayListOfPrimitives took 2324.4041 ms in total, 2168.4038 ms to insert, 156.0003 to read TestGenerics.exe 4 TimeArrayListOfObjects start .......... ArrayListOfObjects took 4508.408 ms in total, 4352.4077 ms to insert, 156.0003 to read It's fairly conclusive. For collections of primitives (ints, longs, etc)- generic collections are definitely much faster than non-generic collections- because there is no need to box items. For collections of objects- generic collections show no substantial improvement over non-generic collections.","title":"Revisiting Generic Collections"},{"location":"archives/2017/2017-03-21-timing_numpy/","tags":"patterns","text":"I've been hearing a lot of good things about NumPy and Python- so much so that I've finally had to give it a try. What's so good about NumPy? For one thing, its built-in array data structure. Given that data arrays are one continous block of memory, referencing numbers directly in arrays would be much faster than referencing them in Python's built-in lists- which would really be a list of pointers to the real location of data. \ufeff from timeit import timeit test_list_loop = ''' alist = [0] * 1000 for i in xrange(0, len(alist)): alist[i] += 1 ''' test_numpy_arrays = ''' a = np.zeros(1000) b = a+1 ''' print( timeit( stmt=test_numpy_arrays, setup= ' import numpy as np ' , number=100000 ) ) print( timeit( stmt=test_list_loop, number=100000 ) ) The result? 0.680721998215 7.49408698082 It's fairly conclusive. NumPy arrays are 11 times faster than Python lists. No contest.","title":"Timing NumPy"},{"location":"archives/2017/2017-04-23-the-tao-of_charlie-munger/","tags":"patterns","text":"From the book \"The Tao of Charlie Munger\" by David Clark. Waiting It's waiting that helps you as an investor, and a lot of people just can't stand to wait. When to Bet Heavily You should remember that good ideas are rare- when the odds are greatly in your favor, bet heavily. The Herd Mimicking the herd invites regression to the mean.","title":"The Tao of Charlie Munger"},{"location":"archives/2017/2017-04-23-the-tao-of_charlie-munger/#waiting","text":"It's waiting that helps you as an investor, and a lot of people just can't stand to wait.","title":"Waiting"},{"location":"archives/2017/2017-04-23-the-tao-of_charlie-munger/#when-to-bet-heavily","text":"You should remember that good ideas are rare- when the odds are greatly in your favor, bet heavily.","title":"When to Bet Heavily"},{"location":"archives/2017/2017-04-23-the-tao-of_charlie-munger/#the-herd","text":"Mimicking the herd invites regression to the mean.","title":"The Herd"},{"location":"archives/2017/2017-05-14-technologies-at-a-glance/","tags":"patterns","text":"With so many buzzwords coming up every year, it's very easy to lose track of what's what. A technologist, like any professional, must keep reading to keep abreast of new developments. As homework for myself, I've created an easy-to-read guide below to organize each specific technology in its proper space. Technology C# Java Python Javascript Php IOC Inversion of Control Spring Dagger Guice Unit Testing Jasmine Mocha Mocking Moq RhinoMocks unittest.mock ORM Peewee WebApi NancyFX Flask Django Nodejs Profiling","title":"Technologies at a Glance"},{"location":"archives/2017/2017-06-03-fooled-by-randomness/","tags":"patterns","text":"Nassim Tabeb's \"Fooled By Randomness\" is such a great book, I thought I'd save some great passages here. On attributing brilliance to success: A few years ago, when I told one A, a then Master-of-the-Universe type, that track records were less relevant than he thought, he found the remark so offensive that he violently flung his cigarette lighter in my direction. The episode taught me a lot. Remember that nobody accepts randomness in his own success, only failure. His ego was pumped up as he was heading up a department of \"great traders\" who were then temporarily making a fortune in the markets and attributing the idea to the sounding of their business, their insights, or their intelligence. They subsequently blew up during the harsh New York winter of 1994 (it was the bond market crash that followed the surprise interest rate hike by Alan Greenspan). The interesting part is that several years later I can hardly find any of them still trading (ergodicity). On cycles: Recall that some economists call the rare event a \"peso problem.\" The designation peso problem does not appear to be undeservedly stereotypical. Things have not gotten better since the early 1980s with the currency of the United States' southern neighbor. Long periods of stability draw hordes of bank currency traders and hedge fund operators to the calm waters of the Mexican peso; they enjoy owning the currency because of the high interest rate it commands. Then they \"unexpectedly\" blow up, lose money for investors, lose their jobs, and switch careers. Then a new period of stability sets in. New currency traders come in with no memory of the bad event. They are drawn to the Mexican peso and the story repeats itself. On asymmetry: I was once asked in one of those meetings to express my views on the stock market. I state, not without a modicum of pomp, that I believed that the market would go slightly up over the next week with a high probability. How high? \"About 70%\". Clearly, that was a very strong opinion. But then someone interjected. \"But Nassim, you just boasted being short a very large quantity of SP500 futures, making a bet that the market would go down. What made you change your mind?\" \"I did not change my mind! I have a lot of faith in my bet! As a matter of fact I now feel like selling even more!\" The other employees in the room seemed utterly confused. \"Are you bullish or are you bearish?\" I was asked by the strategist. I replied that I could not understand the words bullish and bearish outside of their purely zoological consideration.... my opinion was that the market was more likely to go up (\"I would be bullish\"), but that it was preferably to short it (\"I would be bearish\"), because, in the event of its going down, it could go down a lot. Suddently, the few traders in the room understood my opinion and started voicing similar opinions. And I was not forced to come back to the following discussion. Let us assume that the reader shared my opinion, that the market over the next week had a 70% probability of going up and 30% probability of going down. However, let us say that it would go up by 1% on average, while it could go down by an average of 10%. What would the reader do? Is the reader bullish or bearish? Accordingly, bullish or bearish are terms used by people who do not engage in practicing uncertainty, like the television commentators, or those who have no experience in handling risk.","title":"Fooled By Randomness"},{"location":"archives/2017/2017-06-03-fooled-by-randomness/#recall-that-some-economists-call-the-rare-event-a-peso-problem-the-designation-peso-problem-does-not-appear-to-be-undeservedly-stereotypical-things-have-not-gotten-better-since-the-early-1980s-with-the-currency-of-the-united-states-southern-neighbor-long-periods-of-stability-draw-hordes-of-bank-currency-traders-and-hedge-fund-operators-to-the-calm-waters-of-the-mexican-peso-they-enjoy-owning-the-currency-because-of-the-high-interest-rate-it-commands-then-they-unexpectedly-blow-up-lose-money-for-investors-lose-their-jobs-and-switch-careers-then-a-new-period-of-stability-sets-in-new-currency-traders-come-in-with-no-memory-of-the-bad-event-they-are-drawn-to-the-mexican-peso-and-the-story-repeats-itself","text":"On asymmetry: I was once asked in one of those meetings to express my views on the stock market. I state, not without a modicum of pomp, that I believed that the market would go slightly up over the next week with a high probability. How high? \"About 70%\". Clearly, that was a very strong opinion. But then someone interjected. \"But Nassim, you just boasted being short a very large quantity of SP500 futures, making a bet that the market would go down. What made you change your mind?\" \"I did not change my mind! I have a lot of faith in my bet! As a matter of fact I now feel like selling even more!\" The other employees in the room seemed utterly confused. \"Are you bullish or are you bearish?\" I was asked by the strategist. I replied that I could not understand the words bullish and bearish outside of their purely zoological consideration.... my opinion was that the market was more likely to go up (\"I would be bullish\"), but that it was preferably to short it (\"I would be bearish\"), because, in the event of its going down, it could go down a lot. Suddently, the few traders in the room understood my opinion and started voicing similar opinions. And I was not forced to come back to the following discussion. Let us assume that the reader shared my opinion, that the market over the next week had a 70% probability of going up and 30% probability of going down. However, let us say that it would go up by 1% on average, while it could go down by an average of 10%. What would the reader do? Is the reader bullish or bearish? Accordingly, bullish or bearish are terms used by people who do not engage in practicing uncertainty, like the television commentators, or those who have no experience in handling risk.","title":"Recall that some economists call the rare event a &quot;peso problem.&quot;  The\ndesignation peso problem does not appear to be undeservedly stereotypical.\nThings have not gotten better since the early 1980s with the currency of\nthe United States&#39; southern neighbor.  Long periods of stability draw hordes\nof bank currency traders and hedge fund operators to the calm waters of\nthe Mexican peso; they enjoy owning the currency because of the high interest\nrate it commands.  Then they &quot;unexpectedly&quot; blow up, lose money for \ninvestors, lose their jobs, and switch careers.  Then a new period of \nstability sets in.  New currency traders come in with no memory of the bad\nevent.  They are drawn to the Mexican peso and the story repeats itself.\n"},{"location":"archives/2017/2017-06-08-python_import/","tags":"patterns","text":"What's the difference between: 1) import numpy, 2) import numpy as np, and 3) from numpy import * ? First example: import numpy Second example: import numpy as np Third example: from numpy import * The first example allows usage of all sub-modules and functions in the numpy module- but they can only be accessed by numpy.method(). The second example is the same as the first example- but also sets up np as alias thru which to access the numpy functions- example: np.method(). The third example imports all sub-modules and functions from the numpy module into the local namespace. This allows using numpy's methods without namespace qualifications- example: method(). However, this has the disadvantage of complicating the local namespace with common method names- and overriding methods with the same names from other modules.","title":"Imports in Python"},{"location":"archives/2017/2017-06-09-setting-up-vim-for-python/","tags":"python","text":"While I'm enthusiastic with using Vim, I'm afraid that my many years of using Visual Studio's Intellisense has spoiled me. I now require the same method popups now on Vim when coding Python in Linux. But how to do this? First I backup my original .vimrc: \" Automatic syntax highlighting syntax on \" Stop vim from creating automatic backups set noswapfile set nobackup set nowb \" Reload files modified outside of vim set autoread \" Make tabs 4 spaces wide set tabstop=4 set shiftwidth=4 \" Replace tabs with spaces set expandtab \" If already indented, next line should be indented set autoindent \" Show line numbers set number \" Highlight col 81 to keep under 80 cols set colorcolumn=80 \" Set screen to 85x40 set lines=45 set columns=85 \" Set editing to nowrap set nowrap set nocompatible colorscheme oceandeep set guifont=Inconsolata\\ 15 set guicursor=a:blinkon0 set foldmethod=indent set foldlevel=99 filetype on filetype indent plugin on \" Set split window navigation shortcuts map <c-j> <c-w>j map <c-k> <c-w>k map <c-l> <c-w>l map <c-h> <c-w>h set guioptions-=T \"get rid of toolbar set guioptions-=m \"get rid of men source $VIMRUNTIME/mswin.vim behave mswin let g:miniBufExplMapWindowNavVim = 1 let g:miniBufExplMapWindowNavArrows = 1 let g:miniBufExplMapCTabSwitchBufs = 1 let g:miniBufExplModSelTarget = 1 Next I followed instructions for Vundle . Sadly I found the page instructions incomprehensible. I next tried this page and similarly failed to install YouCompleteMe using Vundle. It's mostly there are some external dependencies that are blocked behind China's Great Firewall. I'll retry when I'm outside of the Great Firewall.","title":"Setting Up Vim For Python"},{"location":"archives/2017/2017-06-10-using-conda/","tags":"python","text":"Notes on using Conda, NumPy Conda | Setup Python 3.5 env | conda create -n py35 python=3.5 anaconda | | Setup Python 2.7 env | conda create -n py27 python=2.7 anaconda | | Switch to Python 3.5 env | source activate py35 | | Check Python version | python -V | Numpy | Import numpy | import numpy as np | | Create a new array | na = array([1,2,3,4]) | | Use any numpy function | na.min() | | Load data into array | na = np.loadtxt('data.txt') | | Save array to file | np.savetxt('data.txt', na) |","title":"Using Conda, NumPy"},{"location":"archives/2017/2017-06-10-using-conda/#conda","text":"| Setup Python 3.5 env | conda create -n py35 python=3.5 anaconda | | Setup Python 2.7 env | conda create -n py27 python=2.7 anaconda | | Switch to Python 3.5 env | source activate py35 | | Check Python version | python -V |","title":"Conda"},{"location":"archives/2017/2017-06-10-using-conda/#numpy","text":"| Import numpy | import numpy as np | | Create a new array | na = array([1,2,3,4]) | | Use any numpy function | na.min() | | Load data into array | na = np.loadtxt('data.txt') | | Save array to file | np.savetxt('data.txt', na) |","title":"Numpy"},{"location":"archives/2017/2017-06-11-basic-matplotlib/","tags":"patterns","text":"Most data analysts just want to generate a plot quickly with minimal work. However Matplotlib's api has a slight learning curve- and it requires some investment to pick up on its class hierachies and its terminologies. I've jotted down some Matplotlib gems here so others users can have less of a learning curve. One key point to note is that regardless of what commands used to generate plots, they all devolve into one low level plot method- which is pyplot.subplots(). Exploting this method well is the key to build great looking charts. The Axes class is the main class to work with for customising the plot type and the x and y axes. For working with all other plot elements, we use the Figure class. We acquire pointers (or references) to both the Figure and Axes whenever we call the pyplot.subplot() method. Sample Matplotlib command usage: Topic Intent Usage Plots Create 2x1 subplots fg, ax = plt.subplots(2, 1, sharex=True) Spines Make top spine invisible ax.spines['top'].set_visible(False) X Ticks Set xtick color, label size, and direction ax.tick_params(axis='y', color='#333333', labelsize='small', direction='in') Styles Use preset plot styles style.style.use('ggplot') Styles See available styles print(plt.style.available) Text Set text at x,y data points ax.text(dates[2], prices[2], 'Example') Text Text with arrow ax.annotate('Dividend',(dates[2],prices[2]), xytext=(0.8, 0.9), textcoords='axes fraction', arrowprops = dict(facecolor='grey',color='grey')) Subplots Create subplots ax = plt.subplot2grid((gx,gy), (x,y), colspan=c) Subplots Create subplots ax = plt.subplot2grid((gx,gy), (x,y), rowspan=r) Sample Matplotlib script: jupyter qtconsole import numpy as np import matplotlib.pyplot as plt plt.figure() # Create a new figure window xlist = np.linspace(-2.0, 1.0, 100) # Create 1-D arrays for x,y dimensions ylist = np.linspace(-1.0, 2.0, 100) X,Y = np.meshgrid(xlist, ylist) # Create 2-D grid xlist,ylist values Z = np.sqrt(X**2 + Y**2) # Compute function values on the grid plt.contour(X, Y, Z, [0.5, 1.0, 1.2, 1.5], colors = \u2019k\u2019, linestyles = \u2019solid\u2019) plt.show()","title":"Basic Matplotlib Plot"},{"location":"archives/2017/2017-06-24-the-effective-engineer/","tags":"patterns","text":"Just read \"The Effective Engineer\" by Edmond Lau. For those who have no time to read, I've simplified the book to 11 bullet points below. Increase your leverage by focusing on high impact activities and completing activities quicker. Learning is like compound interest. Steadily acquiring small bits of knowledge over time accumulates to a mountain of knowledge. Prioritize regularly- differentiate between urgent vs important. Invest in iteration speed- with continuous testing and small incremental changes. Invest in time saving tools. Use metrics to drive progress. Validate ideas via feedbacks early and often. Test your ideas with automated tests. Relentless automate repetitive tasks. Invest in team's growth. Build the simplest system possible.","title":"The Effective Engineer"},{"location":"archives/2017/2017-09-03-managing/","tags":"managing","text":"Harold Geneen was a longtime CEO of ITT, a huge conglomerate. His book, concisely named 'Managing', details his thoughts on running a business. I've jotted down some main more important points from his point- for long term reference. On Management Theories ...No Theory X, Y, or Z will give us simple answers to complex problems... The men and women with whom I have worked have been whole, rounded, complex persons with a wide variety of good and bad qualities. I could never fit them into any convenient psychological pigeonhole. The only way I knew how to judge people at ITT was by the test of performance.... All the computers, reports, surveys, and staff analyses provied us with only one thing: Information- factural information and sometimes, misinformation. When it came time to make a decision, I would ask one, two or several people, \"What do you think?\" From the interchange of ideas, one sparking the other, based upon the facts at hand, we would reach a decision, for better or worse. We learned as we went along; our bank of experience grew richer; we became quickerand more sophisticated in handling more complex problems; we became more self-confident of our abilities. But we never reduced the art of management to a formula. We could never be sure we were right on any one, specific decison. Many people, young and old, have asked me from time to time for the secret of my success in business. Usually I avoided giving any answer. Now I can reveal it- The secret of how to succeed in business or in life is that there is no secret. No secret at all. No formula. No theory. A Three Sentence Course on Business Management- You read a book from the beginning to the end. You run a business the opposite way. You start with the end, and then you do everything you mut to reach it. You decide what it is that you want to do, then you start doing it. On the tactics of selling Never make your sales pitch right away. Offer the client a cigarette, sit down, and talk to him about the advantages of your product. Listen to what he says. Don't interrupt him. Pick out his main objection or doubt and focus your sales talk on that. Finally, before you leave, don't forget to ask for the order. On departing a job Strong doubts and misgivings besieged me right up to the evening that I left the plant. It had been my first real postwar job, a happy, good place to work, with responsibilities that had challenged my abilities. Looking back from the parking lot to the light still buring in my office, I wondered whether or not I should turn back. But I could not turn back. No one can turn back, not successfully. One makes a decision to go forward, for better or worse, and you go forward, with the feeling and faith that if you succeed at one task, you have every reason to believe you will succeed at your next, bigger one. There are no guarantees, of course, but the risk must be taken, if you are going to live with yourself thereafter. On reviewing problems One by one, we would go through each of the monthly reports. Not only I but anyone else at the meeting could say anything, question anything, suggest anything that was pertinent... With the figures on the screen, we could all see how each profit center measured up to its budget commitments, its last year's performance and wahterver, in sales, earnings, etc... When problems arose, as they always did, we could deal with them and perhaps even solve them on the spot... Often, we would deal with a problem of one company that was similar to if not a replica of a problem faced by several other companies. Men learned by learning to the woes of others. It was at times almost group therapy. Often, the manager of one company could suggest a solution that worked for him that would help another manager with a similar problem in his company... I asked questions based upon the notes I had made on their monthly operating reports. Why were the sales down? Was he sure of the reasons? Had he checked it out? How? What was he doing about it? What did he expect in the month or two ahread? Did he need help? How did he plan to meet or outdistance the competition? Oftentimes, as we explored a situation, we found that the reason for a problem was not as expected, but something entirely different. I did not come to those meetings with all the answers. We explored and we tested out alternatives. The minds of many men dealt with the problem at hand. When I felt the man needed help, I assigned a team of staff man to help him. And I explained that we were all there to help the man in trouble; we were all one team, one company, and I was interested in solving the problem at hand, not taking action against the man personally. I brought this point home at a General Managers Meeting early in my reign at ITT when the man in charge of our Latin America operations reported that he had failed to sell our newest, multimillion-dollar telephone switching system to the government of Brazil. I probed for quite a while into the efforts that had been made, the presentation given, the facts of the situation. He told me of all the avenues he had explored. \"Who makes the final decision there on whether or not they buy our system\", I asked. \"President Kubitschek.\" \"Did you see him?\" \"No.\" \"Why not?\" \"Because... really makes the decision. He recommends the decision and the President follows his advice,\" he explained, adding, \"Besides, I don't think I can get in to see Kubitschek.\" \"Well, why don't you try? You have everything to gain and nothing to lose.\" The following month, he returned to announce with a sheepish grin on his face that he had seen the President of Brazil and had sold the ITT system. It went over quite big. The men in the room applauded him. Experience has taught me what I came to call the inverse ratio of time to veracity. It has long seemed to me that the lower you are in the corporate hiearchy, the more time you have to verify the facts upon which you were acting... and the higher you rise and the greater your responsibilities, the less time you have to check your facts, and the more important it is to do so. On Leadership Leadership is the ability to inspire other people to work together as a team, following your lead, in order to attain a common objective, whether in business, in politics, in war, or on the football field. No one can do it alone. Others must want to follow the lader. I don't particularly subscribe to the theory that there are natural born leaders. Leadership is learned, although I cannot explain entirely how it is learned. The ability to lead and inspire others is far more instintual than premeditated and it is acquired somehow through the experiences of one's everyday life, and the ultimate nature and quality of that leadership comes out of the innate character and personality of the leader himself. I wanted to create that kind of invigorating, challenging, creative atmosphere at ITT. I wanted to get the people there to reach for goals that they might think were beyond them. I wanted them to accomplish more than they thought were possible. And I wanted them to do it not only for the company and their careers but also for the fun of it. I wanted them to enjoy the process of tackling a different piece of business, solving it, and going on to bigger, better, and tougher challenges. I wanted them to do this, not for self-aggrandizement, but s part of a greater team effort, in which each player realised his own contribution to the team, knew that he was needed and appreciated, and took pride and self-satisfaction from playing a winner game. My job as a chief executive, as I saw it, was to unlock wahtever inhibitions or fears bound these people in chains of insecurity. The way to do that was to create at ITT a climate of growth and opportunity, a climate in which each fellow would want to carry his own share, and would be driven to excel not only because I pushed him but because of peer pressure and pride. The best hope of achieving that, given my own sense of leadership, was to jump in the boat, grab an oar, and start pulling along with the other men. I suppose you might call it participatory leadership. I didn't want to be the captain sitting in the back of the boat, exhorting his men to do all the work while he sat there doing nothing. Nor did I want to be like the master of a galley, frightening his slaves half to death with the giant whip in his hands. I worked as long and as hard as any man at ITT and they knew it...I did set an example, an honest example, which traveled down the ranks of management and, to an extent, established a standard of performance for the whole company. After all, if I could do it, so could the next man- if he had any measure of pride in his own ability. The person who heads a company should realise that his people are not really working for himl they are working with him for themselves. They have their own dreams, their own need for self-fulfillment. He has to help fill their needs as much as they do his. He has to prove to them that he is working as hard as they are, that he is competent in his role as chief executive, that he will not lead them over the cliff and jeapedise their livelihoods, they he can be relied upon to reward them properly and fairly, that he is willing to share the risks as well as the rewards of their enterprise. On meetings We cut through layers of fat in our management ranks by putting all the people in one room so they could talk with one another, face to face, regardless of rank, and an honest assessment of any situation could be based upon the facts which emerged...People could disagree with me or with anyone else... I tried to welcome criticism. Naturally, no one likes to be criticized. One's first instinct is to be defensive and fight back. But that is the kind of defensiveness one should try to keep under control... I always wanted someone to point out where I might be heading for a mistake. I never batted down such a man. I listened and we exchanged views. Sometimes I was clearly wrong; sometimes he was mistaken. Not infrequently, it was a little of both. Almost always new facts and new ideas emerged and our exchange would reveal a better course of action which neither of us had envisioned before... Being open to criticism usually pays unexpected dividends. People were free to come to me or to anyone else and ask honestly for help, and they would get it, again without fear of diminution of status, rank or whatever. We were all in the same lifeboat, all pulling toward a single goal. That was our underlying philosophy. On delegation ...He delegates this and he delegates that. He delegates just about everything he can, saying that his shop is well organized and that he runs a tight ship. But I have to ask- Organized for what? Tight in what way? If he delegates everything that crosses his desk (and leaves it clean), has he not reduced his function o that of a traffic cop? What he is really doing, whether or not he realizes it, is directing the flow of paper and giving the go-ahead or stop signal to decisions made by others. There is nothing wrong with being a traffic cop, but should he be paid the salary of a top corporate executive? One can hire a business administrator at a fraction of the salary and bonuses paid to top management. The real danger in turning over responsbility and authority for a job, without knowing the details of what is involved, is that the manager who receives the responsibility might fail. If that happens, the chief executive does not know enough to resuce the situation. All he can do is to hire someone else to do the job. Therefore, beneath the facade of his title, the size of office, and the quality of his desk, is he incompetent. On the other hand, if all his vice presidents do their own jobs superbly, it won't be long before someone discovers that they don't need him as the chief executive at all. Any one of his subordinates would be happy to take over. More prevalent are the professional money managers who give other reasons for their tidy desk tops. One type freely admits that he worked hard to get to the top and now, presumably safely enscounced, delights in having others do the work for him. He won't last long, in my estimation, with that false sense of security. Even more prevalent are the men who persuade themselves that they are now above the mundane, nitty-gritty aspects of the day-to-day problems of running the business. They say they have to keep their desks and minds clear for the deeper, long-range strategies that will guide their companies to new wondrous heights in the world of tomorrow. They are planning for the future, they say, looking far over the heads of the mere mortals on the operating lines of the company. They sincerely believe it, too. On managing The key, essential element in all good business management is emotional attitude. The rest is mechanics. As I use the term, management is not a collection of boxes with names and titles on the organizational chart. Management is a living force. It is the force that gets things done to acceptable standards- high standards. You either have it in a company or you don't. Management must have a purpose, a dedication, and that dedication must be an emotional commitment. It must be built in a vital part of the personality of anyone who is truly a manager. He or she is the one who understands that management must mange. The attitude is a self-fulfilling one, too. The man who says, \"I must do this,\" will stay at his task until all hours, trying again and again and again, until he finds a satsifactory answer. The answer must be, above all, satisfactory to him. And he will know it. There may be seventy-eight ways to do something and only ten of them with satisfactorily good answers. The manager will continue to probe and to seek for one of those ten answers. It may not be the best of all answers. But he won't settle for anything lower than one of those ten. The next time he will strive for yet a better answer, higher on the list, learning something new all the time, and achieving better results as he goes along. He will work this way because of his emotional attitude, more than anything else, and that attitude inevitably will be emulated by those who work with him, so that it becomes a way of life in that organization. The urge to do what must be done is powered by deep-seated emotion, not logic. He might not be able to explain why he works the way he does, or why he makes this choice and not the other one. He does it because he 'feels' that it is right. That feeling is transmitted to others who work for him or with him. They know his emotional commitment includes them as well as the goals of the enterprise. They are willing to follow his lead because of that 'feeling' which makes him the kind of person he is. If the manager is to accomplish his objectives, he absolutely has to get the information necessary to make the right decisions. The steps along the way define themselves as he goes toward his objectives. To surmount each step, he needs solid facts so that he can recognize the realities of situations. His decisions, if based realistically upon reliable information, will not be all that difficult. Facts are power. They are crucial to good management. In order to get the straight facts in any situation, the manager must ask straight questions, and to do that he must do his homework so that he has a deep understanding of what he is encountering. If he has a good record of making the right decisions, he can help people around him to be effective and successful in their own areas, so that their total accomplishments is greater than the sum of their individual parts. That is leadership. And if the leadership is successful, it creates a momentum in the enterprise which enriches the participants with such a feeling of pride and energy tha they produce results, short-term and long-term results, which they themselves never thought possible. I've separated the elements here, but in practice, they all move along together, en masse, nourishing each other like the fusion in a nuclear reactor, creating the fire, the pressure, and the power which produce energy. All this is the critical emotional content of good management. This is the emotional horsepower that drives people to do things, drives them to keep at it because they feel they must get the answer, drives them to push on until they get results that are satisfactory to them. Of course, you don't always succeed in every effort. But then you recognize it early on, and you get out of that situation. You cut your losses and go on to something else. If you are a manager, you don't drift.","title":"Managing, by Harold Geneen"},{"location":"archives/2017/2017-10-12-decorators/","tags":"patterns","text":"Pattern Usage Decorator Adds new functionality to existing components without changing the component Visitor Adds new operations to existing without modifying existing data structures Strategy Allows interchanging functionality at runtime without modifying code","title":"Patterns"},{"location":"archives/2017/2017-10-13-decorator-pattern/","tags":"patterns","text":"The Decorator pattern- is used to dynamically add new functionality to existing components- without having to change the existing components. IShippingMethod.cs using System ; namespace Decorator { public interface IShippingMethod { double GetCost(); } } GroundShipping.cs using System ; namespace Decorator { public class GroundShipping : IShippingMethod { public double GetCost() { return 10.0; } } } AirShipping.cs using System ; namespace Decorator { public class AirShipping : IShippingMethod { public double GetCost() { return 50.0; } } } DecoratorShipping.cs using System ; namespace Decorator { public class DecoratorShipping : IShippingMethod { IShippingMethod _shippingMethod; public DecoratorShipping(IShippingMethod shippingMethod) { _shippingMethod = shippingMethod; } public virtual double GetCost() { return _shippingMethod.GetCost(); } } } ReceiptDecorator.cs using System ; namespace Decorator { public class ReceiptDecorator : DecoratorShipping { public ReceiptDecorator(IShippingMethod shippingMethod) : base (shippingMethod) { } public override double GetCost() { return base .GetCost() + 1.0; } } } SignatureRequiredDecorator.cs using System ; namespace Decorator { public class SignatureRequiredDecorator : DecoratorShipping { public SignatureRequiredDecorator(IShippingMethod shippingMethod) : base (shippingMethod) { } public override double GetCost() { return base .GetCost() + 2.0; } } } DecoratorTester.cs using System ; using Microsoft.VisualStudio.TestTools.UnitTesting ; using Decorator ; namespace DecoratorTests { [TestClass] public class DecoratorTester { [TestMethod] public void GroundShippingWithNoOptionsShouldCostTenDollars() { var groundShipment = new GroundShipping(); Assert.AreEqual(10.0, groundShipment.GetCost()); } [TestMethod] public void GroundShippingWithReceiptOptionShouldCostElevenDollars() { var groundShipment = new GroundShipping(); var groundShipmentWithReceiptOption = new ReceiptDecorator(groundShipment); Assert.AreEqual(11.0, groundShipmentWithReceiptOption.GetCost()); } [TestMethod] public void GrondShippingWithSignatureOptionShouldCostTwelveDollars() { var groundShipment = new GroundShipping(); var groundShipmentWithSignatureOption = new SignatureRequiredDecorator(groundShipment); Assert.AreEqual(12.0, groundShipmentWithSignatureOption.GetCost()); } [TestMethod] public void GrondShippingWithSignatureOptionAndReceiptShouldCostThirteenDollars() { var groundShipment = new GroundShipping(); var receiptOption = new ReceiptDecorator(groundShipment); var groundShipmentWithSignatureAndReceiptOption = new SignatureRequiredDecorator(receiptOption); Assert.AreEqual(13.0, groundShipmentWithSignatureAndReceiptOption.GetCost()); } [TestMethod] public void AirShippingWithNoOptionsShouldCostFiftyDollars() { var airShipment = new AirShipping(); Assert.AreEqual(50.0, airShipment.GetCost()); } [TestMethod] public void AirShippingWithReceiptOptionShouldCostElevenDollars() { var airShipment = new AirShipping(); var airShipmentWithReceiptOption = new ReceiptDecorator(airShipment); Assert.AreEqual(51.0, airShipmentWithReceiptOption.GetCost()); } } }","title":"Decorator Pattern"},{"location":"archives/2017/2017-10-13-decorator-pattern/#ishippingmethodcs","text":"using System ; namespace Decorator { public interface IShippingMethod { double GetCost(); } }","title":"IShippingMethod.cs"},{"location":"archives/2017/2017-10-13-decorator-pattern/#groundshippingcs","text":"using System ; namespace Decorator { public class GroundShipping : IShippingMethod { public double GetCost() { return 10.0; } } }","title":"GroundShipping.cs"},{"location":"archives/2017/2017-10-13-decorator-pattern/#airshippingcs","text":"using System ; namespace Decorator { public class AirShipping : IShippingMethod { public double GetCost() { return 50.0; } } }","title":"AirShipping.cs"},{"location":"archives/2017/2017-10-13-decorator-pattern/#decoratorshippingcs","text":"using System ; namespace Decorator { public class DecoratorShipping : IShippingMethod { IShippingMethod _shippingMethod; public DecoratorShipping(IShippingMethod shippingMethod) { _shippingMethod = shippingMethod; } public virtual double GetCost() { return _shippingMethod.GetCost(); } } }","title":"DecoratorShipping.cs"},{"location":"archives/2017/2017-10-13-decorator-pattern/#receiptdecoratorcs","text":"using System ; namespace Decorator { public class ReceiptDecorator : DecoratorShipping { public ReceiptDecorator(IShippingMethod shippingMethod) : base (shippingMethod) { } public override double GetCost() { return base .GetCost() + 1.0; } } }","title":"ReceiptDecorator.cs"},{"location":"archives/2017/2017-10-13-decorator-pattern/#signaturerequireddecoratorcs","text":"using System ; namespace Decorator { public class SignatureRequiredDecorator : DecoratorShipping { public SignatureRequiredDecorator(IShippingMethod shippingMethod) : base (shippingMethod) { } public override double GetCost() { return base .GetCost() + 2.0; } } }","title":"SignatureRequiredDecorator.cs"},{"location":"archives/2017/2017-10-13-decorator-pattern/#decoratortestercs","text":"using System ; using Microsoft.VisualStudio.TestTools.UnitTesting ; using Decorator ; namespace DecoratorTests { [TestClass] public class DecoratorTester { [TestMethod] public void GroundShippingWithNoOptionsShouldCostTenDollars() { var groundShipment = new GroundShipping(); Assert.AreEqual(10.0, groundShipment.GetCost()); } [TestMethod] public void GroundShippingWithReceiptOptionShouldCostElevenDollars() { var groundShipment = new GroundShipping(); var groundShipmentWithReceiptOption = new ReceiptDecorator(groundShipment); Assert.AreEqual(11.0, groundShipmentWithReceiptOption.GetCost()); } [TestMethod] public void GrondShippingWithSignatureOptionShouldCostTwelveDollars() { var groundShipment = new GroundShipping(); var groundShipmentWithSignatureOption = new SignatureRequiredDecorator(groundShipment); Assert.AreEqual(12.0, groundShipmentWithSignatureOption.GetCost()); } [TestMethod] public void GrondShippingWithSignatureOptionAndReceiptShouldCostThirteenDollars() { var groundShipment = new GroundShipping(); var receiptOption = new ReceiptDecorator(groundShipment); var groundShipmentWithSignatureAndReceiptOption = new SignatureRequiredDecorator(receiptOption); Assert.AreEqual(13.0, groundShipmentWithSignatureAndReceiptOption.GetCost()); } [TestMethod] public void AirShippingWithNoOptionsShouldCostFiftyDollars() { var airShipment = new AirShipping(); Assert.AreEqual(50.0, airShipment.GetCost()); } [TestMethod] public void AirShippingWithReceiptOptionShouldCostElevenDollars() { var airShipment = new AirShipping(); var airShipmentWithReceiptOption = new ReceiptDecorator(airShipment); Assert.AreEqual(51.0, airShipmentWithReceiptOption.GetCost()); } } }","title":"DecoratorTester.cs"},{"location":"archives/2019/2019-02-16-2019-new-ideas/","tags":"ideas","text":". Books Currently Reading Invested Google SRE The Banished Immortal Some Ideas To Resolve Soon Poisson distribution What is PCA? What is irvega rho? Some notes on financial markets How to use TensorFlow? How to use pivottable.js? How to use metplotlib for charts? Backtest strategy to buy on n% dips? Build pages on individual tickers How to host python script on AWS? Why use NumPy? New Investment Ideas A new proposed idea is to buy on n% dips. Would this work? Or buy an index instead of individual stocks on such dips. PCA PCA - principal component analysis sounds very much like fourier transform. It is a statistical proceudre that reduces 100 variables to a few important- orthogonal (meaning unrelated) variables- principal components- that explains 95% of the movements of the original wave. PCA is used primarily for making predictive models. Rho Rho is the sensitivity of the option value to changes in the risk free interest rate. PivotTable.js PivotTable.js looks pretty powerful. Why use NumPy? ndarray- a fast and space efficient multi-dimensional array providing vectorized arithmetic operations and broadcasting capabilities functions for reading and writing to disk tools for integrating with C, C++ and Fortran math operations with no loops linear algebra and fourier transform functions But what functions does NumPy provide and what from Pandas? I believe data analysis primarily use math functions from Pandas and use NumPy primarily for its fast ndarray. Pandas runs on top of NumPy- so Pandas depends on NumPy. Pandas provides datatable-like functions- as well as stats, groupbys, merge and join methods. Pandas was built starting in 2008 by Wes McKinney at AQR. Matplotlib for Quick Charts Quick charts demo Poisson Distribution Poisson Distribution is for modelling the number of times an event occurs in an interval of time or space- for example- the number of patients arriving in an emergency room between 10 and 11pm. The following assumptions must be true in order to use Poisson Distribution k is the number of times an event occurs in an interval- like 0, 1, 2 \u2026 The events are independent. The rate at which events occur is constant. Two events cannot occur at exactly the same time.","title":"2019 New Ideas"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#books-currently-reading","text":"Invested Google SRE The Banished Immortal","title":"Books Currently Reading"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#some-ideas-to-resolve-soon","text":"Poisson distribution What is PCA? What is irvega rho? Some notes on financial markets How to use TensorFlow? How to use pivottable.js? How to use metplotlib for charts? Backtest strategy to buy on n% dips? Build pages on individual tickers How to host python script on AWS? Why use NumPy?","title":"Some Ideas To Resolve Soon"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#new-investment-ideas","text":"A new proposed idea is to buy on n% dips. Would this work? Or buy an index instead of individual stocks on such dips.","title":"New Investment Ideas"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#pca","text":"PCA - principal component analysis sounds very much like fourier transform. It is a statistical proceudre that reduces 100 variables to a few important- orthogonal (meaning unrelated) variables- principal components- that explains 95% of the movements of the original wave. PCA is used primarily for making predictive models.","title":"PCA"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#rho","text":"Rho is the sensitivity of the option value to changes in the risk free interest rate.","title":"Rho"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#pivottablejs","text":"PivotTable.js looks pretty powerful.","title":"PivotTable.js"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#why-use-numpy","text":"ndarray- a fast and space efficient multi-dimensional array providing vectorized arithmetic operations and broadcasting capabilities functions for reading and writing to disk tools for integrating with C, C++ and Fortran math operations with no loops linear algebra and fourier transform functions But what functions does NumPy provide and what from Pandas? I believe data analysis primarily use math functions from Pandas and use NumPy primarily for its fast ndarray. Pandas runs on top of NumPy- so Pandas depends on NumPy. Pandas provides datatable-like functions- as well as stats, groupbys, merge and join methods. Pandas was built starting in 2008 by Wes McKinney at AQR.","title":"Why use NumPy?"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#matplotlib-for-quick-charts","text":"Quick charts demo","title":"Matplotlib for Quick Charts"},{"location":"archives/2019/2019-02-16-2019-new-ideas/#poisson-distribution","text":"Poisson Distribution is for modelling the number of times an event occurs in an interval of time or space- for example- the number of patients arriving in an emergency room between 10 and 11pm. The following assumptions must be true in order to use Poisson Distribution k is the number of times an event occurs in an interval- like 0, 1, 2 \u2026 The events are independent. The rate at which events occur is constant. Two events cannot occur at exactly the same time.","title":"Poisson Distribution"},{"location":"archives/2019/2019-02-20-how-to-use-slide-rules/","tags":"retro","text":". Multiplication To multiply two small numbers, 2x3 - Use rules C and D. Starting from the left, line up C (1) to D (2). - Move cursor to C (3). D (6) shows the answer. To mulitply two big numbers, 6x7 - Use rules C and D. Starting from the right, line up C (1) to D (6). - Move cursor to C (7). D (4.2) shows the answer. Adjust by 10 = 42. To multiple two big numbers, 12 x 67 - Use rules C and D. Starting from the left, line up C (1.2) to D (1.2). - Move cursor to C (6.7). D (8) shows the answer. Adjust by thinking 10x70=700. So 8 must be 800. What are the limits of rules C and D? - Reading C and D from left to right is only for small digits, like 2x4. - Reading C and D from right to left works for bigger digits. . Division To divide two small numbers, 4.5 / 7.8 - Use rules C and D. - Move cursor to D (4.5). - Move C (7.8) until 7.8 hits the cursor. - Move cursor to C (1). - The answer is in D (5.78). - Since 4/8 ~ 0.5, the answer is 0.578. To divide two numbers, 142 / 83 - Use rules C and D. - Move cursor to D (1.42). - Move C (8.3) until 8.3 hits the cursor. - Move cursor to C (1). - The answer is in D (1.72). - Since 160/80 ~ 2, the answer is 1.72. To divide two big numbers, 2,313,184 / 80,234 - Use rules C and D. - 2,313,184 ~ 2.3e6. - 80,234 ~ 8.0e4. - Move cursor to D (2.3). - Move C (8.0) until 8.0 hits the cursor. - Move cursor to C (1). - The answer is in D (2.88). ~ Adjusted for scale, 2.88e2 ~ 28.8. . Sin 30 - Use rule A and S. Align rules. - Move cursor to S (30). - The answer is in A (5). - Adjusted, the answer is 0.5. Cos 30 - Once you can do sin 0-90, you can do any sin or cos. - If you look at the cos/sin charts, cos 30 is the same as sin 60. - Sin 60 = 0.866. Tan 30 - Use rule D and T. Align rules. - Move cursor to T (30). - The answer is in D (5.76). - Adjusted, the answer is 0.576.","title":"How to use slide rules"},{"location":"archives/2019/2019-02-20-how-to-use-slide-rules/#multiplication","text":"To multiply two small numbers, 2x3 - Use rules C and D. Starting from the left, line up C (1) to D (2). - Move cursor to C (3). D (6) shows the answer. To mulitply two big numbers, 6x7 - Use rules C and D. Starting from the right, line up C (1) to D (6). - Move cursor to C (7). D (4.2) shows the answer. Adjust by 10 = 42. To multiple two big numbers, 12 x 67 - Use rules C and D. Starting from the left, line up C (1.2) to D (1.2). - Move cursor to C (6.7). D (8) shows the answer. Adjust by thinking 10x70=700. So 8 must be 800. What are the limits of rules C and D? - Reading C and D from left to right is only for small digits, like 2x4. - Reading C and D from right to left works for bigger digits. .","title":"Multiplication"},{"location":"archives/2019/2019-02-20-how-to-use-slide-rules/#division","text":"To divide two small numbers, 4.5 / 7.8 - Use rules C and D. - Move cursor to D (4.5). - Move C (7.8) until 7.8 hits the cursor. - Move cursor to C (1). - The answer is in D (5.78). - Since 4/8 ~ 0.5, the answer is 0.578. To divide two numbers, 142 / 83 - Use rules C and D. - Move cursor to D (1.42). - Move C (8.3) until 8.3 hits the cursor. - Move cursor to C (1). - The answer is in D (1.72). - Since 160/80 ~ 2, the answer is 1.72. To divide two big numbers, 2,313,184 / 80,234 - Use rules C and D. - 2,313,184 ~ 2.3e6. - 80,234 ~ 8.0e4. - Move cursor to D (2.3). - Move C (8.0) until 8.0 hits the cursor. - Move cursor to C (1). - The answer is in D (2.88). ~ Adjusted for scale, 2.88e2 ~ 28.8. .","title":"Division"},{"location":"archives/2019/2019-02-20-how-to-use-slide-rules/#sin-30","text":"- Use rule A and S. Align rules. - Move cursor to S (30). - The answer is in A (5). - Adjusted, the answer is 0.5.","title":"Sin 30"},{"location":"archives/2019/2019-02-20-how-to-use-slide-rules/#cos-30","text":"- Once you can do sin 0-90, you can do any sin or cos. - If you look at the cos/sin charts, cos 30 is the same as sin 60. - Sin 60 = 0.866.","title":"Cos 30"},{"location":"archives/2019/2019-02-20-how-to-use-slide-rules/#tan-30","text":"- Use rule D and T. Align rules. - Move cursor to T (30). - The answer is in D (5.76). - Adjusted, the answer is 0.576.","title":"Tan 30"},{"location":"archives/2019/2019-07-20-all-about-dieting/","tags":"nutrition","text":"Recommendations from Dr Valter Longo Plenty of vegetables and legumes and a generous splash of olive oil Key to longevity is to slow down the growth hormone receptor (GHR). Proteins activate the GHR- which increases the level of insulin- which is linked to diabetes and cancer. Proteins activate TOR-S6K- genes that accelerate aging. Sugars activate PKA- another gene that accelerate aging. Reducing calories, particularly from proteins and sugars- decrease the activites of the GHR- and indirectly- TOR-S6K and PKA. Keep diet to 80% plant and 20% fish. Keep fish to wild salmon. Tuna has high levels of mercury- canned light tuna has less- but better stick to salmon, sardines and cod. Eat just enough proteins- about 50 grams of protein a day. Get an estimate of protein levels here. Eat good unsaturated fats Recommendations from the pros Dr Gott from Dr. Gott's No Flour, No Sugar Diet says- While many a low-carb diet guru would have you believe that all carbohyrates are created equal- and are equally to blame for making you fat- they are just plain wrong. Fresh fruits and vegetables- as well as whole grains- are full of the essential vitamins, minerals, and fiber that we need to have healthy bodies, protect ourselves against disease, and function properly. The problem arises when technology takes over the digestion process, removing all those valuable nutrients... Simply put, the more refined a carb is, the fewer nutrients it contains because it has already been broken down, by the refining process, to its elemental form. Modern processing technology has manged to take once healthful whole grains and strip them of their very benefits. The whole grain, for instance, a veritable nutrition workhorse in its natural form, is steamed, pounded, and scraped to remove its outer fiber-full bran layer, its mineral-dense germ, and its vitamin- rich oil. Next it is pulverised by high speed steel rollers into a fine powder, then bleached to remove any possible likeness to its original form. This powdery white substance is then labeled 'all-purpose flour' and used to make almost all of the breads, cookies, crackers, cereals, and pastas you find on your supermarket shelves. Even those toasty brown 'wheat breads' are often made with white flour and then artifically colored to make them look 'healthy'. After all that processing, flour retains its high calorie nature but little else. It is virtually devoid of fiber and the vitamins and minerals our bodies need to function properly and fend off disease. The calories in all-purpose flour are what nutritionists call 'empty calories'. They will fill you up and provide instance energy, but they won't nourish your body for the long haul. The point of my No Flour, No Sugar Diet is to replace the empty calories of highly refined foots with the nutrient dense calories found in unprocessed foots. So when I say no flour- I mean no all-purpose flour, but also no whole wheat flour or any product with the word flour in its ingredient list.... All carbs are allowed on the diet except for those foods that contain flour. This means that you can still enjoy rice, potatoes, barley, oats, peas, corn, beans, vegetables and fruits. Dr Gott says Avoid food containing flour of any kind- wheat, rice, and corn flours- examples- pizza, pasta, buttery cookies refined or concentrated sugars- cane sugar, beet sugar, glocose, sucrose, high frutose corn syrup, maple syrup, honey- examples- cakes, ice-cream Eat whole grains and starchy vegetables- brown rice, potatoes, barley, oats, peas, corn, beans, vegetables and fruits. Maintain a body-mass index of 18.5-24. BMI = 703 * Weight in pounds / Height in inches squared . Robert Davis, PhD in Coffee is good for You Fish oil prevents heart disease...the key ingredients appear to be the omega-3 fatty acids eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), which are found in most fish but especially oily ones such as salmon, mackerel, trout, sardines, and tuna. Eggs are not bad for your heart...Eating up to six a week doesn't appear to be harmful for most healthy people. So how can this be if egg yolks are high in cholesterol and too much cholesterol is bad for us? Most of our cholesterol is made by the liver, which ramps up production when we eat saturated and trans fats. But cholesterol from food appears to have little impact on most people's cholesterol levels. Eggs are relatively low in saturated fat, and they contain unsaturated fats, which may be beneficial. Plus, they're a good source of protein and several vitamins and minerals. They can be a healthful and more filling alternative to high-calorie muffins, begals, and sugary cereals. Nuts prevent heart attacks...Nuts lower LDL (bad) cholesterol levels. They also appear to decrease inflammation in arteries, which may contribute to heart attacks...So which nuts are best for you?... Walnuts, for example, are richest in ALA, an omega-3 fatty acid and peanuts contain resveratrol, a substance also found in red wine... All nuts are relatively high in unsaturated fats, which care thought to be good for the heart. Trans fats (partially hydrogenated fats) are harmful...Like saturated fats, trans fats were found to raise LDL (bad) cholesterol, but they also lowered HDL (good) cholesterol. People who consume the most trans fats are more likely to develop heart disease. The increased risk appears to come from artificially created trans fats, not those that occur naturally in milk and meat. Scientists suspect that trans fats cause harm by not only affecting cholestrol levels but also raising blood fats called triglycerides, promoting inflammation in arteries, and adversely affecting the lining of blood vessels. Overall, the evidence suggests trans fats are more harmful than saturated fats, and it's more consistent. To avoid it, check ingredient labels and steer clear of anything containing partially hydrogenated oils. Gene Stone in The Secrets of People Who Never Get Sick According to Susan Roberts, professor at the Friedman School of Nutrition Science and Policy at Tufts University and author of The \"I\" Diet , her study of caloric reduction calls for a 25 percent cut in calories, but she believes it can be done in any way the dieter wishes as long as it feels comfortable- eating a full diet one day and then cutting calories the next, or eating a normal meal once a day with a reduced meal at other times... Food groups- Macro nutrients Proteins Found in meat, nuts, and eggs- sources of amino acids. Fats Major source of stored energy in the body Saturated fats Unsaturated fats Mono-unsaturated fats- oleic acid in olive oil Poly-unsaturated fats- salmon and corn oil Carbohydrates Simple carbohydrates- simple sugars- monosaccharides (fructose, glucose) and dissachrides (lactose, sucrose) found in fruit juices, honey, candy or sodas. This type of carbohydrate provides ready energy because your body has to do very little work to convert simple sugars to glucose. They are digested quickly and easily, sending a rush of glucose into your blood stream. When your body is flooded with glucose in this way, you experience a temporary sugar high caused by the spike in your blood sugar level. A short time later, as the glucose leaves your system, you experience a crash, which leaves you feeling fatigued and listless- and hungry again as your body craves more fuel. Complex carbohydrates- whole grains- brown rice, wheat, oats, barley, quinoa and corn, legumes (beans), and vegetables are made up of much more complicated sugar molecules. Your body needs to work much harder to break these complex sugars down and convert them to glucose. Because of the extra effort required to digest these foods, digestion takes place over an extended period of time- and the glucose your body gets from these foods is released into your blood stream at a slower, steadier pace. Examples of good carbohydrates Vegetables- all of them Whole fruits- apples, bananas, strawberries Whole grains- pure oats, quinoa, brown rice Legumes- lentils, kidney beans, peas Nuts- almondds, walnuts, hazel nuts, peanuts, macadamia nuts Exceptions to simple carb rule are- milk products and fruits. Because milk products and fruits are relatively low in sugar and provide big doses of imortant vitamins and minerals- fruits also provide fiber- these foods can be enjoyed as a regular part of a healthful diet. Choose fresh fruits instead of fruit juices and low fat or non-fat milk products. Difference between white rice and brown rice White rice is what you get when you remove the husk, bran and germ from whole grain \u2013 or brown rice. When you lose the bran \u2013 you lose the fiber. When you lose the germ \u2013 you lose B vitamins and some fat. All that remains is the endosperm, making white rice essentially, nutritionally naked starch. Consumers like white rice because it\u2019s light and fluffy. Food manufacturers like it because without the fat it is less likely to go rancid and has a longer shelf life than whole grain rice does What is wrong with starch? Starches include grain products, such as bread, crackers, pasta, and rice. As with simple sugars, some complex carbohydrate foods are better choices than others. Refined grains, such as white flour and white rice, have been processed, which removes nutrients and fiber. White rice is considered empty carbs since it loses its main sources of nutrients. ... A 3.5-ounce (100-gram) serving of brown rice has fewer calories and carbs than white rice and twice as much fiber. In general, brown rice also has higher amounts of vitamins and minerals than white rice. What are free radicals and antioxidants? Free radicals are unstable atoms that can damage cells, causing illness and aging. Read here for more details on free radicals and antioxidants.","title":"Food smarts"},{"location":"archives/2019/2019-07-20-all-about-dieting/#recommendations-from-dr-valter-longo","text":"Plenty of vegetables and legumes and a generous splash of olive oil Key to longevity is to slow down the growth hormone receptor (GHR). Proteins activate the GHR- which increases the level of insulin- which is linked to diabetes and cancer. Proteins activate TOR-S6K- genes that accelerate aging. Sugars activate PKA- another gene that accelerate aging. Reducing calories, particularly from proteins and sugars- decrease the activites of the GHR- and indirectly- TOR-S6K and PKA. Keep diet to 80% plant and 20% fish. Keep fish to wild salmon. Tuna has high levels of mercury- canned light tuna has less- but better stick to salmon, sardines and cod. Eat just enough proteins- about 50 grams of protein a day. Get an estimate of protein levels here. Eat good unsaturated fats","title":"Recommendations from Dr Valter Longo"},{"location":"archives/2019/2019-07-20-all-about-dieting/#recommendations-from-the-pros","text":"Dr Gott from Dr. Gott's No Flour, No Sugar Diet says- While many a low-carb diet guru would have you believe that all carbohyrates are created equal- and are equally to blame for making you fat- they are just plain wrong. Fresh fruits and vegetables- as well as whole grains- are full of the essential vitamins, minerals, and fiber that we need to have healthy bodies, protect ourselves against disease, and function properly. The problem arises when technology takes over the digestion process, removing all those valuable nutrients... Simply put, the more refined a carb is, the fewer nutrients it contains because it has already been broken down, by the refining process, to its elemental form. Modern processing technology has manged to take once healthful whole grains and strip them of their very benefits. The whole grain, for instance, a veritable nutrition workhorse in its natural form, is steamed, pounded, and scraped to remove its outer fiber-full bran layer, its mineral-dense germ, and its vitamin- rich oil. Next it is pulverised by high speed steel rollers into a fine powder, then bleached to remove any possible likeness to its original form. This powdery white substance is then labeled 'all-purpose flour' and used to make almost all of the breads, cookies, crackers, cereals, and pastas you find on your supermarket shelves. Even those toasty brown 'wheat breads' are often made with white flour and then artifically colored to make them look 'healthy'. After all that processing, flour retains its high calorie nature but little else. It is virtually devoid of fiber and the vitamins and minerals our bodies need to function properly and fend off disease. The calories in all-purpose flour are what nutritionists call 'empty calories'. They will fill you up and provide instance energy, but they won't nourish your body for the long haul. The point of my No Flour, No Sugar Diet is to replace the empty calories of highly refined foots with the nutrient dense calories found in unprocessed foots. So when I say no flour- I mean no all-purpose flour, but also no whole wheat flour or any product with the word flour in its ingredient list.... All carbs are allowed on the diet except for those foods that contain flour. This means that you can still enjoy rice, potatoes, barley, oats, peas, corn, beans, vegetables and fruits. Dr Gott says Avoid food containing flour of any kind- wheat, rice, and corn flours- examples- pizza, pasta, buttery cookies refined or concentrated sugars- cane sugar, beet sugar, glocose, sucrose, high frutose corn syrup, maple syrup, honey- examples- cakes, ice-cream Eat whole grains and starchy vegetables- brown rice, potatoes, barley, oats, peas, corn, beans, vegetables and fruits. Maintain a body-mass index of 18.5-24. BMI = 703 * Weight in pounds / Height in inches squared . Robert Davis, PhD in Coffee is good for You Fish oil prevents heart disease...the key ingredients appear to be the omega-3 fatty acids eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), which are found in most fish but especially oily ones such as salmon, mackerel, trout, sardines, and tuna. Eggs are not bad for your heart...Eating up to six a week doesn't appear to be harmful for most healthy people. So how can this be if egg yolks are high in cholesterol and too much cholesterol is bad for us? Most of our cholesterol is made by the liver, which ramps up production when we eat saturated and trans fats. But cholesterol from food appears to have little impact on most people's cholesterol levels. Eggs are relatively low in saturated fat, and they contain unsaturated fats, which may be beneficial. Plus, they're a good source of protein and several vitamins and minerals. They can be a healthful and more filling alternative to high-calorie muffins, begals, and sugary cereals. Nuts prevent heart attacks...Nuts lower LDL (bad) cholesterol levels. They also appear to decrease inflammation in arteries, which may contribute to heart attacks...So which nuts are best for you?... Walnuts, for example, are richest in ALA, an omega-3 fatty acid and peanuts contain resveratrol, a substance also found in red wine... All nuts are relatively high in unsaturated fats, which care thought to be good for the heart. Trans fats (partially hydrogenated fats) are harmful...Like saturated fats, trans fats were found to raise LDL (bad) cholesterol, but they also lowered HDL (good) cholesterol. People who consume the most trans fats are more likely to develop heart disease. The increased risk appears to come from artificially created trans fats, not those that occur naturally in milk and meat. Scientists suspect that trans fats cause harm by not only affecting cholestrol levels but also raising blood fats called triglycerides, promoting inflammation in arteries, and adversely affecting the lining of blood vessels. Overall, the evidence suggests trans fats are more harmful than saturated fats, and it's more consistent. To avoid it, check ingredient labels and steer clear of anything containing partially hydrogenated oils. Gene Stone in The Secrets of People Who Never Get Sick According to Susan Roberts, professor at the Friedman School of Nutrition Science and Policy at Tufts University and author of The \"I\" Diet , her study of caloric reduction calls for a 25 percent cut in calories, but she believes it can be done in any way the dieter wishes as long as it feels comfortable- eating a full diet one day and then cutting calories the next, or eating a normal meal once a day with a reduced meal at other times...","title":"Recommendations from the pros"},{"location":"archives/2019/2019-07-20-all-about-dieting/#food-groups-macro-nutrients","text":"","title":"Food groups- Macro nutrients"},{"location":"archives/2019/2019-07-20-all-about-dieting/#proteins","text":"Found in meat, nuts, and eggs- sources of amino acids.","title":"Proteins"},{"location":"archives/2019/2019-07-20-all-about-dieting/#fats","text":"Major source of stored energy in the body Saturated fats Unsaturated fats Mono-unsaturated fats- oleic acid in olive oil Poly-unsaturated fats- salmon and corn oil","title":"Fats"},{"location":"archives/2019/2019-07-20-all-about-dieting/#carbohydrates","text":"Simple carbohydrates- simple sugars- monosaccharides (fructose, glucose) and dissachrides (lactose, sucrose) found in fruit juices, honey, candy or sodas. This type of carbohydrate provides ready energy because your body has to do very little work to convert simple sugars to glucose. They are digested quickly and easily, sending a rush of glucose into your blood stream. When your body is flooded with glucose in this way, you experience a temporary sugar high caused by the spike in your blood sugar level. A short time later, as the glucose leaves your system, you experience a crash, which leaves you feeling fatigued and listless- and hungry again as your body craves more fuel. Complex carbohydrates- whole grains- brown rice, wheat, oats, barley, quinoa and corn, legumes (beans), and vegetables are made up of much more complicated sugar molecules. Your body needs to work much harder to break these complex sugars down and convert them to glucose. Because of the extra effort required to digest these foods, digestion takes place over an extended period of time- and the glucose your body gets from these foods is released into your blood stream at a slower, steadier pace. Examples of good carbohydrates Vegetables- all of them Whole fruits- apples, bananas, strawberries Whole grains- pure oats, quinoa, brown rice Legumes- lentils, kidney beans, peas Nuts- almondds, walnuts, hazel nuts, peanuts, macadamia nuts Exceptions to simple carb rule are- milk products and fruits. Because milk products and fruits are relatively low in sugar and provide big doses of imortant vitamins and minerals- fruits also provide fiber- these foods can be enjoyed as a regular part of a healthful diet. Choose fresh fruits instead of fruit juices and low fat or non-fat milk products.","title":"Carbohydrates"},{"location":"archives/2019/2019-07-20-all-about-dieting/#difference-between-white-rice-and-brown-rice","text":"White rice is what you get when you remove the husk, bran and germ from whole grain \u2013 or brown rice. When you lose the bran \u2013 you lose the fiber. When you lose the germ \u2013 you lose B vitamins and some fat. All that remains is the endosperm, making white rice essentially, nutritionally naked starch. Consumers like white rice because it\u2019s light and fluffy. Food manufacturers like it because without the fat it is less likely to go rancid and has a longer shelf life than whole grain rice does","title":"Difference between white rice and brown rice"},{"location":"archives/2019/2019-07-20-all-about-dieting/#what-is-wrong-with-starch","text":"Starches include grain products, such as bread, crackers, pasta, and rice. As with simple sugars, some complex carbohydrate foods are better choices than others. Refined grains, such as white flour and white rice, have been processed, which removes nutrients and fiber. White rice is considered empty carbs since it loses its main sources of nutrients. ... A 3.5-ounce (100-gram) serving of brown rice has fewer calories and carbs than white rice and twice as much fiber. In general, brown rice also has higher amounts of vitamins and minerals than white rice.","title":"What is wrong with starch?"},{"location":"archives/2019/2019-07-20-all-about-dieting/#what-are-free-radicals-and-antioxidants","text":"Free radicals are unstable atoms that can damage cells, causing illness and aging. Read here for more details on free radicals and antioxidants.","title":"What are free radicals and antioxidants?"},{"location":"archives/2019/2019-08-21-laws-of-investing/","tags":"patterns","text":"Laws of Investing","title":"Laws of Investing"},{"location":"archives/2020/2020-01-10-colossal_failure/","tags":"history","text":"Lawrence McDonald's \"A Colossal Failure of Common Sense\" reads like a work of fiction- a real page-turner- but the events that led to the downfall of Lehman Brothers happened in an unreal era not too long ago. I've decided to save some prized passages here: On fuck-ups: The trading floor is an arena of instant decisions: all traders are called to make markets all the time, to price the stock, price the bonds, buy, sell, or hold. And I'd just make a mistake. A big one. There was nowhere to turn. No one could help. My word was my bond. There was no going back. Which was precisely when Rich Gatward appeared on my left shoulder, like the angel of death. \"The Calpine trade ... what delta did you do it on?\" The equity trading floor around me suddenly seemed like like the petrified forest. It always does when Gatward comes over. Everyone stops, watching for the scene to unfold. I knew only one thing: I'd shorted only half the stock I should have. Ah...er...Rich, I did it on a 30, but I probably should have done it on a 60.\" \"What's this word _probably_ -- what do you mean by that\" \"Er..I mean we should have done the trade on a 60 delta...\" \"How many shares of stock do you need to sell right now to be hedged?\" I grappled for the bond calculator on the screen and hit the buttons as my entire career flashed before my eyes, the way it does, I believe, when you face instant death. \"Forty-five thousand two hundred, Rich.\" \"Well, don't look at me. Sell the fucking stock,\" he snapped. I could feel every eye on the floor trained on me, and he was not finished yet. \"If you're gonna work on my desk, you don't fly blind. You'd better know your deltas to the fucking penny.\" \"You're right. I screwed up, and I'm sorry. It won't happen again.\" \"You're goddamned right it won't, becuase if it does we're going to have a big fucking probllem. Do you understand that?\" \"Yes, I do. It was a mistake. It won't happen again. I'm sorry.\" \"You'd better be fucking sorry. Right here we're dealing with the firm's capital. You're on my watch, and I have an eye on every fucking penny of risk on this desk- and if you have a problem with that, you can get the fuck out.\" And with that he stormed off, back to his desk. It was as if the entire place could breathe again. People went back to work and the whole shouting, yelling, tempestuous atmosphere of the trading floor swiftly resumed business as usual. On executive presense and decision making ...I twice thought I saw my ultimate boss, Alex Kirk, Lehman's global head of high-yield and leveraged-loan business, and a huge power in the land, look just a tad hard-faced at some of the more optimistic assumptions coming from the guys who walked on water (the mortgage guys). On anyone else I might not have noticed, but Alex was a terrific guy of very even temperament, displaying nerves of steel in all of our trading sorties. He was six feet tall, had an extremely commanding presence, and was never prone to unnecessary displays of emotion. My observation took place at one of our 7AM meetings. The discussion was about the US real estate market, and I thought I noticed osmething. It wasn't a lapse in concentration, because he was listening intently, no doubt about that. But for just a split second I thought he might say something, and I sensed it might be an unfavorable comment. But whatever it was, he reined himself in and said nothing. Just before we broke up, to return to the trading floor, I thought I noticed it again. And once more the subject was property. But once more our leader refrained from making a comment, and I never gave it another thought. At least not until we were outside the room. That was when Alex pulled Larry McCarthy and me aside and looked at us with a deadly serious expression. \"This housing market,\" he snapped, \"it's 'roided up.\" ... \"This whole thing is fucking ridiculous,\" he confirmed, obviously not wanting to sugarcoat the issue completely. And then he added, just for good measure, \"This market is on fucking steriods.\" The three of us just stood there. And for once Larry was lost for words. He looked straight at Alex, nodded curtly, and held out his right hand. I watched them shake. I witnessed an unspoken bond forged between them. And it was not convertible. We might as well, all three of us, have cut our thumbs with a bowie knife and allowed our blood to mingle, because right there outside that conference room we three had locked our minds into a potential mutiny. And it was one I think we all sensed might one day save this organization, which to a man we believed could be heading for very serious trouble. Triumph with Delta bonds: \"US Air just made a hostile bid for Delta. At least fifty-five cents on the dollar for the bonds.\" I think I nearly died of happiness. Chills ran up my spine, and my pulse was racing as I headed up to the trading floor...I was just running the numbers through my mind, and the key ones were there we now owned about $750 million worth, face value of the bonds and we'd bought most of them for well under 25 cents on the dollar. ... It was not yet seven o'clock, but by now everyone in the entire bank knew about the drama, and a lot of them knew we were about to make a colossal fortune for the firm. The atmosphere was electric, nothing less, as our group moved into gear, because trading was expected to start early, maybe around seven-thirty. The place was packed, and every single eye was on us, especially me, the market maker. But suddenly there was a shift of focus, and we turned to the entrace to the trading floor to see Jane Castle walking in. A huge burst of applause broke out, a spontaneous cry of joy, just for her. Through all the months, through all the doubts and all the fears, she'd never wavered in her valuation of Delta Air Lines, and everyone knew it. The smile on her face would have lit up Yankee Stadium, and she walked straight up to me and gave me a sweeping high five that darn nearly broke my wrist. Moments later Larry came in, wearing a brand-new suit and looking like the king of the world, and another burst of applause ripped into the mourning air. When it died down, he looked over to Joe Beggans, who was about to start trading the Delta bonds, and, with a huge grin on his face, held out his hand and shouted, \"Gimme the keys, Joe. I'm driving!\" The whole place erupted. ... The rest remains a blur until the moment Larry McCarthy decided to get out. \"Okay, guys. Let's go,\" he called, and, for the first time for almost a year, we began to divest ourselves of the Delta bonds. Larry launched them onto the market with consummate skill, knowing, of course, that US Air was out there waiting, begging to buy. By the time he had finished, Lehman had made a $250 million profit, the larget one-day triumph in the history of Lehman Brothers bond trading. Mike Gelband's farewell The news broke the following morning on the Bloomberg tape, and Larry McCarthy was not so much shocked as shattered. Mike Gelband was his linesman, our blocker, the big hitter who was a huge sponsor of all of our risk and short positions. He'd had the most phenomenal career, punctuated by success after success. In a democracy he'd have been swept to power, most certainly by Larry McCarthy, who regarded him as the most talented guy in the building. The chairman and his deputy had somehow found a way to lose him, and that had to rank as one of the most stupid acts he'd ever seen anyone do- anywhere. On the day Mike left, May 2 2007, everyone trooped down to the third floor around eleven to say good-bye. So many people wanted to shake his hand that a huge receiving line formed. Everyone owed him something. He was such a big part of our strength and standing in the corporation. His presense made us count. Some of the women were in tears as the great Lehman banker moved from friend to friend. How could anything ever be the same again. Mike could have saved his job, could have gone on collecting $10 to $20 million a year, every dollar of it earned. But he was not that kind of guy. Like Larry, Mike was certain we were steaming toward the iceberg, with a balance sheet he thought was catastrophically overleveraged. He had to be true not only to the firm but to himself,and he could not countenance the wishes of the chairman. And so he walked away from one of the highest paying jobs on Wall Street, walked away from those enormous earnings. It took a real man to do that. He came over to say a last good-bye to Larry, Joe, and me. And there was a strange silence throughout the trading floor as he did so. When he finally turned away and walked toward the door, there was a sustained and heartfelt burst of applause- not the raucous outpouring that greets a touchdown or a home run, just a fierce clapping of hands, like the kind that greets a pitcher when he's finally relieved in the eighth with his team out in front after a long job, brilliantly done. For the record, he did turn around one last time and, typically, just smiled and nodded to his fans. If he'd been wearing a cap, he would have doffed it- for the good times. Larry McCarthy's farewell \"I told them I'd heard a lot about Dick Fuld over the years. He's a former commercial paper trader, but not once, not one time in all my years here, did I ever see him on the trading floor. Not even on the day me and the guys had the single most profitable day in the history of Lehman's fixed-income division- two hundred fifty million clams, and the guy's a no-show.\" It's hard for Captain Cool to show outage. But I could see it on his face at that moment, just at the memory of that shining day when we sold the Delta bonds and never even received a note or a handshake from the head of the corporation. \"I said I just thought it was very odd, that's all- a pretty unusual way to stay close to your troops.\" For the rest of the morning Larry walked around saying his goodbyes and spending time with the support staff. He told me he was leaving the building right after lunch, but he didn't mention precisely what lunch would mean on this day. It turned out he'd ordered twenty carts of food from the outstanding steakhouse Ben Benson's. That's where he ate, and that was the food he wanted for his guys. When fifteen waiters started pushing them in I thought the A train had veered off its tracks. There were huge metal trays of prime rib, filets, porterhouses, creamed spinach, mountains of potatoes. There was enough shrimp and lobster to feed the population of Martha's Vineyard. Larry had decried, \"No plastic,\" so there was only the finest cutlery and linen napkins. The feast cost him around $14,000. He and I talked quietly while we dined, and he came up with some true McCarthyisms- \"Never tell anyone on Wall Street your problems, old buddy. Ninety percent of those you tell don't care, and the other ten percent are glad you have them.\" ... There were eighteen rows of people between Larry and the door, and one by one they stood up and applauded as he walked past, just as they had with Mike. Larry never looked back. But just before he reached the glass doors, he raised a clenched right fist high in the air. And then he was gone. Something in the soul of Lehman Brothers was gone with him, and it never came back as we steamed ever onward toward Larry's iceberg. The carry trade For a start, commercial paper is short-term money, loaned out for thirty to forty days or less. This market is used by the biggest and best blue-chip companies. Commercial paper is the quickest, cheapest, and easiest way for them to raise a fast loan that is not registed by the SEC. As an example, say Bear Stearns goes to JPMorganChase and requests a $500 million loan for fourteen days. Question- would you lend Bear Stearns half a billion dollars just a couple of weeks when they were backing it with AAA-rated mortgage bonds and willing to pay 5 percent interest? Answer: probably yes, since that would mean a $959,000 profit. Now JPMorganChase isn't going to offer up that $500 million to any old applicant. But Bear Stearns is a highly respected bank, and they've done something similar many times before. The same would apply to Lehman, Morgan Stanley, ... or Countrywide. All of them have always paid back, with the interest, right on time. But in many cases they paid back with money from another short-term paper loan they'd borrow from someone else. For banks with blue-chip lines of credit, it was possible to keep a huge loan rolling for months and months, paying back with borrowed money over andover. Simply put, they were taking short-term borrowed money and investing in longer-term mortgage-backed securities that paid a higher yield. In Wall Street jargon, this was known as the \"carry trade\" or the \"positive carry trade.\"","title":"A Colossal Failure"},{"location":"archives/2020/2020-01-10-colossal_failure/#on-fuck-ups","text":"The trading floor is an arena of instant decisions: all traders are called to make markets all the time, to price the stock, price the bonds, buy, sell, or hold. And I'd just make a mistake. A big one. There was nowhere to turn. No one could help. My word was my bond. There was no going back. Which was precisely when Rich Gatward appeared on my left shoulder, like the angel of death. \"The Calpine trade ... what delta did you do it on?\" The equity trading floor around me suddenly seemed like like the petrified forest. It always does when Gatward comes over. Everyone stops, watching for the scene to unfold. I knew only one thing: I'd shorted only half the stock I should have. Ah...er...Rich, I did it on a 30, but I probably should have done it on a 60.\" \"What's this word _probably_ -- what do you mean by that\" \"Er..I mean we should have done the trade on a 60 delta...\" \"How many shares of stock do you need to sell right now to be hedged?\" I grappled for the bond calculator on the screen and hit the buttons as my entire career flashed before my eyes, the way it does, I believe, when you face instant death. \"Forty-five thousand two hundred, Rich.\" \"Well, don't look at me. Sell the fucking stock,\" he snapped. I could feel every eye on the floor trained on me, and he was not finished yet. \"If you're gonna work on my desk, you don't fly blind. You'd better know your deltas to the fucking penny.\" \"You're right. I screwed up, and I'm sorry. It won't happen again.\" \"You're goddamned right it won't, becuase if it does we're going to have a big fucking probllem. Do you understand that?\" \"Yes, I do. It was a mistake. It won't happen again. I'm sorry.\" \"You'd better be fucking sorry. Right here we're dealing with the firm's capital. You're on my watch, and I have an eye on every fucking penny of risk on this desk- and if you have a problem with that, you can get the fuck out.\" And with that he stormed off, back to his desk. It was as if the entire place could breathe again. People went back to work and the whole shouting, yelling, tempestuous atmosphere of the trading floor swiftly resumed business as usual.","title":"On fuck-ups:"},{"location":"archives/2020/2020-01-10-colossal_failure/#on-executive-presense-and-decision-making","text":"...I twice thought I saw my ultimate boss, Alex Kirk, Lehman's global head of high-yield and leveraged-loan business, and a huge power in the land, look just a tad hard-faced at some of the more optimistic assumptions coming from the guys who walked on water (the mortgage guys). On anyone else I might not have noticed, but Alex was a terrific guy of very even temperament, displaying nerves of steel in all of our trading sorties. He was six feet tall, had an extremely commanding presence, and was never prone to unnecessary displays of emotion. My observation took place at one of our 7AM meetings. The discussion was about the US real estate market, and I thought I noticed osmething. It wasn't a lapse in concentration, because he was listening intently, no doubt about that. But for just a split second I thought he might say something, and I sensed it might be an unfavorable comment. But whatever it was, he reined himself in and said nothing. Just before we broke up, to return to the trading floor, I thought I noticed it again. And once more the subject was property. But once more our leader refrained from making a comment, and I never gave it another thought. At least not until we were outside the room. That was when Alex pulled Larry McCarthy and me aside and looked at us with a deadly serious expression. \"This housing market,\" he snapped, \"it's 'roided up.\" ... \"This whole thing is fucking ridiculous,\" he confirmed, obviously not wanting to sugarcoat the issue completely. And then he added, just for good measure, \"This market is on fucking steriods.\" The three of us just stood there. And for once Larry was lost for words. He looked straight at Alex, nodded curtly, and held out his right hand. I watched them shake. I witnessed an unspoken bond forged between them. And it was not convertible. We might as well, all three of us, have cut our thumbs with a bowie knife and allowed our blood to mingle, because right there outside that conference room we three had locked our minds into a potential mutiny. And it was one I think we all sensed might one day save this organization, which to a man we believed could be heading for very serious trouble.","title":"On executive presense and decision making"},{"location":"archives/2020/2020-01-10-colossal_failure/#triumph-with-delta-bonds","text":"\"US Air just made a hostile bid for Delta. At least fifty-five cents on the dollar for the bonds.\" I think I nearly died of happiness. Chills ran up my spine, and my pulse was racing as I headed up to the trading floor...I was just running the numbers through my mind, and the key ones were there we now owned about $750 million worth, face value of the bonds and we'd bought most of them for well under 25 cents on the dollar. ... It was not yet seven o'clock, but by now everyone in the entire bank knew about the drama, and a lot of them knew we were about to make a colossal fortune for the firm. The atmosphere was electric, nothing less, as our group moved into gear, because trading was expected to start early, maybe around seven-thirty. The place was packed, and every single eye was on us, especially me, the market maker. But suddenly there was a shift of focus, and we turned to the entrace to the trading floor to see Jane Castle walking in. A huge burst of applause broke out, a spontaneous cry of joy, just for her. Through all the months, through all the doubts and all the fears, she'd never wavered in her valuation of Delta Air Lines, and everyone knew it. The smile on her face would have lit up Yankee Stadium, and she walked straight up to me and gave me a sweeping high five that darn nearly broke my wrist. Moments later Larry came in, wearing a brand-new suit and looking like the king of the world, and another burst of applause ripped into the mourning air. When it died down, he looked over to Joe Beggans, who was about to start trading the Delta bonds, and, with a huge grin on his face, held out his hand and shouted, \"Gimme the keys, Joe. I'm driving!\" The whole place erupted. ... The rest remains a blur until the moment Larry McCarthy decided to get out. \"Okay, guys. Let's go,\" he called, and, for the first time for almost a year, we began to divest ourselves of the Delta bonds. Larry launched them onto the market with consummate skill, knowing, of course, that US Air was out there waiting, begging to buy. By the time he had finished, Lehman had made a $250 million profit, the larget one-day triumph in the history of Lehman Brothers bond trading.","title":"Triumph with Delta bonds:"},{"location":"archives/2020/2020-01-10-colossal_failure/#mike-gelbands-farewell","text":"The news broke the following morning on the Bloomberg tape, and Larry McCarthy was not so much shocked as shattered. Mike Gelband was his linesman, our blocker, the big hitter who was a huge sponsor of all of our risk and short positions. He'd had the most phenomenal career, punctuated by success after success. In a democracy he'd have been swept to power, most certainly by Larry McCarthy, who regarded him as the most talented guy in the building. The chairman and his deputy had somehow found a way to lose him, and that had to rank as one of the most stupid acts he'd ever seen anyone do- anywhere. On the day Mike left, May 2 2007, everyone trooped down to the third floor around eleven to say good-bye. So many people wanted to shake his hand that a huge receiving line formed. Everyone owed him something. He was such a big part of our strength and standing in the corporation. His presense made us count. Some of the women were in tears as the great Lehman banker moved from friend to friend. How could anything ever be the same again. Mike could have saved his job, could have gone on collecting $10 to $20 million a year, every dollar of it earned. But he was not that kind of guy. Like Larry, Mike was certain we were steaming toward the iceberg, with a balance sheet he thought was catastrophically overleveraged. He had to be true not only to the firm but to himself,and he could not countenance the wishes of the chairman. And so he walked away from one of the highest paying jobs on Wall Street, walked away from those enormous earnings. It took a real man to do that. He came over to say a last good-bye to Larry, Joe, and me. And there was a strange silence throughout the trading floor as he did so. When he finally turned away and walked toward the door, there was a sustained and heartfelt burst of applause- not the raucous outpouring that greets a touchdown or a home run, just a fierce clapping of hands, like the kind that greets a pitcher when he's finally relieved in the eighth with his team out in front after a long job, brilliantly done. For the record, he did turn around one last time and, typically, just smiled and nodded to his fans. If he'd been wearing a cap, he would have doffed it- for the good times.","title":"Mike Gelband's farewell"},{"location":"archives/2020/2020-01-10-colossal_failure/#larry-mccarthys-farewell","text":"\"I told them I'd heard a lot about Dick Fuld over the years. He's a former commercial paper trader, but not once, not one time in all my years here, did I ever see him on the trading floor. Not even on the day me and the guys had the single most profitable day in the history of Lehman's fixed-income division- two hundred fifty million clams, and the guy's a no-show.\" It's hard for Captain Cool to show outage. But I could see it on his face at that moment, just at the memory of that shining day when we sold the Delta bonds and never even received a note or a handshake from the head of the corporation. \"I said I just thought it was very odd, that's all- a pretty unusual way to stay close to your troops.\" For the rest of the morning Larry walked around saying his goodbyes and spending time with the support staff. He told me he was leaving the building right after lunch, but he didn't mention precisely what lunch would mean on this day. It turned out he'd ordered twenty carts of food from the outstanding steakhouse Ben Benson's. That's where he ate, and that was the food he wanted for his guys. When fifteen waiters started pushing them in I thought the A train had veered off its tracks. There were huge metal trays of prime rib, filets, porterhouses, creamed spinach, mountains of potatoes. There was enough shrimp and lobster to feed the population of Martha's Vineyard. Larry had decried, \"No plastic,\" so there was only the finest cutlery and linen napkins. The feast cost him around $14,000. He and I talked quietly while we dined, and he came up with some true McCarthyisms- \"Never tell anyone on Wall Street your problems, old buddy. Ninety percent of those you tell don't care, and the other ten percent are glad you have them.\" ... There were eighteen rows of people between Larry and the door, and one by one they stood up and applauded as he walked past, just as they had with Mike. Larry never looked back. But just before he reached the glass doors, he raised a clenched right fist high in the air. And then he was gone. Something in the soul of Lehman Brothers was gone with him, and it never came back as we steamed ever onward toward Larry's iceberg.","title":"Larry McCarthy's farewell"},{"location":"archives/2020/2020-01-10-colossal_failure/#the-carry-trade","text":"For a start, commercial paper is short-term money, loaned out for thirty to forty days or less. This market is used by the biggest and best blue-chip companies. Commercial paper is the quickest, cheapest, and easiest way for them to raise a fast loan that is not registed by the SEC. As an example, say Bear Stearns goes to JPMorganChase and requests a $500 million loan for fourteen days. Question- would you lend Bear Stearns half a billion dollars just a couple of weeks when they were backing it with AAA-rated mortgage bonds and willing to pay 5 percent interest? Answer: probably yes, since that would mean a $959,000 profit. Now JPMorganChase isn't going to offer up that $500 million to any old applicant. But Bear Stearns is a highly respected bank, and they've done something similar many times before. The same would apply to Lehman, Morgan Stanley, ... or Countrywide. All of them have always paid back, with the interest, right on time. But in many cases they paid back with money from another short-term paper loan they'd borrow from someone else. For banks with blue-chip lines of credit, it was possible to keep a huge loan rolling for months and months, paying back with borrowed money over andover. Simply put, they were taking short-term borrowed money and investing in longer-term mortgage-backed securities that paid a higher yield. In Wall Street jargon, this was known as the \"carry trade\" or the \"positive carry trade.\"","title":"The carry trade"},{"location":"archives/2020/2020-02-06-cpp-initialising-containers/","tags":"cpp","text":"Modern c++ (v11 and v14) has new ways of initialising standard library containers. void testInitialisingVectors() { // initialise the old way vector< int > v1; v1.push_back(1); v1.push_back(2); // initialise the new way vector< int > v2{1,2}; // initialise using with and without = vector< int > v3 = {1,2}; } void testInitialisingMaps() { // initialise the old way map< int , string> m1; m1[1] = \"hello\" ; cout << \"m1 \" << 1 << \"->\" << m1[1] << endl; // another old way typedef map< int , string>::iterator miter; pair<miter, bool > result = m1.insert( pair< int , string>(2, \"world\" ) ); if (result.second) { cout << \"m1 \" << (result.first)->first << \"->\" << (result.first)->second << endl; } else { cout << \"m1 failed to insert\" << endl; } // reinsert same key again pair<miter, bool > result2 = m1.insert( pair< int , string>(2, \"world\" ) ); if (result2.second) { cout << \"m1 \" << (result2.first)->first << \"->\" << (result2.first)->second << endl; } else { cout << \"m1 failed to insert great!\" << endl; } // initialise the new way map< int ,string> m2{ {1, \"hello\" }, {2, \"world\" } }; cout << \"m2 \" << 1 << \"->\" << m2[1] << endl; cout << \"m2 \" << 2 << \"->\" << m2[2] << endl; // initialise the new way with = map< int ,string> m3 = { {1, \"hello\" }, {2, \"world\" } }; } The result of running these two functions: m1 1->hello m1 2->world m1 failed to insert great! m2 1->hello m2 2->world","title":"C++ initialising containers"},{"location":"archives/2020/2020-02-07-cpp-multimaps/","tags":"cpp","text":"In C++, multimaps are data containers that work like maps but allow multiple instances of the same key! How does this work? void testMultiMap() { multimap<string, int > mm{ { \"mickey\" , 100}, { \"minnie\" , 150}, { \"mickey\" , 200}, { \"minnie\" , 300}, { \"minnie\" , 400} }; cout << \"mickey count \" << mm.count( \"mickey\" ) << endl; cout << \"minnie count \" << mm.count( \"minnie\" ) << endl; auto res = mm.equal_range( \"mickey\" ); for ( auto iter=res.first; iter != res.second; ++iter) { cout << iter->first << \" \" << iter->second << endl; } res = mm.equal_range( \"minnie\" ); for ( auto iter=res.first; iter != res.second; ++iter) { cout << iter->first << \" \" << iter->second << endl; } // erase just the second instance of minnie // reverse iterate because erasing a member removes // member from container for ( auto iter=res.second; iter != res.first; --iter) { if (iter->second>=300) { iter = mm.erase(iter); } } cout << \"after erasing select instances of minnie\" << endl; res = mm.equal_range( \"minnie\" ); for ( auto iter=res.first; iter != res.second; ++iter) { cout << iter->first << \" \" << iter->second << endl; } } After executing this function: mickey count 2 minnie count 3 mickey 100 mickey 200 minnie 150 minnie 300 minnie 400 after erasing select instances of minnie minnie 150 ~~~","title":"C++ How to use multimaps"},{"location":"archives/2020/2020-02-08-cpp-explicit-keyword/","tags":"cpp","text":"In C++, the use of the explicit keyword prevents the compiler from dynamically creating temporaily objects just when value types match the parameter types in its constructor. An example describes this best- class TestClass { public : explicit TestClass( double d) : _d(d) {}; private : double _d; }; void testExplicitKeyword() { vector<TestClass> v1; // with explicit keyword in constructor // this no longer works // v1.push_back(1.0); // this works v1.push_back(TestClass(1.0)); }","title":"C++ explicit keyword"},{"location":"archives/2020/2020-02-09-the-hard-things/","tags":"books","text":"Just read Ben Horowitz's \"The Hard Thing About Hard Things\". Here are some take-aways that I find useful. Why It's Imperative To Tell It Like It Is There are three key reasons why being transparent about your company's problems make sense: Trust Without trust, communication breaks. More specifically- In any human interaction, the required amount of communication is inversely proportional to the level of trust. Consider the following- If I trust you completely, then I require no explanation or communication of your actions whatsoever, because I know that whatever you are doing is in my best interests. On the other hand, if I don't trust you at all, then no amount of talking, explaining, or reasoning will have any effect on me, because I do not trust that you are telling me the truth. [Personal commentary- this reminds me of how the staff of a well-tuned kitchen works.] The more brains working on the hard problems, the better In order to build a great technology company, you have to hire lots of incredibly smart people. It's a total waste to have lots of big brains but not let them work on your biggest problems. A brain, no matter how big, cannot solve a problem it doesn't know about. As the open source community would explain it, \"Given enough eyeballs, all bugs are shallow.\" A good culture is like the old RIP routing protocol- Bad news travel fast; good news travel slow If you investigate companies that have failed, you will find that many employees knew about fatal issues long before those issues killed the company. If the employees knew about the deadly problems, why didn't they say something? (Personal commentary- think NASA or Boeing) Too often the answer is that the company culture discouraged the spread of bad news, so the knowledge lay dormant until it was too late to act. A healthy company culture encourages people to share bad news. A company that discusses its problems freely and openly can quickly solve them. A company that covers up its problems frustrates everyone involved. The resulting action item for CEOs- Build a culture that rewards, not punishes, people for getting problems into the open where they can be solved. As a corollary, beware of management maxims that stop information from flowing freely in your company. For example, consider the old management standard- \"Don't bring me a problem without bringing me a solution.\" What if the employee cannot solve an important problem? For example, what if an engineer identifies a serious flaw in the way the product is being marketed? Do you really want him to bury that information? Management truisms like these may be good for employees to asipre to in the abstract, but they can also be the enemy of free-flowing information- which may be critical for the health of the company.","title":"The Hard Thing About Hard Things"},{"location":"archives/2020/2020-02-09-the-hard-things/#why-its-imperative-to-tell-it-like-it-is","text":"There are three key reasons why being transparent about your company's problems make sense:","title":"Why It's Imperative To Tell It Like It Is"},{"location":"archives/2020/2020-02-09-the-hard-things/#trust","text":"Without trust, communication breaks. More specifically- In any human interaction, the required amount of communication is inversely proportional to the level of trust. Consider the following- If I trust you completely, then I require no explanation or communication of your actions whatsoever, because I know that whatever you are doing is in my best interests. On the other hand, if I don't trust you at all, then no amount of talking, explaining, or reasoning will have any effect on me, because I do not trust that you are telling me the truth. [Personal commentary- this reminds me of how the staff of a well-tuned kitchen works.]","title":"Trust"},{"location":"archives/2020/2020-02-09-the-hard-things/#the-more-brains-working-on-the-hard-problems-the-better","text":"In order to build a great technology company, you have to hire lots of incredibly smart people. It's a total waste to have lots of big brains but not let them work on your biggest problems. A brain, no matter how big, cannot solve a problem it doesn't know about. As the open source community would explain it, \"Given enough eyeballs, all bugs are shallow.\"","title":"The more brains working on the hard problems, the better"},{"location":"archives/2020/2020-02-09-the-hard-things/#a-good-culture-is-like-the-old-rip-routing-protocol-bad-news-travel-fast-good-news-travel-slow","text":"If you investigate companies that have failed, you will find that many employees knew about fatal issues long before those issues killed the company. If the employees knew about the deadly problems, why didn't they say something? (Personal commentary- think NASA or Boeing) Too often the answer is that the company culture discouraged the spread of bad news, so the knowledge lay dormant until it was too late to act. A healthy company culture encourages people to share bad news. A company that discusses its problems freely and openly can quickly solve them. A company that covers up its problems frustrates everyone involved. The resulting action item for CEOs- Build a culture that rewards, not punishes, people for getting problems into the open where they can be solved. As a corollary, beware of management maxims that stop information from flowing freely in your company. For example, consider the old management standard- \"Don't bring me a problem without bringing me a solution.\" What if the employee cannot solve an important problem? For example, what if an engineer identifies a serious flaw in the way the product is being marketed? Do you really want him to bury that information? Management truisms like these may be good for employees to asipre to in the abstract, but they can also be the enemy of free-flowing information- which may be critical for the health of the company.","title":"A good culture is like the old RIP routing protocol- Bad news travel fast; good news travel slow"},{"location":"archives/2020/2020-02-10-heroku-howto/","tags":"history","text":"Quick Notes File system - data written to the file system when the virtual server restarts. Use a shared file storage system such as AWS S3 instead. Sharing state across multiple servers- requires a distributed store like Memcached. Dependency management - requires language specific tools like Bundler for Ruby or Ivy or Java Dyno- a dyno is a standard unit of virtual server capability. Logs- to see logs, do heroku logs --tail Steps heroku login in folder container git repository heroku create (this creates an application in heroku to contain the git code it also sets the app to point to the git repo) git push heroku master (deploys code to virtual machine)","title":"Heroku Notes"},{"location":"archives/2020/2020-02-10-heroku-howto/#quick-notes","text":"File system - data written to the file system when the virtual server restarts. Use a shared file storage system such as AWS S3 instead. Sharing state across multiple servers- requires a distributed store like Memcached. Dependency management - requires language specific tools like Bundler for Ruby or Ivy or Java Dyno- a dyno is a standard unit of virtual server capability. Logs- to see logs, do heroku logs --tail","title":"Quick Notes"},{"location":"archives/2020/2020-02-10-heroku-howto/#steps","text":"heroku login in folder container git repository heroku create (this creates an application in heroku to contain the git code it also sets the app to point to the git repo) git push heroku master (deploys code to virtual machine)","title":"Steps"},{"location":"archives/2020/2020-02-11-who-gets-what/","tags":"books","text":"Quick Notes Economics is about the efficient allocation of scare resources, and about making them less scarce. One way financial markets provide thickness to ordinary traders is by giving certain professional traders the incentive to become \"liquidity providers.\" Members of this group don't plan to hold a security and watch it appreciate; rather, they move fast and act as market makers. They always offer both a bid and an ask on the financial commodity for which they are making a market; that is, they simultaneously offer to buy and sell. Liquidity providers make their money by having a spread between those buy and sell offers, which they continuously adjust as the market moves. The narrower that spread, the greater the quantity they offer to buy or sell at that spread, the better service they are able to provide to whoever comes on the market to make a trade. But when there are high-speed traders in the markets, LPs are forced to quote bigger spreads or offer to trade a lower quantity to at least partially protect themselves against being 'sniped' by a trader using one of the new superfast lines. Such a trader might be able to buy from them at their old prices (now out of date, or 'stale') and then moments later sell back to them at the new higher prices. The wider the spreads the LPs quote, the further prices have to jump before they can be exploited on both sides of the trade this way, and the more they pass on the cost of protecting themselvs to ordinary investors.","title":"Who Gets What And Why"},{"location":"archives/2020/2020-02-11-who-gets-what/#quick-notes","text":"Economics is about the efficient allocation of scare resources, and about making them less scarce. One way financial markets provide thickness to ordinary traders is by giving certain professional traders the incentive to become \"liquidity providers.\" Members of this group don't plan to hold a security and watch it appreciate; rather, they move fast and act as market makers. They always offer both a bid and an ask on the financial commodity for which they are making a market; that is, they simultaneously offer to buy and sell. Liquidity providers make their money by having a spread between those buy and sell offers, which they continuously adjust as the market moves. The narrower that spread, the greater the quantity they offer to buy or sell at that spread, the better service they are able to provide to whoever comes on the market to make a trade. But when there are high-speed traders in the markets, LPs are forced to quote bigger spreads or offer to trade a lower quantity to at least partially protect themselves against being 'sniped' by a trader using one of the new superfast lines. Such a trader might be able to buy from them at their old prices (now out of date, or 'stale') and then moments later sell back to them at the new higher prices. The wider the spreads the LPs quote, the further prices have to jump before they can be exploited on both sides of the trade this way, and the more they pass on the cost of protecting themselvs to ordinary investors.","title":"Quick Notes"},{"location":"archives/2020/2020-03-01-many-ideas/","tags":"patterns","text":"Depressive Realism Depressed people have a more accurate view of the world because they\u2019re more realistic about how risky and fragile life is. The opposite of \u201cblissfully unaware.\u201d Skill Compensation People who are exceptionally good at one thing tend to be exceptionally poor at another. Curse of Knowledge The inability to communicate your ideas because you wrongly assume others have the necessary background to understand what you\u2019re talking about. Base Rates The success rate of everyone who\u2019s done what you\u2019re about to try. Base-Rate Neglect Assuming the success rate of everyone who\u2019s done what you\u2019re about to try doesn\u2019t apply to you, caused by overestimating the extent to which you do things differently than everyone else. Compassion Fade People have more compassion for small groups of victims than larger groups, because the smaller the group the easier it is to identify individual victims. System Justification Theory Inefficient systems will be defended and maintained if they serve the needs of people who benefit from them \u2013 individual incentives can sustain systemic stupidity. Three Men Make a Tiger People will believe anything if enough people tell them it\u2019s true. It comes from a Chinese proverb that if one person tells you there\u2019s a tiger roaming around your neighborhood, you can assume they\u2019re lying. If two people tell you, you begin to wonder. If three say it\u2019s true, you\u2019re convinced there\u2019s a tiger in your neighborhood and you panic. Buridan\u2019s Ass A thirsty donkey is placed exactly midway between two pails of water. It dies because it can\u2019t make a rational decision about which one to choose. A form of decision paralysis. Pareto Principle The majority of outcomes are driven by a minority of events. Sturgeon\u2019s Law \u201c90% of everything is crap.\u201d The obvious inverse of the Pareto Principle, but hard to accept in practice. Cumulative advantage Social status snowballs in either direction because people like associating with successful people, so doors are opened for them, and avoid associating with unsuccessful people, for whom doors are closed. Impostor Syndrome Fear of being exposed as less talented than people think you are, often because talent is owed to cumulative advantage rather than actual effort or skill. Anscombe\u2019s Quartet Four sets of numbers that look identical on paper (mean average, variance, correlation, etc.) but look completely different when graphed. Describes a situation where exact calculations don\u2019t offer a good representation of how the world works. Ringelmann Effect Members of a group become lazier as the size of their group increases. Based on the assumption that \u201csomeone else is probably taking care of that.\u201d Semmelweis Reflex Automatically rejecting evidence that contradicts your tribe\u2019s established norms. Named after a Hungarian doctor who discovered that patients treated by doctors who wash their hands suffer fewer infections, but struggled to convince other doctors that his finding was true. False-Consensus Effect Overestimating how widely held your own beliefs are, caused by the difficulty of imagining the experiences of other people. Boomerang Effect Trying to persuade someone to do one thing can make them more likely to do the opposite, because the act of persuasion can feel like someone stealing your freedom and doing the opposite makes you feel like you\u2019re taking your freedom back. Chronological Snobbery \u201cThe assumption that whatever has gone out of date is on that account discredited. You must find why it went out of date. Was it ever refuted (and if so by whom, where, and how conclusively) or did it merely die away as fashions do? If the latter, this tells us nothing about its truth or falsehood. From seeing this, one passes to the realization that our own age is also \u2018a period,\u2019 and certainly has, like all periods, its own characteristic illusions.\u201d \u2013 C.S. Lewis Planck\u2019s Principle \u201cA new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die and a new generation grows up that is familiar with it.\u201d McNamara Fallacy A belief that rational decisions can be made with quantitative measures alone, when in fact the things you can\u2019t measure are often the most consequential. Named after Defense Secretary McNamara, who tried to quantify every aspect of the Vietnam War. Courtesy Bias Giving opinions that are likely to offend people the least, rather than what you actually believe. Berkson\u2019s Paradox Strong correlations can fall apart when combined with a larger population. Among hospital patients, motorcycle crash victims wearing helmets are more likely to be seriously injured than those not wearing helmets. But that\u2019s because most crash victims saved by helmets did not need to become hospital patients, and those without helmets are more likely to die before becoming a hospital patient. Group Attribution Error Incorrectly assuming that the views of a group member reflect those of the whole group. Baader-Meinhof Phenomenon Noticing an idea everywhere you look as soon as it\u2019s brought to your attention in a way that makes you overestimate its prevalence. Ludic Fallacy Falsely associated simulations with real life. Nassim Taleb \u201cOrganized competitive fighting trains the athlete to focus on the game and, in order not to dissipate his concentration, to ignore the possibility of what is not specifically allowed by the rules, such as kicks to the groin, a surprise knife, et cetera. So those who win the gold medal might be precisely those who will be most vulnerable in real life.\u201d Normalcy Bias Underestimating the odds of disaster because it\u2019s comforting to assume things will keep functioning the way they\u2019ve always functioned. Actor-Observer Asymmetry We judge others based solely on their actions, but when judging ourselves we have an internal dialogue that justifies our mistakes and bad decisions. The 90-9-1 Rule In social media networks, 90% of users just read content, 9% of users contribute a little content, and 1% of users contribute almost all the content. Gives a false impression of what ideas are popular or \u201caverage.\u201d Texas Sharpshooter Fallacy Goals set retroactively after an activity, like shooting a blank wall and then drawing a bullseye around the holes you left, or picking a benchmark after you\u2019ve invested. Fredkin\u2019s Paradox Confronted with two equally good options, you struggle to decide, even though your decision doesn\u2019t matter because both options are equally good. The more equal the options, the harder the decision. Poisoning the Well Presenting irrelevant adverse information about someone in a way that makes everything else that person says seem untrustworthy. \u201cBefore you hear my opponent\u2019s healthcare plan, let me remind you that he got a DUI in college.\u201d Golem Effect Performance declines when supervisors/teachers have low expectations of your abilities. Appeal to Consequences Arguing that a hypothesis must be true (or false) because the outcome is something you like (or dislike). The classic example is arguing that climate change isn\u2019t real because combating climate change will hurt the economy. Plain Folks Fallacy People of authority acquiring trust by presenting themselves as Average Joe\u2019s, when in fact their authority proves they are different from everyone else. Behavioral Inevitability \u201cHistory never repeats itself; man always does.\u201d \u2013 Voltaire Apophenia A tendency to perceive correlations between unrelated things, because your mind can only deal with tiny sample sizes and assuming things are correlated creates easy/comforting explanations of how the world works. Self-Handicapping Avoiding effort because you don\u2019t want to deal with the emotional pain of that effort failing. Hanlon\u2019s Razor \u201cNever attribute to malice that which can be adequately explained by stupidity.\u201d False Uniqueness Effect Assuming your skills are unique when they\u2019re not. Comes from conflating \u201cI\u2019m good at this\u201d with \u201cOthers are bad at this.\u201d Hard-Easy Effect Hard tasks promote overconfidence because the rewards are high and fun to dream about; easy tasks promote underconfidence because they\u2019re boring and easy to put off. Neglect of Probability Arguing that Nate Silver was wrong when he said Hillary Clinton has a 70% chance of winning, and using Donald Trump\u2019s victory as your proof. Good predictions are based on probabilities, but the assessment of predictions are always binary, right or wrong. Cobra Effect Attempting to solve a problem makes that problem worse. Comes from an Indian story about a city infested with snakes offering a bounty for every dead cobra, which caused entrepreneurs to start breeding cobras for slaughter. Braess\u2019s Paradox Adding more roads can make traffic worse because new shortcuts become popular and overcrowded. Non-Ergodic When group probabilities don\u2019t apply to singular events. If 100 people play Russian Roulette once, the odds of dying might be, say, 10%. But if one person plays Russian Roulette 100 times, the odds are dying are practically 100%. Pollyanna Principle It\u2019s easier to remember happy memories than bad ones. Declinism Perpetually viewing society as in decline, because you\u2019re afflicted by the Pollyanna Principle and you forget how much things sucked in the past. Empathy Gap Underestimating how you\u2019ll behave when you\u2019re \u201chot\u201d (angry/aroused/rushed), caused by the inability to accurately foresee how your body\u2019s physical response to situations (dopamine, adrenaline, etc.) will influence decision-making. Abilene Paradox A group decides to do something that no one in the group wants to do because everyone mistakenly assumes they\u2019re the only ones who object to the idea and they don\u2019t want to rock the boat by speaking up. Collective Narcissism Exaggerating the importance and influence of your social group (country, industry, company, department, etc.). Moral Luck Praising someone for a good deed they didn\u2019t have full control over. \u201cAvoid calling heroes those who had no other choice.\u201d \u2013 Taleb. Feedback Loops Falling stock prices scare people, which cause them to sell, which makes prices fall, which scares more people, which causes more people to sell, and so on. Works both ways. Hawthorne Effect Being watched/studied changes how people behave, making it difficult to conduct social studies that accurately reflect the real world. Perfect Solution Fallacy Comparing reality with an idealized alternative. Prevalent in any field governed by uncertainty. Weasel Words Phrases that appear to have meaning but convey nothing tangible. \u201cGrowth was solid last quarter,\u201d or \u201cMany people believe.\u201d Hormesis Something that hurts you in a high dose can be good for you in small doses. (Weight on your bones, drinking red wine, etc.) Backfiring Effect A supercharged version of confirmation bias where being presented with evidence that goes against your beliefs makes you double down on your initial beliefs because you feel you\u2019re being attacked. Reflexivity When cause and effect are the same. People think Tesla will sell a lot of cars, so Tesla stock goes up, which lets Tesla raise a bunch of new capital, which helps Tesla sell a lot of cars. Second Half of the Chessboard Put one grain of rice on the first chessboard square, two on the next, four on the next, then eight, then sixteen, etc, doubling the amount of rice on each square. When you\u2019ve covered half the chessboard\u2019s squares you\u2019re dealing with an amount of rice that can fit in your lap; in the second half you quickly get to a pile that will consume an entire city. That\u2019s how compounding works slowly, then ferociously. Peter Principle Good workers will continue to be promoted until they end up in a role they\u2019re bad at. Friendship Paradox On average, people have fewer friends than their friends have. Occurs because people with an abnormally high number of friends are more likely to be one of your friends. It\u2019s a fundamental part of social network dynamics and makes most people feel less popular than they are. Hedonic Treadmill Expectations rise with results, so nothing feels as good as you\u2019d imagine for as long as you\u2019d expect. Positive Illusions Excessively rosy views about the decisions you\u2019ve made to maintain self-esteem in a world where everyone makes bad decisions all the time. Ironic Process Theory Going out of your way to suppress thoughts makes those thoughts more prominent in your mind. Clustering Illusions Falsely assuming that the inevitable bunching of random results in a large sample indicates a trend. Foundational Species A single thing that plays an outsized role in supporting an ecosystem, whose loss would pull down many others with it. In nature kelp, algae, and coral. In business The Federal Reserve and Amazon. Bizarreness Effect Crazy things are easier to remember than common things, providing a distorted sense of \u201cnormal.\u201d Nonlinearity Outputs aren\u2019t always proportional to inputs, so the world is a barrage of massive wins and horrible losses that surprise people. Moderating Relationship The correlation between two variables depends on a third, seemingly unrelated variable. The quality of a marriage may be dependent on a spouse\u2019s work project that\u2019s causing stress. Denomination Effect One hundred $1 bills feels like less money than one $100 bill. Also explains stock splits \u2013 buying 10 shares for $10 each feels cheaper than one share for $100. Woozle Effect \u201cA reliable way to make people believe in falsehoods is frequent repetition, because familiarity is not easily distinguished from truth.\u201d - Daniel Kahneman. Google Scholar Effect Scientific research depends on citing other research, and the research that gets cited the most is whatever shows up in the top results of Google Scholar searches, regardless of its contribution to the field. Inversion Avoiding problems can be more important than scoring wins. Gambler\u2019s Ruin Has many meanings, the most important of which is that playing a negative-probability game persistently enough guarantees going broke. Principle of Least Effort When seeking information, effort declines as soon as the minimum acceptable result is reached. Dunning-Kruger Effect Knowing the limits of your intelligence requires a certain level of intelligence, so some people are too stupid to know how stupid they are. Knightian Uncertainty Risk that can\u2019t be measured; admitting that you don\u2019t know what you don\u2019t know. Aumann\u2019s Agreement Theorem If you understand your opponent\u2019s beliefs you cannot agree to disagree. If you agree to disagree it\u2019s because one side doesn\u2019t understand the other side\u2019s view. Focusing Effect Overemphasizing factors that seem important but exist as part of a complex system. People from the Midwest assume Californians are happier because the weather is better, but they\u2019re not because Californians also deal with traffic, bad bosses, unhappy marriages, etc, which more than offset the happiness boost from sunny skies. The Middle Ground Fallacy Falsely assuming that splitting the difference between two polar opposite views is a healthy compromise. If one person says vaccines cause autism and another person says they don\u2019t, it\u2019s not right to compromise and say vaccines sometimes cause autism. Rebound Effect New symptoms, or supercharged old symptoms, emerge when medicine or other protections are withdrawn. Ostrich Effect Avoiding negative information that might challenge views that you desperately want to be right. Founder\u2019s Syndrome When a CEO is so emotionally invested in a company that they can\u2019t effectively delegate decisions. In-Group Favoritism Giving preference to people from your social group regardless of their objective qualifications. Bounded Rationality People can\u2019t be fully rational because your brain is a hormone machine, not an Excel spreadsheet. Luxury Paradox The more expensive something is the less likely you are to use it, so the relationship between price and utility is an inverted U. Ferraris sit in garages; Hondas get driven. Meat Paradox Dogs are family, pigs are food. Some animals classified as food are wrongly perceived to have lower intelligence than those classified as pets. An example of morality depending on utility. Fluency Heuristic Ideas that can be explained simply are more likely to be believed than those that are complex, even if the simple-sounding ideas are nonsense. It occurs because ideas that are easy to grasp are hard to distinguish from ideas you\u2019re familiar with. Historical Wisdom \u201cThe dead outnumber the living 14 to 1, and we ignore the accumulated experience of such a huge majority of mankind at our peril.\u201d \u2013 Niall Ferguson Fact-Check Scarcity Principle This article is called 100 Little Ideas but there are fewer than 100 ideas. 99% of readers won\u2019t notice because they\u2019re not checking, and most of those who notice won\u2019t say anything. Don\u2019t believe everything you read. Emotional Contagion One person\u2019s emotions trigger the same emotions in other people, because evolution has selected for empathizing with those in your social group whose actions you rely on. Tribal Affiliation Beliefs can be swayed by identity and a desire to fit in over rational analysis. There is little correlation between climate change denial and scientific literacy. But there is a strong correlation between climate change denial and political affiliation. Emotional Competence The ability to recognize others\u2019 emotions and respond to them productively. Harder and rarer than it sounds.","title":"Ideas From Many Fields"},{"location":"archives/2020/2020-03-01-many-ideas/#depressive-realism","text":"Depressed people have a more accurate view of the world because they\u2019re more realistic about how risky and fragile life is. The opposite of \u201cblissfully unaware.\u201d","title":"Depressive Realism"},{"location":"archives/2020/2020-03-01-many-ideas/#skill-compensation","text":"People who are exceptionally good at one thing tend to be exceptionally poor at another.","title":"Skill Compensation"},{"location":"archives/2020/2020-03-01-many-ideas/#curse-of-knowledge","text":"The inability to communicate your ideas because you wrongly assume others have the necessary background to understand what you\u2019re talking about.","title":"Curse of Knowledge"},{"location":"archives/2020/2020-03-01-many-ideas/#base-rates","text":"The success rate of everyone who\u2019s done what you\u2019re about to try.","title":"Base Rates"},{"location":"archives/2020/2020-03-01-many-ideas/#base-rate-neglect","text":"Assuming the success rate of everyone who\u2019s done what you\u2019re about to try doesn\u2019t apply to you, caused by overestimating the extent to which you do things differently than everyone else.","title":"Base-Rate Neglect"},{"location":"archives/2020/2020-03-01-many-ideas/#compassion-fade","text":"People have more compassion for small groups of victims than larger groups, because the smaller the group the easier it is to identify individual victims.","title":"Compassion Fade"},{"location":"archives/2020/2020-03-01-many-ideas/#system-justification-theory","text":"Inefficient systems will be defended and maintained if they serve the needs of people who benefit from them \u2013 individual incentives can sustain systemic stupidity.","title":"System Justification Theory"},{"location":"archives/2020/2020-03-01-many-ideas/#three-men-make-a-tiger","text":"People will believe anything if enough people tell them it\u2019s true. It comes from a Chinese proverb that if one person tells you there\u2019s a tiger roaming around your neighborhood, you can assume they\u2019re lying. If two people tell you, you begin to wonder. If three say it\u2019s true, you\u2019re convinced there\u2019s a tiger in your neighborhood and you panic.","title":"Three Men Make a Tiger"},{"location":"archives/2020/2020-03-01-many-ideas/#buridans-ass","text":"A thirsty donkey is placed exactly midway between two pails of water. It dies because it can\u2019t make a rational decision about which one to choose. A form of decision paralysis.","title":"Buridan\u2019s Ass"},{"location":"archives/2020/2020-03-01-many-ideas/#pareto-principle","text":"The majority of outcomes are driven by a minority of events.","title":"Pareto Principle"},{"location":"archives/2020/2020-03-01-many-ideas/#sturgeons-law","text":"\u201c90% of everything is crap.\u201d The obvious inverse of the Pareto Principle, but hard to accept in practice.","title":"Sturgeon\u2019s Law"},{"location":"archives/2020/2020-03-01-many-ideas/#cumulative-advantage","text":"Social status snowballs in either direction because people like associating with successful people, so doors are opened for them, and avoid associating with unsuccessful people, for whom doors are closed.","title":"Cumulative advantage"},{"location":"archives/2020/2020-03-01-many-ideas/#impostor-syndrome","text":"Fear of being exposed as less talented than people think you are, often because talent is owed to cumulative advantage rather than actual effort or skill.","title":"Impostor Syndrome"},{"location":"archives/2020/2020-03-01-many-ideas/#anscombes-quartet","text":"Four sets of numbers that look identical on paper (mean average, variance, correlation, etc.) but look completely different when graphed. Describes a situation where exact calculations don\u2019t offer a good representation of how the world works.","title":"Anscombe\u2019s Quartet"},{"location":"archives/2020/2020-03-01-many-ideas/#ringelmann-effect","text":"Members of a group become lazier as the size of their group increases. Based on the assumption that \u201csomeone else is probably taking care of that.\u201d","title":"Ringelmann Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#semmelweis-reflex","text":"Automatically rejecting evidence that contradicts your tribe\u2019s established norms. Named after a Hungarian doctor who discovered that patients treated by doctors who wash their hands suffer fewer infections, but struggled to convince other doctors that his finding was true.","title":"Semmelweis Reflex"},{"location":"archives/2020/2020-03-01-many-ideas/#false-consensus-effect","text":"Overestimating how widely held your own beliefs are, caused by the difficulty of imagining the experiences of other people.","title":"False-Consensus Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#boomerang-effect","text":"Trying to persuade someone to do one thing can make them more likely to do the opposite, because the act of persuasion can feel like someone stealing your freedom and doing the opposite makes you feel like you\u2019re taking your freedom back.","title":"Boomerang Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#chronological-snobbery","text":"\u201cThe assumption that whatever has gone out of date is on that account discredited. You must find why it went out of date. Was it ever refuted (and if so by whom, where, and how conclusively) or did it merely die away as fashions do? If the latter, this tells us nothing about its truth or falsehood. From seeing this, one passes to the realization that our own age is also \u2018a period,\u2019 and certainly has, like all periods, its own characteristic illusions.\u201d \u2013 C.S. Lewis","title":"Chronological Snobbery"},{"location":"archives/2020/2020-03-01-many-ideas/#plancks-principle","text":"\u201cA new scientific truth does not triumph by convincing its opponents and making them see the light, but rather because its opponents eventually die and a new generation grows up that is familiar with it.\u201d","title":"Planck\u2019s Principle"},{"location":"archives/2020/2020-03-01-many-ideas/#mcnamara-fallacy","text":"A belief that rational decisions can be made with quantitative measures alone, when in fact the things you can\u2019t measure are often the most consequential. Named after Defense Secretary McNamara, who tried to quantify every aspect of the Vietnam War.","title":"McNamara Fallacy"},{"location":"archives/2020/2020-03-01-many-ideas/#courtesy-bias","text":"Giving opinions that are likely to offend people the least, rather than what you actually believe.","title":"Courtesy Bias"},{"location":"archives/2020/2020-03-01-many-ideas/#berksons-paradox","text":"Strong correlations can fall apart when combined with a larger population. Among hospital patients, motorcycle crash victims wearing helmets are more likely to be seriously injured than those not wearing helmets. But that\u2019s because most crash victims saved by helmets did not need to become hospital patients, and those without helmets are more likely to die before becoming a hospital patient.","title":"Berkson\u2019s Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#group-attribution-error","text":"Incorrectly assuming that the views of a group member reflect those of the whole group.","title":"Group Attribution Error"},{"location":"archives/2020/2020-03-01-many-ideas/#baader-meinhof-phenomenon","text":"Noticing an idea everywhere you look as soon as it\u2019s brought to your attention in a way that makes you overestimate its prevalence.","title":"Baader-Meinhof Phenomenon"},{"location":"archives/2020/2020-03-01-many-ideas/#ludic-fallacy","text":"Falsely associated simulations with real life. Nassim Taleb \u201cOrganized competitive fighting trains the athlete to focus on the game and, in order not to dissipate his concentration, to ignore the possibility of what is not specifically allowed by the rules, such as kicks to the groin, a surprise knife, et cetera. So those who win the gold medal might be precisely those who will be most vulnerable in real life.\u201d","title":"Ludic Fallacy"},{"location":"archives/2020/2020-03-01-many-ideas/#normalcy-bias","text":"Underestimating the odds of disaster because it\u2019s comforting to assume things will keep functioning the way they\u2019ve always functioned.","title":"Normalcy Bias"},{"location":"archives/2020/2020-03-01-many-ideas/#actor-observer-asymmetry","text":"We judge others based solely on their actions, but when judging ourselves we have an internal dialogue that justifies our mistakes and bad decisions.","title":"Actor-Observer Asymmetry"},{"location":"archives/2020/2020-03-01-many-ideas/#the-90-9-1-rule","text":"In social media networks, 90% of users just read content, 9% of users contribute a little content, and 1% of users contribute almost all the content. Gives a false impression of what ideas are popular or \u201caverage.\u201d","title":"The 90-9-1 Rule"},{"location":"archives/2020/2020-03-01-many-ideas/#texas-sharpshooter-fallacy","text":"Goals set retroactively after an activity, like shooting a blank wall and then drawing a bullseye around the holes you left, or picking a benchmark after you\u2019ve invested.","title":"Texas Sharpshooter Fallacy"},{"location":"archives/2020/2020-03-01-many-ideas/#fredkins-paradox","text":"Confronted with two equally good options, you struggle to decide, even though your decision doesn\u2019t matter because both options are equally good. The more equal the options, the harder the decision.","title":"Fredkin\u2019s Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#poisoning-the-well","text":"Presenting irrelevant adverse information about someone in a way that makes everything else that person says seem untrustworthy. \u201cBefore you hear my opponent\u2019s healthcare plan, let me remind you that he got a DUI in college.\u201d","title":"Poisoning the Well"},{"location":"archives/2020/2020-03-01-many-ideas/#golem-effect","text":"Performance declines when supervisors/teachers have low expectations of your abilities.","title":"Golem Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#appeal-to-consequences","text":"Arguing that a hypothesis must be true (or false) because the outcome is something you like (or dislike). The classic example is arguing that climate change isn\u2019t real because combating climate change will hurt the economy.","title":"Appeal to Consequences"},{"location":"archives/2020/2020-03-01-many-ideas/#plain-folks-fallacy","text":"People of authority acquiring trust by presenting themselves as Average Joe\u2019s, when in fact their authority proves they are different from everyone else.","title":"Plain Folks Fallacy"},{"location":"archives/2020/2020-03-01-many-ideas/#behavioral-inevitability","text":"\u201cHistory never repeats itself; man always does.\u201d \u2013 Voltaire","title":"Behavioral Inevitability"},{"location":"archives/2020/2020-03-01-many-ideas/#apophenia","text":"A tendency to perceive correlations between unrelated things, because your mind can only deal with tiny sample sizes and assuming things are correlated creates easy/comforting explanations of how the world works.","title":"Apophenia"},{"location":"archives/2020/2020-03-01-many-ideas/#self-handicapping","text":"Avoiding effort because you don\u2019t want to deal with the emotional pain of that effort failing.","title":"Self-Handicapping"},{"location":"archives/2020/2020-03-01-many-ideas/#hanlons-razor","text":"\u201cNever attribute to malice that which can be adequately explained by stupidity.\u201d","title":"Hanlon\u2019s Razor"},{"location":"archives/2020/2020-03-01-many-ideas/#false-uniqueness-effect","text":"Assuming your skills are unique when they\u2019re not. Comes from conflating \u201cI\u2019m good at this\u201d with \u201cOthers are bad at this.\u201d","title":"False Uniqueness Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#hard-easy-effect","text":"Hard tasks promote overconfidence because the rewards are high and fun to dream about; easy tasks promote underconfidence because they\u2019re boring and easy to put off.","title":"Hard-Easy Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#neglect-of-probability","text":"Arguing that Nate Silver was wrong when he said Hillary Clinton has a 70% chance of winning, and using Donald Trump\u2019s victory as your proof. Good predictions are based on probabilities, but the assessment of predictions are always binary, right or wrong.","title":"Neglect of Probability"},{"location":"archives/2020/2020-03-01-many-ideas/#cobra-effect","text":"Attempting to solve a problem makes that problem worse. Comes from an Indian story about a city infested with snakes offering a bounty for every dead cobra, which caused entrepreneurs to start breeding cobras for slaughter.","title":"Cobra Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#braesss-paradox","text":"Adding more roads can make traffic worse because new shortcuts become popular and overcrowded.","title":"Braess\u2019s Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#non-ergodic","text":"When group probabilities don\u2019t apply to singular events. If 100 people play Russian Roulette once, the odds of dying might be, say, 10%. But if one person plays Russian Roulette 100 times, the odds are dying are practically 100%.","title":"Non-Ergodic"},{"location":"archives/2020/2020-03-01-many-ideas/#pollyanna-principle","text":"It\u2019s easier to remember happy memories than bad ones.","title":"Pollyanna Principle"},{"location":"archives/2020/2020-03-01-many-ideas/#declinism","text":"Perpetually viewing society as in decline, because you\u2019re afflicted by the Pollyanna Principle and you forget how much things sucked in the past.","title":"Declinism"},{"location":"archives/2020/2020-03-01-many-ideas/#empathy-gap","text":"Underestimating how you\u2019ll behave when you\u2019re \u201chot\u201d (angry/aroused/rushed), caused by the inability to accurately foresee how your body\u2019s physical response to situations (dopamine, adrenaline, etc.) will influence decision-making.","title":"Empathy Gap"},{"location":"archives/2020/2020-03-01-many-ideas/#abilene-paradox","text":"A group decides to do something that no one in the group wants to do because everyone mistakenly assumes they\u2019re the only ones who object to the idea and they don\u2019t want to rock the boat by speaking up.","title":"Abilene Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#collective-narcissism","text":"Exaggerating the importance and influence of your social group (country, industry, company, department, etc.).","title":"Collective Narcissism"},{"location":"archives/2020/2020-03-01-many-ideas/#moral-luck","text":"Praising someone for a good deed they didn\u2019t have full control over. \u201cAvoid calling heroes those who had no other choice.\u201d \u2013 Taleb.","title":"Moral Luck"},{"location":"archives/2020/2020-03-01-many-ideas/#feedback-loops","text":"Falling stock prices scare people, which cause them to sell, which makes prices fall, which scares more people, which causes more people to sell, and so on. Works both ways.","title":"Feedback Loops"},{"location":"archives/2020/2020-03-01-many-ideas/#hawthorne-effect","text":"Being watched/studied changes how people behave, making it difficult to conduct social studies that accurately reflect the real world.","title":"Hawthorne Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#perfect-solution-fallacy","text":"Comparing reality with an idealized alternative. Prevalent in any field governed by uncertainty.","title":"Perfect Solution Fallacy"},{"location":"archives/2020/2020-03-01-many-ideas/#weasel-words","text":"Phrases that appear to have meaning but convey nothing tangible. \u201cGrowth was solid last quarter,\u201d or \u201cMany people believe.\u201d","title":"Weasel Words"},{"location":"archives/2020/2020-03-01-many-ideas/#hormesis","text":"Something that hurts you in a high dose can be good for you in small doses. (Weight on your bones, drinking red wine, etc.)","title":"Hormesis"},{"location":"archives/2020/2020-03-01-many-ideas/#backfiring-effect","text":"A supercharged version of confirmation bias where being presented with evidence that goes against your beliefs makes you double down on your initial beliefs because you feel you\u2019re being attacked.","title":"Backfiring Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#reflexivity","text":"When cause and effect are the same. People think Tesla will sell a lot of cars, so Tesla stock goes up, which lets Tesla raise a bunch of new capital, which helps Tesla sell a lot of cars.","title":"Reflexivity"},{"location":"archives/2020/2020-03-01-many-ideas/#second-half-of-the-chessboard","text":"Put one grain of rice on the first chessboard square, two on the next, four on the next, then eight, then sixteen, etc, doubling the amount of rice on each square. When you\u2019ve covered half the chessboard\u2019s squares you\u2019re dealing with an amount of rice that can fit in your lap; in the second half you quickly get to a pile that will consume an entire city. That\u2019s how compounding works slowly, then ferociously.","title":"Second Half of the Chessboard"},{"location":"archives/2020/2020-03-01-many-ideas/#peter-principle","text":"Good workers will continue to be promoted until they end up in a role they\u2019re bad at.","title":"Peter Principle"},{"location":"archives/2020/2020-03-01-many-ideas/#friendship-paradox","text":"On average, people have fewer friends than their friends have. Occurs because people with an abnormally high number of friends are more likely to be one of your friends. It\u2019s a fundamental part of social network dynamics and makes most people feel less popular than they are.","title":"Friendship Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#hedonic-treadmill","text":"Expectations rise with results, so nothing feels as good as you\u2019d imagine for as long as you\u2019d expect.","title":"Hedonic Treadmill"},{"location":"archives/2020/2020-03-01-many-ideas/#positive-illusions","text":"Excessively rosy views about the decisions you\u2019ve made to maintain self-esteem in a world where everyone makes bad decisions all the time.","title":"Positive Illusions"},{"location":"archives/2020/2020-03-01-many-ideas/#ironic-process-theory","text":"Going out of your way to suppress thoughts makes those thoughts more prominent in your mind.","title":"Ironic Process Theory"},{"location":"archives/2020/2020-03-01-many-ideas/#clustering-illusions","text":"Falsely assuming that the inevitable bunching of random results in a large sample indicates a trend.","title":"Clustering Illusions"},{"location":"archives/2020/2020-03-01-many-ideas/#foundational-species","text":"A single thing that plays an outsized role in supporting an ecosystem, whose loss would pull down many others with it. In nature kelp, algae, and coral. In business The Federal Reserve and Amazon.","title":"Foundational Species"},{"location":"archives/2020/2020-03-01-many-ideas/#bizarreness-effect","text":"Crazy things are easier to remember than common things, providing a distorted sense of \u201cnormal.\u201d","title":"Bizarreness Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#nonlinearity","text":"Outputs aren\u2019t always proportional to inputs, so the world is a barrage of massive wins and horrible losses that surprise people.","title":"Nonlinearity"},{"location":"archives/2020/2020-03-01-many-ideas/#moderating-relationship","text":"The correlation between two variables depends on a third, seemingly unrelated variable. The quality of a marriage may be dependent on a spouse\u2019s work project that\u2019s causing stress.","title":"Moderating Relationship"},{"location":"archives/2020/2020-03-01-many-ideas/#denomination-effect","text":"One hundred $1 bills feels like less money than one $100 bill. Also explains stock splits \u2013 buying 10 shares for $10 each feels cheaper than one share for $100.","title":"Denomination Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#woozle-effect","text":"\u201cA reliable way to make people believe in falsehoods is frequent repetition, because familiarity is not easily distinguished from truth.\u201d - Daniel Kahneman.","title":"Woozle Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#google-scholar-effect","text":"Scientific research depends on citing other research, and the research that gets cited the most is whatever shows up in the top results of Google Scholar searches, regardless of its contribution to the field.","title":"Google Scholar Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#inversion","text":"Avoiding problems can be more important than scoring wins.","title":"Inversion"},{"location":"archives/2020/2020-03-01-many-ideas/#gamblers-ruin","text":"Has many meanings, the most important of which is that playing a negative-probability game persistently enough guarantees going broke.","title":"Gambler\u2019s Ruin"},{"location":"archives/2020/2020-03-01-many-ideas/#principle-of-least-effort","text":"When seeking information, effort declines as soon as the minimum acceptable result is reached.","title":"Principle of Least Effort"},{"location":"archives/2020/2020-03-01-many-ideas/#dunning-kruger-effect","text":"Knowing the limits of your intelligence requires a certain level of intelligence, so some people are too stupid to know how stupid they are.","title":"Dunning-Kruger Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#knightian-uncertainty","text":"Risk that can\u2019t be measured; admitting that you don\u2019t know what you don\u2019t know.","title":"Knightian Uncertainty"},{"location":"archives/2020/2020-03-01-many-ideas/#aumanns-agreement-theorem","text":"If you understand your opponent\u2019s beliefs you cannot agree to disagree. If you agree to disagree it\u2019s because one side doesn\u2019t understand the other side\u2019s view.","title":"Aumann\u2019s Agreement Theorem"},{"location":"archives/2020/2020-03-01-many-ideas/#focusing-effect","text":"Overemphasizing factors that seem important but exist as part of a complex system. People from the Midwest assume Californians are happier because the weather is better, but they\u2019re not because Californians also deal with traffic, bad bosses, unhappy marriages, etc, which more than offset the happiness boost from sunny skies.","title":"Focusing Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#the-middle-ground-fallacy","text":"Falsely assuming that splitting the difference between two polar opposite views is a healthy compromise. If one person says vaccines cause autism and another person says they don\u2019t, it\u2019s not right to compromise and say vaccines sometimes cause autism.","title":"The Middle Ground Fallacy"},{"location":"archives/2020/2020-03-01-many-ideas/#rebound-effect","text":"New symptoms, or supercharged old symptoms, emerge when medicine or other protections are withdrawn.","title":"Rebound Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#ostrich-effect","text":"Avoiding negative information that might challenge views that you desperately want to be right.","title":"Ostrich Effect"},{"location":"archives/2020/2020-03-01-many-ideas/#founders-syndrome","text":"When a CEO is so emotionally invested in a company that they can\u2019t effectively delegate decisions.","title":"Founder\u2019s Syndrome"},{"location":"archives/2020/2020-03-01-many-ideas/#in-group-favoritism","text":"Giving preference to people from your social group regardless of their objective qualifications.","title":"In-Group Favoritism"},{"location":"archives/2020/2020-03-01-many-ideas/#bounded-rationality","text":"People can\u2019t be fully rational because your brain is a hormone machine, not an Excel spreadsheet.","title":"Bounded Rationality"},{"location":"archives/2020/2020-03-01-many-ideas/#luxury-paradox","text":"The more expensive something is the less likely you are to use it, so the relationship between price and utility is an inverted U. Ferraris sit in garages; Hondas get driven.","title":"Luxury Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#meat-paradox","text":"Dogs are family, pigs are food. Some animals classified as food are wrongly perceived to have lower intelligence than those classified as pets. An example of morality depending on utility.","title":"Meat Paradox"},{"location":"archives/2020/2020-03-01-many-ideas/#fluency-heuristic","text":"Ideas that can be explained simply are more likely to be believed than those that are complex, even if the simple-sounding ideas are nonsense. It occurs because ideas that are easy to grasp are hard to distinguish from ideas you\u2019re familiar with.","title":"Fluency Heuristic"},{"location":"archives/2020/2020-03-01-many-ideas/#historical-wisdom","text":"\u201cThe dead outnumber the living 14 to 1, and we ignore the accumulated experience of such a huge majority of mankind at our peril.\u201d \u2013 Niall Ferguson","title":"Historical Wisdom"},{"location":"archives/2020/2020-03-01-many-ideas/#fact-check-scarcity-principle","text":"This article is called 100 Little Ideas but there are fewer than 100 ideas. 99% of readers won\u2019t notice because they\u2019re not checking, and most of those who notice won\u2019t say anything. Don\u2019t believe everything you read.","title":"Fact-Check Scarcity Principle"},{"location":"archives/2020/2020-03-01-many-ideas/#emotional-contagion","text":"One person\u2019s emotions trigger the same emotions in other people, because evolution has selected for empathizing with those in your social group whose actions you rely on.","title":"Emotional Contagion"},{"location":"archives/2020/2020-03-01-many-ideas/#tribal-affiliation","text":"Beliefs can be swayed by identity and a desire to fit in over rational analysis. There is little correlation between climate change denial and scientific literacy. But there is a strong correlation between climate change denial and political affiliation.","title":"Tribal Affiliation"},{"location":"archives/2020/2020-03-01-many-ideas/#emotional-competence","text":"The ability to recognize others\u2019 emotions and respond to them productively. Harder and rarer than it sounds.","title":"Emotional Competence"},{"location":"archives/2020/2020-04-25-motivation/","tags":"patterns","text":"When you need a swift kick in the butt, just listen- . Some key take-aways Nelson Mandela said, \"There is no passion to be found playing small and settling for a life that's less than the one you're capable of living...\" If I'm going to fall, I don't want to fall back on anything. I want to fall FORWARD. ...So do what you feel passionate about. Take chances. Don't be afraid to fail. ... Don't be afraid to think outside the box. Don't be afraid to FAIL BIG. Reggie Jackson struck out 2600 times in his career, the most in the history of baseball. But you don't hear about the strikeouts. People remember the homeruns. Every failed experiment is one step closer to success. You WILL FAIL at some point in your life. Accept it. You will lose. You will embarrass yourself. You will suck at something. There is no doubt about it. If you don't fail, you're not even trying. To get something you never had, you have to do something you never did. . For a more thorough ass-kicking , listen to this one- . Thinking about the hard times...","title":"What's my Motivation?"},{"location":"archives/2020/2020-11-28-potpourri/","tags":"patterns","text":"Import module versus from module import foo in Python This question had always bugged me. There are two ways to import modules in Python. import module Simplest way to import a module However must require using the name of the module as a prefix before a module's class or function- like module.foo . One way around this is to use import module as mo . Then you can use mo.foo . from module import foo No need to use module namespace prefix to use foo. Can import individual functions or classes. However, problem with no module namespace prefix means readers have no idea where a function or class comes from. from module import * adds all items from module into current namespace- which is horrible. The Zen of Python From Python Python Enhancement Proposal (PEP) #20 Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! The Agile Manifesto Scrum Lean Software","title":"Potpourri of items"},{"location":"archives/2020/2020-11-28-potpourri/#import-module-versus-from-module-import-foo-in-python","text":"This question had always bugged me. There are two ways to import modules in Python.","title":"Import module versus from module import foo in Python"},{"location":"archives/2020/2020-11-28-potpourri/#import-module","text":"Simplest way to import a module However must require using the name of the module as a prefix before a module's class or function- like module.foo . One way around this is to use import module as mo . Then you can use mo.foo .","title":"import module"},{"location":"archives/2020/2020-11-28-potpourri/#from-module-import-foo","text":"No need to use module namespace prefix to use foo. Can import individual functions or classes. However, problem with no module namespace prefix means readers have no idea where a function or class comes from. from module import * adds all items from module into current namespace- which is horrible.","title":"from module import foo"},{"location":"archives/2020/2020-11-28-potpourri/#the-zen-of-python","text":"From Python Python Enhancement Proposal (PEP) #20 Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those!","title":"The Zen of Python"},{"location":"archives/2020/2020-11-28-potpourri/#the-agile-manifesto","text":"","title":"The Agile Manifesto"},{"location":"archives/2020/2020-11-28-potpourri/#scrum","text":"","title":"Scrum"},{"location":"archives/2020/2020-11-28-potpourri/#lean-software","text":"","title":"Lean Software"},{"location":"archives/2020/2020-12-19-pytest/","tags":"patterns","text":"Reasons pytest is the best unit test framework for Python Python coders appear to favor pytest over unittest by a wide margin. What's so good about pytest? Here is a summary: minimal test coding fuss. No need to derive test from a unittest base class. pytest shows the intermediate values leading to test failures- without requiring debugging. simple reusable test fixture setup. easy to parameterize tests without writing duplicate tests. can directly kick off pdb debugger in the event of a test failure marks for allowing selection of tests to execute. mark groups of tests with decorator @pytest.mark.label then execute that one group of test with: pytest -m label can run one a set of matching tests by name with -k automatic test discovery in folder and subfolders. many extensions (plugins) are available pytest-xdist, pytest test.py -n 3, run tests on 3 parallel processes parameterized, decorate test function with @parameterized.expand(['a','b','c']) pytest-flake8, pytest --flake8, check code against PEP8 standards pytest-html, pytest --html=rep.html, generate pretty test result report Python most useful command line options -v, -vv, -vvv: verbose and very verbose, very very verbose --pdb: start pdb debugger when a test fails -k: run only certain tests using a keyword filter -s: to display program stdout output while tests are running instead of after failure -x: exit after first failure","title":"What's so good about pytest?"},{"location":"archives/2020/2020-12-19-pytest/#reasons-pytest-is-the-best-unit-test-framework-for-python","text":"Python coders appear to favor pytest over unittest by a wide margin. What's so good about pytest? Here is a summary: minimal test coding fuss. No need to derive test from a unittest base class. pytest shows the intermediate values leading to test failures- without requiring debugging. simple reusable test fixture setup. easy to parameterize tests without writing duplicate tests. can directly kick off pdb debugger in the event of a test failure marks for allowing selection of tests to execute. mark groups of tests with decorator @pytest.mark.label then execute that one group of test with: pytest -m label can run one a set of matching tests by name with -k automatic test discovery in folder and subfolders. many extensions (plugins) are available pytest-xdist, pytest test.py -n 3, run tests on 3 parallel processes parameterized, decorate test function with @parameterized.expand(['a','b','c']) pytest-flake8, pytest --flake8, check code against PEP8 standards pytest-html, pytest --html=rep.html, generate pretty test result report","title":"Reasons pytest is the best unit test framework for Python"},{"location":"archives/2020/2020-12-19-pytest/#python-most-useful-command-line-options","text":"-v, -vv, -vvv: verbose and very verbose, very very verbose --pdb: start pdb debugger when a test fails -k: run only certain tests using a keyword filter -s: to display program stdout output while tests are running instead of after failure -x: exit after first failure","title":"Python most useful command line options"},{"location":"archives/2020/2020-12-20-ust-fx-basics/","tags":"patterns","text":"UST Basics UST quote notation: FX Basics Spot-currency trading is conducted through pips. One pip is 1/100th of a penny. One pip is 0.0001 in the exchange rate of a currency pair. A standard lot is 100,000 units of a currency pair. One pip move of a standard contract is 1e5 * 1e-4 = 1e1 = 10 units (for example $10). A mini lot is 10,000 units of a currency pair. One pip move of a mini lot contract is 1e4 * 1e-4 = 1e0 = 1 unit (for example $1). The cost of a buy and sell round trip is the size of the bid-ask spread.","title":"UST and FX Basics"},{"location":"archives/2020/2020-12-20-ust-fx-basics/#ust-basics","text":"UST quote notation:","title":"UST Basics"},{"location":"archives/2020/2020-12-20-ust-fx-basics/#fx-basics","text":"Spot-currency trading is conducted through pips. One pip is 1/100th of a penny. One pip is 0.0001 in the exchange rate of a currency pair. A standard lot is 100,000 units of a currency pair. One pip move of a standard contract is 1e5 * 1e-4 = 1e1 = 10 units (for example $10). A mini lot is 10,000 units of a currency pair. One pip move of a mini lot contract is 1e4 * 1e-4 = 1e0 = 1 unit (for example $1). The cost of a buy and sell round trip is the size of the bid-ask spread.","title":"FX Basics"},{"location":"cheats/cmake/","text":"Cmake Basics Each folder must have a make file named 'CMakeLists.txt'. CMake generates a Makefile and also kicks off the build. cmake_minimum_required(VERSION 3.5) add_executable(cmake_test test01.cpp) Commands to fire cmake to generate makefile and then kick off the build cmake ./ cmake ./ -DCMAKE_CXX_COMPILER=\"icc\" -DCMAKE_CXX_FLAGS=\"-std=c++11\" make make VERBOSE=1 make clean Command line parameters get saved to a file- CMakeCache.txt. Common commands add_subdirectory add_executable include_directories add_definition target_link_libraries","title":"Cmake"},{"location":"cheats/cmake/#cmake","text":"","title":"Cmake"},{"location":"cheats/cmake/#basics","text":"Each folder must have a make file named 'CMakeLists.txt'. CMake generates a Makefile and also kicks off the build. cmake_minimum_required(VERSION 3.5) add_executable(cmake_test test01.cpp) Commands to fire cmake to generate makefile and then kick off the build cmake ./ cmake ./ -DCMAKE_CXX_COMPILER=\"icc\" -DCMAKE_CXX_FLAGS=\"-std=c++11\" make make VERBOSE=1 make clean Command line parameters get saved to a file- CMakeCache.txt.","title":"Basics"},{"location":"cheats/cmake/#common-commands","text":"add_subdirectory add_executable include_directories add_definition target_link_libraries","title":"Common commands"},{"location":"cheats/git/","text":"Git Common Commands git config --global alias.tree 'log --graph --abbrev-commit --oneline' git log --all --decorate --oneline --graph git log branch1 branch2 git show (hashid) git merge (branch.to.merge.from) git diff branch1 branch2 --name-only git webdiff branch1 branch2 git config --global alias.unstage 'reset HEAD --' git unstage filename git config --global alias.difflast 'diff --cached HEAD^' git log -G\"textToFind\" --online git log -n git diff HEAD~2 HEAD Git merge Merge copies all feature branch changes to another branch. Before (master)v1-->v2 \\ \\(br)-->b1-->b2 Git merge moves changes b1 and b2 from branch br to the master branch. After (master)v1-->v2-->b1-->b2 \\ \\(br)-->b1-->b2 git tree shows (base) quantboy@ThinkPad:~/dev/test$ git tree * 49bf8d4 (HEAD -> master) Merge branch 'br' |\\ | * 7c5741d (br) b2 | * 3335395 b1 * | 8545eca v3 |/ * 11378de v2 * e97f722 v1 ========================== Steps to reproduce ========================== mkdir test cd test git init echo v1 >> file.txt git add . git commit -m \"v1\" echo v2 >> file.txt git add . git commit -m \"v2\" git checkout -b br echo b1 >> fileb.txt git add . git commit -m \"b1\" echo b2 >> fileb.txt git add . git commit -m \"b2\" git checkout master echo v3 >> file.txt git add . git commit -m \"v3\" git merge br Git rebase Before (master)v1-->v2-->v3 \\ \\(br)-->b1-->b2 git tree shows * 75f7798 (HEAD -> br) b2 * 53cbe04 b1 * 11a44e7 v2 * 067f3ca v1 In branch br, git rebase master After (master)v1-->v2-->v3 \\ \\(br)-->b1-->b2 git tree shows * af3ee5e (HEAD -> br) b2 * 6112718 b1 * 89dc959 (master) v3 * 11a44e7 v2 * 067f3ca v1 git checkout master git merge br git tree shows * 75f7798 (HEAD -> br) b2 * 53cbe04 b1 * 89dc959 v3 * 11a44e7 v2 * 067f3ca v1 ========================== Steps to reproduce ========================== mkdir test cd test git init echo v1 >> file.txt git add . git commit -m \"v1\" echo v2 >> file.txt git add . git commit -m \"v2\" git checkout -b br echo b1 >> fileb.txt git add . git commit -m \"b1\" echo b2 >> fileb.txt git add . git commit -m \"b2\" git checkout master echo v3 >> file.txt git add . git commit -m \"v3\" git checkout br git rebase master git checkout master git merge br ------------------------------------------------ Before (master)v1-->v2-->v3 \\ \\(br)-->b1-->b2 After (master)v1-->v2-->v3-->b1-->b2 \\ \\(br)-->b1-->b2 In master branch, git rebase br git tree shows * af3ee5e (HEAD -> master, br) b2 * 6112718 b1 * 89dc959 v3 * 11a44e7 v2 * 067f3ca v1 The upside is that there is less branches to show in the tree log. The downside is that this rewrites the history- so be super careful with remote repositories shared with teammates.","title":"Git"},{"location":"cheats/git/#git","text":"","title":"Git"},{"location":"cheats/git/#common-commands","text":"git config --global alias.tree 'log --graph --abbrev-commit --oneline' git log --all --decorate --oneline --graph git log branch1 branch2 git show (hashid) git merge (branch.to.merge.from) git diff branch1 branch2 --name-only git webdiff branch1 branch2 git config --global alias.unstage 'reset HEAD --' git unstage filename git config --global alias.difflast 'diff --cached HEAD^' git log -G\"textToFind\" --online git log -n git diff HEAD~2 HEAD","title":"Common Commands"},{"location":"cheats/git/#git-merge","text":"Merge copies all feature branch changes to another branch. Before (master)v1-->v2 \\ \\(br)-->b1-->b2 Git merge moves changes b1 and b2 from branch br to the master branch. After (master)v1-->v2-->b1-->b2 \\ \\(br)-->b1-->b2 git tree shows (base) quantboy@ThinkPad:~/dev/test$ git tree * 49bf8d4 (HEAD -> master) Merge branch 'br' |\\ | * 7c5741d (br) b2 | * 3335395 b1 * | 8545eca v3 |/ * 11378de v2 * e97f722 v1 ========================== Steps to reproduce ========================== mkdir test cd test git init echo v1 >> file.txt git add . git commit -m \"v1\" echo v2 >> file.txt git add . git commit -m \"v2\" git checkout -b br echo b1 >> fileb.txt git add . git commit -m \"b1\" echo b2 >> fileb.txt git add . git commit -m \"b2\" git checkout master echo v3 >> file.txt git add . git commit -m \"v3\" git merge br","title":"Git merge"},{"location":"cheats/git/#git-rebase","text":"Before (master)v1-->v2-->v3 \\ \\(br)-->b1-->b2 git tree shows * 75f7798 (HEAD -> br) b2 * 53cbe04 b1 * 11a44e7 v2 * 067f3ca v1 In branch br, git rebase master After (master)v1-->v2-->v3 \\ \\(br)-->b1-->b2 git tree shows * af3ee5e (HEAD -> br) b2 * 6112718 b1 * 89dc959 (master) v3 * 11a44e7 v2 * 067f3ca v1 git checkout master git merge br git tree shows * 75f7798 (HEAD -> br) b2 * 53cbe04 b1 * 89dc959 v3 * 11a44e7 v2 * 067f3ca v1 ========================== Steps to reproduce ========================== mkdir test cd test git init echo v1 >> file.txt git add . git commit -m \"v1\" echo v2 >> file.txt git add . git commit -m \"v2\" git checkout -b br echo b1 >> fileb.txt git add . git commit -m \"b1\" echo b2 >> fileb.txt git add . git commit -m \"b2\" git checkout master echo v3 >> file.txt git add . git commit -m \"v3\" git checkout br git rebase master git checkout master git merge br ------------------------------------------------ Before (master)v1-->v2-->v3 \\ \\(br)-->b1-->b2 After (master)v1-->v2-->v3-->b1-->b2 \\ \\(br)-->b1-->b2 In master branch, git rebase br git tree shows * af3ee5e (HEAD -> master, br) b2 * 6112718 b1 * 89dc959 v3 * 11a44e7 v2 * 067f3ca v1 The upside is that there is less branches to show in the tree log. The downside is that this rewrites the history- so be super careful with remote repositories shared with teammates.","title":"Git rebase"},{"location":"cheats/journalctl/","text":"journalctl Options -u (name) unit name -f follow -n show last 10 entries -n (num) show last num entries _PID=(pid) process id --no-full truncate logs --no-pager do not page, can redirect to grep or disk -a display all -since (datetime) -until (datetime) Datetime options include: \"2022-01-01 09:00:00\" \"2022-01-01\" 09:00 today yesterday \"1 hour ago\" \"10 minutes ago\"","title":"journalctl"},{"location":"cheats/journalctl/#journalctl","text":"","title":"journalctl"},{"location":"cheats/journalctl/#options","text":"-u (name) unit name -f follow -n show last 10 entries -n (num) show last num entries _PID=(pid) process id --no-full truncate logs --no-pager do not page, can redirect to grep or disk -a display all -since (datetime) -until (datetime) Datetime options include: \"2022-01-01 09:00:00\" \"2022-01-01\" 09:00 today yesterday \"1 hour ago\" \"10 minutes ago\"","title":"Options"},{"location":"cheats/nix/","text":"Nix find . -name \"pattern\" # find any objects with a name pattern find . -name \"pattern\" -type f # find any files with a name pattern find . -mtime -1 # find any objects modified within the past day find . -name \"regex_abc\" -type f -exec grep -nH regex_xyz {} \\; # find any file with regex_abc whose contents contain regex_xyz","title":"Nix"},{"location":"cheats/nix/#nix","text":"find . -name \"pattern\" # find any objects with a name pattern find . -name \"pattern\" -type f # find any files with a name pattern find . -mtime -1 # find any objects modified within the past day find . -name \"regex_abc\" -type f -exec grep -nH regex_xyz {} \\; # find any file with regex_abc whose contents contain regex_xyz","title":"Nix"},{"location":"cheats/vi/","text":"Vi Finding things f{c} find the next instance of character F{c} find the previous instance of character /{pattern} find the next instance of pattern ?{pattern} find the previous instance of pattern * find the next instance of word under cursor n after find, go to the next instance N after find, go to the previous instance Replacing things :s/old/new/g replace old with new only on current line :n,m s/old/new/g replace old with new only on lines n to m :%s/old/new/g replace old with new globally %s is special symbol in ed for all rows in file Vital ops u undo last sequence of change Buffers :e select a file to edit from local folder :ls list loaded files in buffers :bn buffer next :bp buffer previous :bdelete n buffer delete n Windows Ctrl-w s split horizontal window Ctrl-w v split vertical window Ctrl-w h/j/k/l window jump- up, down, left, right Ctrl-w Ctrl-w window cycle Ctrl-w c close window Ctrl-w = resize window sizes all equal Visual blocks v select block by character V select block by line Ctrl-v select block Moving around $ jump to end of line dw delete word forward daw delete a word dd delete line Reformatting :set textwidth=65 v gq Bookmarks m(c) mark position with character c '(c) jump back to position c Macros q(r) record a macro to register r @(r) playback macro r n@(r) playback macro r n number of times","title":"Vi"},{"location":"cheats/vi/#vi","text":"","title":"Vi"},{"location":"cheats/vi/#finding-things","text":"f{c} find the next instance of character F{c} find the previous instance of character /{pattern} find the next instance of pattern ?{pattern} find the previous instance of pattern * find the next instance of word under cursor n after find, go to the next instance N after find, go to the previous instance","title":"Finding things"},{"location":"cheats/vi/#replacing-things","text":":s/old/new/g replace old with new only on current line :n,m s/old/new/g replace old with new only on lines n to m :%s/old/new/g replace old with new globally %s is special symbol in ed for all rows in file","title":"Replacing things"},{"location":"cheats/vi/#vital-ops","text":"u undo last sequence of change","title":"Vital ops"},{"location":"cheats/vi/#buffers","text":":e select a file to edit from local folder :ls list loaded files in buffers :bn buffer next :bp buffer previous :bdelete n buffer delete n","title":"Buffers"},{"location":"cheats/vi/#windows","text":"Ctrl-w s split horizontal window Ctrl-w v split vertical window Ctrl-w h/j/k/l window jump- up, down, left, right Ctrl-w Ctrl-w window cycle Ctrl-w c close window Ctrl-w = resize window sizes all equal","title":"Windows"},{"location":"cheats/vi/#visual-blocks","text":"v select block by character V select block by line Ctrl-v select block","title":"Visual blocks"},{"location":"cheats/vi/#moving-around","text":"$ jump to end of line dw delete word forward daw delete a word dd delete line","title":"Moving around"},{"location":"cheats/vi/#reformatting","text":":set textwidth=65 v gq","title":"Reformatting"},{"location":"cheats/vi/#bookmarks","text":"m(c) mark position with character c '(c) jump back to position c","title":"Bookmarks"},{"location":"cheats/vi/#macros","text":"q(r) record a macro to register r @(r) playback macro r n@(r) playback macro r n number of times","title":"Macros"}]}